{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Baseline Model\n- We will be using the processed CIFAR-10 dataset to train a baseline CNN model.\n- In the baseline model, we will be using the labelled dataset only, and will be testing the model on the test dataset","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"markdown","source":"## Importing the Packages","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom tqdm import tqdm\nfrom sklearn.metrics import accuracy_score, log_loss\n\nimport tensorflow as tf\nimport tensorflow.keras.layers as tfl","metadata":{"execution":{"iopub.status.busy":"2022-03-05T12:38:22.321417Z","iopub.execute_input":"2022-03-05T12:38:22.321953Z","iopub.status.idle":"2022-03-05T12:38:29.386963Z","shell.execute_reply.started":"2022-03-05T12:38:22.321847Z","shell.execute_reply":"2022-03-05T12:38:29.385702Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"## Data Exploration","metadata":{}},{"cell_type":"code","source":"# Importing the Labelled Dataset\ndf_train = pd.read_csv(\"../input/cifar10/train_lab_x.csv\")\ny_train = pd.read_csv(\"../input/cifar10/train_lab_y.csv\")\ndf_train = np.array(df_train)\ny_train = np.array(y_train)\nprint(df_train.shape, y_train.shape)\n\n# Reshaping the dataset\ndf_train = np.reshape(df_train, (-1, 3, 32, 32))\nprint(df_train.shape)\n\n# Visualizing a single image\nind = 11\nexample = df_train[ind, : , : , : ]\nexample = example.transpose((1, 2, 0))\nplt.figure(figsize=(1.5, 1.5))\nplt.imshow(example)\nprint(y_train[ind])","metadata":{"execution":{"iopub.status.busy":"2022-03-05T12:38:29.388479Z","iopub.execute_input":"2022-03-05T12:38:29.388666Z","iopub.status.idle":"2022-03-05T12:38:51.851358Z","shell.execute_reply.started":"2022-03-05T12:38:29.388642Z","shell.execute_reply":"2022-03-05T12:38:51.850715Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## Basic Pre-processing","metadata":{}},{"cell_type":"code","source":"# Creating a random permutation\nperm = np.random.permutation(df_train.shape[0])\n\n# Shuffling the training dataset\ndf_train = df_train[perm, : , : , : ]\ny_train = y_train[perm]\n\n# Reshaping, rescaling and one-hot encoding\ndf_train = np.transpose(np.array(df_train), (0, 2, 3, 1))\ndf_train = df_train / 255\ny_train_oh = tf.one_hot(np.ravel(y_train), depth = 10)\n\nprint(df_train.shape, y_train_oh.shape)","metadata":{"execution":{"iopub.status.busy":"2022-03-05T12:38:51.852545Z","iopub.execute_input":"2022-03-05T12:38:51.853275Z","iopub.status.idle":"2022-03-05T12:38:53.236873Z","shell.execute_reply.started":"2022-03-05T12:38:51.853237Z","shell.execute_reply":"2022-03-05T12:38:53.236308Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## Creating the Model","metadata":{}},{"cell_type":"code","source":"def cnn_model(input_shape):\n    input_img = tf.keras.Input(shape = input_shape)\n    \n    Z1 = tfl.Conv2D(8, kernel_size=3, strides=1, padding='valid')(input_img)\n    A1 = tfl.ReLU()(Z1)\n    P1 = tfl.MaxPool2D(pool_size=2, strides=2, padding='valid')(A1)\n    \n    Z2 = tfl.Conv2D(16, kernel_size=2, strides=1, padding='valid')(P1)\n    A2 = tfl.ReLU()(Z2)\n    P2 = tfl.MaxPool2D(pool_size=2, strides=2, padding='valid')(A2)\n    \n    F1 = tfl.Flatten()(P2)\n    Den1 = tfl.Dense(256, activation='relu')(F1)\n    Drop1 = tfl.Dropout(0.2)(Den1)\n    Den2 = tfl.Dense(64, activation='relu')(Drop1)\n    Drop2 = tfl.Dropout(0.2)(Den2)\n    outputs = tfl.Dense(10, activation='softmax')(Drop2)\n    \n    model = tf.keras.Model(inputs = input_img, outputs = outputs)\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-03-05T12:38:53.238060Z","iopub.execute_input":"2022-03-05T12:38:53.238401Z","iopub.status.idle":"2022-03-05T12:38:53.248032Z","shell.execute_reply.started":"2022-03-05T12:38:53.238369Z","shell.execute_reply":"2022-03-05T12:38:53.247230Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"## Compiling and Training the Model","metadata":{}},{"cell_type":"code","source":"conv_model = cnn_model((32, 32, 3))\nconv_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics='accuracy')\nconv_model.summary()","metadata":{"scrolled":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-03-05T12:38:53.249963Z","iopub.execute_input":"2022-03-05T12:38:53.250157Z","iopub.status.idle":"2022-03-05T12:38:53.398749Z","shell.execute_reply.started":"2022-03-05T12:38:53.250130Z","shell.execute_reply":"2022-03-05T12:38:53.397937Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"train_dataset = tf.data.Dataset.from_tensor_slices((df_train, y_train_oh)).batch(32)\nhistory = conv_model.fit(train_dataset, epochs = 10)","metadata":{"scrolled":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-03-05T12:38:53.399836Z","iopub.execute_input":"2022-03-05T12:38:53.400054Z","iopub.status.idle":"2022-03-05T12:40:34.219697Z","shell.execute_reply.started":"2022-03-05T12:38:53.400026Z","shell.execute_reply":"2022-03-05T12:40:34.218906Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"## Inferencing on the Train/Test Sets","metadata":{}},{"cell_type":"code","source":"# Importing the Test Dataset\ndf_test = pd.read_csv(\"../input/cifar10/test_x.csv\")\ny_test = pd.read_csv(\"../input/cifar10/test_y.csv\")\ndf_test = np.array(df_test)\ny_test = np.array(y_test)\nprint(df_test.shape, y_test.shape)\n\n# Reshaping the dataset\ndf_test = np.reshape(df_test, (-1, 3, 32, 32))\nprint(df_test.shape)\n\n# Reshaping, rescaling and one-hot encoding\ndf_test = np.transpose(np.array(df_test), (0, 2, 3, 1))\ndf_test = df_test / 255\ny_test_oh = tf.one_hot(np.ravel(y_test), depth = 10)\nprint(df_test.shape, y_test_oh.shape)","metadata":{"execution":{"iopub.status.busy":"2022-03-05T12:40:34.222425Z","iopub.execute_input":"2022-03-05T12:40:34.222584Z","iopub.status.idle":"2022-03-05T12:40:40.023403Z","shell.execute_reply.started":"2022-03-05T12:40:34.222565Z","shell.execute_reply":"2022-03-05T12:40:40.022383Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Predicting on the Train/Test Datasets\npreds_train = conv_model.predict(df_train)\npreds_test = conv_model.predict(df_test)\n\n# Finding the Predicted Classes\ncls_train = np.argmax(preds_train, axis = 1)\ncls_test = np.argmax(preds_test, axis = 1)","metadata":{"execution":{"iopub.status.busy":"2022-03-05T12:40:40.024615Z","iopub.execute_input":"2022-03-05T12:40:40.024868Z","iopub.status.idle":"2022-03-05T12:40:45.305495Z","shell.execute_reply.started":"2022-03-05T12:40:40.024836Z","shell.execute_reply":"2022-03-05T12:40:45.304352Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Finding the Train/Test set Loss\nprint(\"Log-loss for Train Dataset = \", log_loss(y_train_oh, preds_train))\nprint(\"Log-loss for Test Dataset = \", log_loss(y_test_oh, preds_test))\nprint(\"Accuracy for Train Dataset = \", accuracy_score(y_train, cls_train))\nprint(\"Accuracy for Test Dataset = \", accuracy_score(y_test, cls_test))","metadata":{"execution":{"iopub.status.busy":"2022-03-05T12:40:45.306909Z","iopub.execute_input":"2022-03-05T12:40:45.307184Z","iopub.status.idle":"2022-03-05T12:40:45.392954Z","shell.execute_reply.started":"2022-03-05T12:40:45.307146Z","shell.execute_reply":"2022-03-05T12:40:45.392076Z"},"trusted":true},"execution_count":9,"outputs":[]}]}