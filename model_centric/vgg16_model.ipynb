{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2eb6c5ef",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 0.023142,
     "end_time": "2022-04-09T15:25:53.765745",
     "exception": false,
     "start_time": "2022-04-09T15:25:53.742603",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# VGG16\n",
    "- CIFAR10 dataset is used to train the pre-trained model VGG16. \n",
    "- Only the labelled dataset is used in this model.\n",
    "- Fine-tuning of the model is also done, through freezing the layer, adding new layers to the model etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da2d2c5",
   "metadata": {
    "papermill": {
     "duration": 0.02126,
     "end_time": "2022-04-09T15:25:53.811356",
     "exception": false,
     "start_time": "2022-04-09T15:25:53.790096",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Importing the Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd2e76b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-09T15:25:53.860715Z",
     "iopub.status.busy": "2022-04-09T15:25:53.858706Z",
     "iopub.status.idle": "2022-04-09T15:26:00.513623Z",
     "shell.execute_reply": "2022-04-09T15:26:00.514227Z",
     "shell.execute_reply.started": "2022-03-12T17:17:36.285622Z"
    },
    "papermill": {
     "duration": 6.682008,
     "end_time": "2022-04-09T15:26:00.514586",
     "exception": false,
     "start_time": "2022-04-09T15:25:53.832578",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from tabulate import tabulate\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "\n",
    "# https://www.kaggle.com/c/ventilator-pressure-prediction/discussion/274717\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.applications import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f048e4e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-09T15:26:02.903611Z",
     "iopub.status.busy": "2022-04-09T15:26:02.902243Z",
     "iopub.status.idle": "2022-04-09T15:26:02.907687Z",
     "shell.execute_reply": "2022-04-09T15:26:02.907143Z",
     "shell.execute_reply.started": "2022-03-12T17:17:41.890648Z"
    },
    "papermill": {
     "duration": 2.371005,
     "end_time": "2022-04-09T15:26:02.907839",
     "exception": false,
     "start_time": "2022-04-09T15:26:00.536834",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU at: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "# Making sure that Tensorflow is able to detect the GPU\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if \"GPU\" not in device_name:\n",
    "    print(\"GPU device not found\")\n",
    "print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ed442dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-09T15:26:02.962130Z",
     "iopub.status.busy": "2022-04-09T15:26:02.955805Z",
     "iopub.status.idle": "2022-04-09T15:26:02.964996Z",
     "shell.execute_reply": "2022-04-09T15:26:02.964389Z",
     "shell.execute_reply.started": "2022-03-12T17:17:43.565245Z"
    },
    "papermill": {
     "duration": 0.034959,
     "end_time": "2022-04-09T15:26:02.965137",
     "exception": false,
     "start_time": "2022-04-09T15:26:02.930178",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# These are the usual ipython objects\n",
    "ipython_vars = ['In', 'Out', 'exit', 'quit', 'get_ipython', 'ipython_vars']\n",
    "\n",
    "# Defining a function to list the memory consumed\n",
    "# Only outputs variables taking at least 1MB space\n",
    "def list_storage(inp_dir):\n",
    "    # Get a sorted list of the objects and their sizes\n",
    "    vars_defined = [x for x in inp_dir if not x.startswith('_') and x not in sys.modules and x not in ipython_vars]\n",
    "    sto = sorted([(x, sys.getsizeof(globals().get(x))) for x in vars_defined], key=lambda x: x[1], reverse=True)\n",
    "    sto = [(x[0], str(round((x[1] / 2**20), 2)) + ' MB') for x in sto if x[1] >= 2**20]\n",
    "    print(tabulate(sto, headers = ['Variable', 'Storage (in MB)']))\n",
    "\n",
    "# In order to use this function, use the below line of code\n",
    "# list_storage(dir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5fdd452",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-09T15:26:03.014126Z",
     "iopub.status.busy": "2022-04-09T15:26:03.012481Z",
     "iopub.status.idle": "2022-04-09T15:26:33.506067Z",
     "shell.execute_reply": "2022-04-09T15:26:33.505407Z",
     "shell.execute_reply.started": "2022-03-12T17:17:43.586646Z"
    },
    "papermill": {
     "duration": 30.519221,
     "end_time": "2022-04-09T15:26:33.506249",
     "exception": false,
     "start_time": "2022-04-09T15:26:02.987028",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Importing the Labelled Dataset\n",
    "df_train = pd.read_csv(\"../input/cifar10/train_lab_x.csv\")\n",
    "y_train = pd.read_csv(\"../input/cifar10/train_lab_y.csv\")\n",
    "\n",
    "# Importing the Test Dataset\n",
    "df_test = pd.read_csv(\"../input/cifar10/test_x.csv\")\n",
    "y_test = pd.read_csv(\"../input/cifar10/test_y.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b771b356",
   "metadata": {
    "papermill": {
     "duration": 0.023191,
     "end_time": "2022-04-09T15:26:33.551854",
     "exception": false,
     "start_time": "2022-04-09T15:26:33.528663",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Basic Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d7ccdcc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-09T15:26:33.603519Z",
     "iopub.status.busy": "2022-04-09T15:26:33.602051Z",
     "iopub.status.idle": "2022-04-09T15:26:34.211775Z",
     "shell.execute_reply": "2022-04-09T15:26:34.211120Z",
     "shell.execute_reply.started": "2022-03-12T17:18:10.602434Z"
    },
    "papermill": {
     "duration": 0.638573,
     "end_time": "2022-04-09T15:26:34.211926",
     "exception": false,
     "start_time": "2022-04-09T15:26:33.573353",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40006, 3072) (40006, 1)\n",
      "(40006, 3, 32, 32)\n",
      "[0]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 108x108 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train = np.array(df_train)\n",
    "y_train = np.array(y_train)\n",
    "print(df_train.shape, y_train.shape)\n",
    "\n",
    "# Reshaping the dataset\n",
    "df_train = np.reshape(df_train, (-1, 3, 32, 32))\n",
    "print(df_train.shape)\n",
    "\n",
    "# Visualizing a single image\n",
    "ind = 89\n",
    "example = df_train[ind, : , : , : ]\n",
    "example = example.transpose((1, 2, 0))\n",
    "plt.figure(figsize=(1.5, 1.5))\n",
    "plt.imshow(example)\n",
    "print(y_train[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "edc417ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-09T15:26:34.268218Z",
     "iopub.status.busy": "2022-04-09T15:26:34.266900Z",
     "iopub.status.idle": "2022-04-09T15:26:37.363986Z",
     "shell.execute_reply": "2022-04-09T15:26:37.364667Z",
     "shell.execute_reply.started": "2022-03-12T17:18:11.129192Z"
    },
    "papermill": {
     "duration": 3.12984,
     "end_time": "2022-04-09T15:26:37.364859",
     "exception": false,
     "start_time": "2022-04-09T15:26:34.235019",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40006, 32, 32, 3) (40006, 10)\n"
     ]
    }
   ],
   "source": [
    "# Creating a random permutation\n",
    "perm = np.random.permutation(df_train.shape[0])\n",
    "\n",
    "# Shuffling the training dataset\n",
    "df_train = df_train[perm, : , : , : ]\n",
    "y_train = y_train[perm]\n",
    "\n",
    "# Reshaping, rescaling and one-hot encoding\n",
    "df_train = np.transpose(np.array(df_train), (0, 2, 3, 1))\n",
    "df_train = df_train / 255\n",
    "y_train_oh = tf.one_hot(np.ravel(y_train), depth = 10)\n",
    "\n",
    "print(df_train.shape, y_train_oh.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5283f313",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-09T15:26:37.420165Z",
     "iopub.status.busy": "2022-04-09T15:26:37.418818Z",
     "iopub.status.idle": "2022-04-09T15:26:37.765201Z",
     "shell.execute_reply": "2022-04-09T15:26:37.764132Z",
     "shell.execute_reply.started": "2022-03-12T17:18:13.559388Z"
    },
    "papermill": {
     "duration": 0.37712,
     "end_time": "2022-04-09T15:26:37.765372",
     "exception": false,
     "start_time": "2022-04-09T15:26:37.388252",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 3072) (10000, 1)\n",
      "(10000, 3, 32, 32)\n",
      "(10000, 32, 32, 3) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "df_test = np.array(df_test)\n",
    "y_test = np.array(y_test)\n",
    "print(df_test.shape, y_test.shape)\n",
    "\n",
    "# Reshaping the dataset\n",
    "df_test = np.reshape(df_test, (-1, 3, 32, 32))\n",
    "print(df_test.shape)\n",
    "\n",
    "# Reshaping, rescaling and one-hot encoding\n",
    "df_test = np.transpose(np.array(df_test), (0, 2, 3, 1))\n",
    "df_test = df_test / 255\n",
    "y_test_oh = tf.one_hot(np.ravel(y_test), depth = 10)\n",
    "print(df_test.shape, y_test_oh.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47a24a2",
   "metadata": {
    "papermill": {
     "duration": 0.023241,
     "end_time": "2022-04-09T15:26:37.813517",
     "exception": false,
     "start_time": "2022-04-09T15:26:37.790276",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Building the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e636c46a",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2022-04-09T15:26:37.869571Z",
     "iopub.status.busy": "2022-04-09T15:26:37.868651Z",
     "iopub.status.idle": "2022-04-09T15:26:41.200345Z",
     "shell.execute_reply": "2022-04-09T15:26:41.199802Z",
     "shell.execute_reply.started": "2022-03-12T17:18:13.897972Z"
    },
    "papermill": {
     "duration": 3.36219,
     "end_time": "2022-04-09T15:26:41.200572",
     "exception": false,
     "start_time": "2022-04-09T15:26:37.838382",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58892288/58889256 [==============================] - 2s 0us/step\n",
      "58900480/58889256 [==============================] - 2s 0us/step\n",
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 64, 64, 3)]       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 64, 64, 64)        1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 64, 64, 64)        36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 32, 32, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 32, 32, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 16, 16, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 16, 16, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 16, 16, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 8, 8, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d (Global (None, 512)               0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_t = tf.keras.Input(shape = (64,64,3))\n",
    "vgg_model = VGG16(weights='imagenet', include_top=False, input_tensor=input_t,\n",
    "                             pooling='max')\n",
    "vgg_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7adf3e42",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2022-04-09T15:26:41.267218Z",
     "iopub.status.busy": "2022-04-09T15:26:41.266144Z",
     "iopub.status.idle": "2022-04-09T15:26:41.268782Z",
     "shell.execute_reply": "2022-04-09T15:26:41.269272Z",
     "shell.execute_reply.started": "2022-03-12T17:18:14.83002Z"
    },
    "papermill": {
     "duration": 0.038935,
     "end_time": "2022-04-09T15:26:41.269461",
     "exception": false,
     "start_time": "2022-04-09T15:26:41.230526",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "for layer in vgg_model.layers:\n",
    "    layer.trainable = True\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa0ffa41",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-09T15:26:41.341753Z",
     "iopub.status.busy": "2022-04-09T15:26:41.340604Z",
     "iopub.status.idle": "2022-04-09T15:26:41.365539Z",
     "shell.execute_reply": "2022-04-09T15:26:41.364947Z",
     "shell.execute_reply.started": "2022-03-12T17:18:14.846598Z"
    },
    "papermill": {
     "duration": 0.065806,
     "end_time": "2022-04-09T15:26:41.365693",
     "exception": false,
     "start_time": "2022-04-09T15:26:41.299887",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "to_res = (64,64)\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(layers.Lambda(lambda image: tf.image.resize(image, to_res))) \n",
    "model.add(vgg_model)\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4589c3b0",
   "metadata": {
    "papermill": {
     "duration": 0.029851,
     "end_time": "2022-04-09T15:26:41.426448",
     "exception": false,
     "start_time": "2022-04-09T15:26:41.396597",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training & Hyperparamater-Tuning for the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "431e6304",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2022-04-09T15:26:41.497432Z",
     "iopub.status.busy": "2022-04-09T15:26:41.496361Z",
     "iopub.status.idle": "2022-04-09T15:26:41.677000Z",
     "shell.execute_reply": "2022-04-09T15:26:41.676400Z",
     "shell.execute_reply.started": "2022-03-12T17:18:14.878388Z"
    },
    "papermill": {
     "duration": 0.219922,
     "end_time": "2022-04-09T15:26:41.677148",
     "exception": false,
     "start_time": "2022-04-09T15:26:41.457226",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lambda (Lambda)              (None, 64, 64, 3)         0         \n",
      "_________________________________________________________________\n",
      "vgg16 (Functional)           (None, 512)               14714688  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 14,891,658\n",
      "Trainable params: 14,889,738\n",
      "Non-trainable params: 1,920\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#compiling model \n",
    "loss = 'categorical_crossentropy'\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=2e-5)\n",
    "metrics = ['accuracy']\n",
    "\n",
    "model.compile(loss = loss, optimizer = opt, metrics = metrics)\n",
    "model.build((None, 64, 64, 3))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6abc961d",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2022-04-09T15:26:41.752824Z",
     "iopub.status.busy": "2022-04-09T15:26:41.751753Z",
     "iopub.status.idle": "2022-04-09T17:14:20.508562Z",
     "shell.execute_reply": "2022-04-09T17:14:20.509095Z",
     "shell.execute_reply.started": "2022-03-12T17:18:14.894162Z"
    },
    "papermill": {
     "duration": 6458.800295,
     "end_time": "2022-04-09T17:14:20.509306",
     "exception": false,
     "start_time": "2022-04-09T15:26:41.709011",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1251/1251 [==============================] - 49s 32ms/step - loss: 2.1299 - accuracy: 0.1875\n",
      "Epoch 2/10\n",
      "1251/1251 [==============================] - 39s 31ms/step - loss: 1.8981 - accuracy: 0.2322\n",
      "Epoch 3/10\n",
      "1251/1251 [==============================] - 40s 32ms/step - loss: 1.7871 - accuracy: 0.2983\n",
      "Epoch 4/10\n",
      "1251/1251 [==============================] - 40s 32ms/step - loss: 1.7154 - accuracy: 0.3245\n",
      "Epoch 5/10\n",
      "1251/1251 [==============================] - 40s 32ms/step - loss: 1.6003 - accuracy: 0.3644\n",
      "Epoch 6/10\n",
      "1251/1251 [==============================] - 39s 32ms/step - loss: 1.5143 - accuracy: 0.4017\n",
      "Epoch 7/10\n",
      "1251/1251 [==============================] - 40s 32ms/step - loss: 1.4544 - accuracy: 0.4253\n",
      "Epoch 8/10\n",
      "1251/1251 [==============================] - 40s 32ms/step - loss: 1.4152 - accuracy: 0.4488\n",
      "Epoch 9/10\n",
      "1251/1251 [==============================] - 40s 32ms/step - loss: 1.3857 - accuracy: 0.4688\n",
      "Epoch 10/10\n",
      "1251/1251 [==============================] - 39s 31ms/step - loss: 1.3317 - accuracy: 0.4947\n",
      "For  10  Epochs:\n",
      "Log-loss for Train Dataset =  1.2719465858564927\n",
      "Log-loss for Test Dataset =  1.3279806447825802\n",
      "Accuracy for Train Dataset =  0.48290256461530773\n",
      "Accuracy for Test Dataset =  0.4765\n",
      "\n",
      "Epoch 1/20\n",
      "1251/1251 [==============================] - 41s 31ms/step - loss: 1.2701 - accuracy: 0.5261\n",
      "Epoch 2/20\n",
      "1251/1251 [==============================] - 39s 31ms/step - loss: 1.2017 - accuracy: 0.5626\n",
      "Epoch 3/20\n",
      "1251/1251 [==============================] - 39s 31ms/step - loss: 1.1442 - accuracy: 0.5921\n",
      "Epoch 4/20\n",
      "1251/1251 [==============================] - 39s 31ms/step - loss: 1.0665 - accuracy: 0.6222\n",
      "Epoch 5/20\n",
      "1251/1251 [==============================] - 39s 31ms/step - loss: 1.0075 - accuracy: 0.6520\n",
      "Epoch 6/20\n",
      "1251/1251 [==============================] - 38s 31ms/step - loss: 0.9610 - accuracy: 0.6680\n",
      "Epoch 7/20\n",
      "1251/1251 [==============================] - 40s 32ms/step - loss: 0.8979 - accuracy: 0.6915\n",
      "Epoch 8/20\n",
      "1251/1251 [==============================] - 38s 31ms/step - loss: 0.8463 - accuracy: 0.7145\n",
      "Epoch 9/20\n",
      "1251/1251 [==============================] - 40s 32ms/step - loss: 0.7988 - accuracy: 0.7307\n",
      "Epoch 10/20\n",
      "1251/1251 [==============================] - 38s 31ms/step - loss: 1.4449 - accuracy: 0.4857\n",
      "Epoch 11/20\n",
      "1251/1251 [==============================] - 39s 31ms/step - loss: 0.9727 - accuracy: 0.6649\n",
      "Epoch 12/20\n",
      "1251/1251 [==============================] - 39s 31ms/step - loss: 0.7885 - accuracy: 0.7380\n",
      "Epoch 13/20\n",
      "1251/1251 [==============================] - 38s 31ms/step - loss: 0.7191 - accuracy: 0.7607\n",
      "Epoch 14/20\n",
      "1251/1251 [==============================] - 40s 32ms/step - loss: 0.6826 - accuracy: 0.7757\n",
      "Epoch 15/20\n",
      "1251/1251 [==============================] - 38s 31ms/step - loss: 0.6319 - accuracy: 0.7949\n",
      "Epoch 16/20\n",
      "1251/1251 [==============================] - 40s 32ms/step - loss: 0.6044 - accuracy: 0.8050\n",
      "Epoch 17/20\n",
      "1251/1251 [==============================] - 38s 30ms/step - loss: 0.5746 - accuracy: 0.8153\n",
      "Epoch 18/20\n",
      "1251/1251 [==============================] - 40s 32ms/step - loss: 0.5267 - accuracy: 0.8327\n",
      "Epoch 19/20\n",
      "1251/1251 [==============================] - 38s 31ms/step - loss: 0.5017 - accuracy: 0.8416\n",
      "Epoch 20/20\n",
      "1251/1251 [==============================] - 38s 30ms/step - loss: 0.4590 - accuracy: 0.8553\n",
      "For  20  Epochs:\n",
      "Log-loss for Train Dataset =  0.46891705241841586\n",
      "Log-loss for Test Dataset =  1.0324562627567673\n",
      "Accuracy for Train Dataset =  0.8427235914612808\n",
      "Accuracy for Test Dataset =  0.7188\n",
      "\n",
      "Epoch 1/30\n",
      "1251/1251 [==============================] - 42s 32ms/step - loss: 0.4350 - accuracy: 0.8643\n",
      "Epoch 2/30\n",
      "1251/1251 [==============================] - 38s 31ms/step - loss: 0.5280 - accuracy: 0.8363\n",
      "Epoch 3/30\n",
      "1251/1251 [==============================] - 38s 31ms/step - loss: 0.4275 - accuracy: 0.8674\n",
      "Epoch 4/30\n",
      "1251/1251 [==============================] - 40s 32ms/step - loss: 0.3991 - accuracy: 0.8785\n",
      "Epoch 5/30\n",
      "1251/1251 [==============================] - 38s 30ms/step - loss: 0.3502 - accuracy: 0.8930\n",
      "Epoch 6/30\n",
      "1251/1251 [==============================] - 39s 31ms/step - loss: 0.3399 - accuracy: 0.8990\n",
      "Epoch 7/30\n",
      "1251/1251 [==============================] - 38s 31ms/step - loss: 0.3223 - accuracy: 0.9037\n",
      "Epoch 8/30\n",
      "1251/1251 [==============================] - 39s 32ms/step - loss: 0.3063 - accuracy: 0.9098\n",
      "Epoch 9/30\n",
      "1251/1251 [==============================] - 38s 31ms/step - loss: 0.3076 - accuracy: 0.9091\n",
      "Epoch 10/30\n",
      "1251/1251 [==============================] - 38s 31ms/step - loss: 0.2727 - accuracy: 0.9223\n",
      "Epoch 11/30\n",
      "1251/1251 [==============================] - 41s 33ms/step - loss: 0.2811 - accuracy: 0.9171\n",
      "Epoch 12/30\n",
      "1251/1251 [==============================] - 38s 31ms/step - loss: 0.2587 - accuracy: 0.9257\n",
      "Epoch 13/30\n",
      "1251/1251 [==============================] - 39s 31ms/step - loss: 0.2891 - accuracy: 0.9178\n",
      "Epoch 14/30\n",
      "1251/1251 [==============================] - 40s 32ms/step - loss: 0.2526 - accuracy: 0.9288\n",
      "Epoch 15/30\n",
      "1251/1251 [==============================] - 38s 31ms/step - loss: 0.2489 - accuracy: 0.9280\n",
      "Epoch 16/30\n",
      "1251/1251 [==============================] - 38s 31ms/step - loss: 0.2166 - accuracy: 0.9409\n",
      "Epoch 17/30\n",
      "1251/1251 [==============================] - 40s 32ms/step - loss: 0.2222 - accuracy: 0.9387\n",
      "Epoch 18/30\n",
      "1251/1251 [==============================] - 39s 31ms/step - loss: 0.2153 - accuracy: 0.9401\n",
      "Epoch 19/30\n",
      "1251/1251 [==============================] - 38s 31ms/step - loss: 0.2026 - accuracy: 0.9445\n",
      "Epoch 20/30\n",
      "1251/1251 [==============================] - 38s 30ms/step - loss: 0.2069 - accuracy: 0.9433\n",
      "Epoch 21/30\n",
      "1251/1251 [==============================] - 41s 33ms/step - loss: 0.2010 - accuracy: 0.9452\n",
      "Epoch 22/30\n",
      "1251/1251 [==============================] - 38s 30ms/step - loss: 0.1810 - accuracy: 0.9517\n",
      "Epoch 23/30\n",
      "1251/1251 [==============================] - 38s 31ms/step - loss: 0.2586 - accuracy: 0.9306\n",
      "Epoch 24/30\n",
      "1251/1251 [==============================] - 39s 31ms/step - loss: 0.2420 - accuracy: 0.9323\n",
      "Epoch 25/30\n",
      "1251/1251 [==============================] - 39s 32ms/step - loss: 0.2013 - accuracy: 0.9469\n",
      "Epoch 26/30\n",
      "1251/1251 [==============================] - 38s 31ms/step - loss: 0.1551 - accuracy: 0.9590\n",
      "Epoch 27/30\n",
      "1251/1251 [==============================] - 38s 31ms/step - loss: 0.1705 - accuracy: 0.9559\n",
      "Epoch 28/30\n",
      "1251/1251 [==============================] - 40s 32ms/step - loss: 0.1544 - accuracy: 0.9594\n",
      "Epoch 29/30\n",
      "1251/1251 [==============================] - 38s 30ms/step - loss: 0.1909 - accuracy: 0.9513\n",
      "Epoch 30/30\n",
      "1251/1251 [==============================] - 38s 31ms/step - loss: 0.1424 - accuracy: 0.9627\n",
      "For  30  Epochs:\n",
      "Log-loss for Train Dataset =  0.357037889916901\n",
      "Log-loss for Test Dataset =  1.6649410898320915\n",
      "Accuracy for Train Dataset =  0.9168124781282807\n",
      "Accuracy for Test Dataset =  0.7294\n",
      "\n",
      "Epoch 1/40\n",
      "1251/1251 [==============================] - 44s 32ms/step - loss: 0.1462 - accuracy: 0.9627\n",
      "Epoch 2/40\n",
      "1251/1251 [==============================] - 38s 31ms/step - loss: 0.1404 - accuracy: 0.9643\n",
      "Epoch 3/40\n",
      "1251/1251 [==============================] - 38s 31ms/step - loss: 0.1243 - accuracy: 0.9684\n",
      "Epoch 4/40\n",
      "1251/1251 [==============================] - 38s 31ms/step - loss: 0.1348 - accuracy: 0.9657\n",
      "Epoch 5/40\n",
      "1251/1251 [==============================] - 38s 31ms/step - loss: 0.1419 - accuracy: 0.9639\n",
      "Epoch 6/40\n",
      "1251/1251 [==============================] - 38s 30ms/step - loss: 0.1394 - accuracy: 0.9641\n",
      "Epoch 7/40\n",
      "1251/1251 [==============================] - 39s 31ms/step - loss: 0.1111 - accuracy: 0.9723\n",
      "Epoch 8/40\n",
      "1251/1251 [==============================] - 41s 33ms/step - loss: 0.1356 - accuracy: 0.9663\n",
      "Epoch 9/40\n",
      "1251/1251 [==============================] - 38s 31ms/step - loss: 0.1239 - accuracy: 0.9695\n",
      "Epoch 10/40\n",
      "1251/1251 [==============================] - 38s 31ms/step - loss: 0.1227 - accuracy: 0.9693\n",
      "Epoch 11/40\n",
      "1251/1251 [==============================] - 38s 30ms/step - loss: 0.1180 - accuracy: 0.9710\n",
      "Epoch 12/40\n",
      "1251/1251 [==============================] - 38s 31ms/step - loss: 0.1113 - accuracy: 0.9724\n",
      "Epoch 13/40\n",
      "1251/1251 [==============================] - 38s 31ms/step - loss: 0.1282 - accuracy: 0.9680\n",
      "Epoch 14/40\n",
      "1251/1251 [==============================] - 40s 32ms/step - loss: 0.1113 - accuracy: 0.9724\n",
      "Epoch 15/40\n",
      "1251/1251 [==============================] - 41s 33ms/step - loss: 0.1105 - accuracy: 0.9729\n",
      "Epoch 16/40\n",
      "1251/1251 [==============================] - 38s 30ms/step - loss: 0.1118 - accuracy: 0.9725\n",
      "Epoch 17/40\n",
      "1251/1251 [==============================] - 38s 31ms/step - loss: 0.1295 - accuracy: 0.9686\n",
      "Epoch 18/40\n",
      "1251/1251 [==============================] - 38s 31ms/step - loss: 0.1019 - accuracy: 0.9753\n",
      "Epoch 19/40\n",
      "1251/1251 [==============================] - 38s 30ms/step - loss: 0.1090 - accuracy: 0.9742\n",
      "Epoch 20/40\n",
      "1251/1251 [==============================] - 38s 31ms/step - loss: 0.0981 - accuracy: 0.9754\n",
      "Epoch 21/40\n",
      "1251/1251 [==============================] - 39s 31ms/step - loss: 0.0988 - accuracy: 0.9755\n",
      "Epoch 22/40\n",
      "1251/1251 [==============================] - 42s 33ms/step - loss: 0.1171 - accuracy: 0.9728\n",
      "Epoch 23/40\n",
      "1251/1251 [==============================] - 38s 30ms/step - loss: 0.1082 - accuracy: 0.9737\n",
      "Epoch 24/40\n",
      "1251/1251 [==============================] - 39s 31ms/step - loss: 0.0787 - accuracy: 0.9815\n",
      "Epoch 25/40\n",
      "1251/1251 [==============================] - 38s 30ms/step - loss: 0.1125 - accuracy: 0.9727\n",
      "Epoch 26/40\n",
      "1251/1251 [==============================] - 38s 31ms/step - loss: 0.0863 - accuracy: 0.9794\n",
      "Epoch 27/40\n",
      "1251/1251 [==============================] - 39s 31ms/step - loss: 0.0804 - accuracy: 0.9798\n",
      "Epoch 28/40\n",
      "1251/1251 [==============================] - 41s 33ms/step - loss: 0.0917 - accuracy: 0.9781\n",
      "Epoch 29/40\n",
      "1251/1251 [==============================] - 38s 31ms/step - loss: 0.0917 - accuracy: 0.9782\n",
      "Epoch 30/40\n",
      "1251/1251 [==============================] - 38s 31ms/step - loss: 0.0852 - accuracy: 0.9789\n",
      "Epoch 31/40\n",
      "1251/1251 [==============================] - 39s 31ms/step - loss: 0.0868 - accuracy: 0.9802\n",
      "Epoch 32/40\n",
      "1251/1251 [==============================] - 38s 31ms/step - loss: 0.0840 - accuracy: 0.9804\n",
      "Epoch 33/40\n",
      "1251/1251 [==============================] - 38s 31ms/step - loss: 0.0957 - accuracy: 0.9772\n",
      "Epoch 34/40\n",
      "1251/1251 [==============================] - 39s 31ms/step - loss: 0.0813 - accuracy: 0.9812\n",
      "Epoch 35/40\n",
      "1251/1251 [==============================] - 42s 33ms/step - loss: 0.0776 - accuracy: 0.9822\n",
      "Epoch 36/40\n",
      "1251/1251 [==============================] - 39s 31ms/step - loss: 0.1470 - accuracy: 0.9658\n",
      "Epoch 37/40\n",
      "1251/1251 [==============================] - 38s 31ms/step - loss: 0.0808 - accuracy: 0.9817\n",
      "Epoch 38/40\n",
      "1251/1251 [==============================] - 38s 31ms/step - loss: 0.0731 - accuracy: 0.9838\n",
      "Epoch 39/40\n",
      "1251/1251 [==============================] - 39s 31ms/step - loss: 0.0794 - accuracy: 0.9815\n",
      "Epoch 40/40\n",
      "1251/1251 [==============================] - 38s 31ms/step - loss: 0.0716 - accuracy: 0.9834\n",
      "For  40  Epochs:\n",
      "Log-loss for Train Dataset =  0.03491503474707017\n",
      "Log-loss for Test Dataset =  1.283587010100124\n",
      "Accuracy for Train Dataset =  0.9912263160525921\n",
      "Accuracy for Test Dataset =  0.7982\n",
      "\n",
      "Epoch 1/50\n",
      "1251/1251 [==============================] - 43s 32ms/step - loss: 0.0761 - accuracy: 0.9827\n",
      "Epoch 2/50\n",
      "1251/1251 [==============================] - 38s 31ms/step - loss: 0.0737 - accuracy: 0.9840\n",
      "Epoch 3/50\n",
      "1251/1251 [==============================] - 38s 31ms/step - loss: 0.0903 - accuracy: 0.9790\n",
      "Epoch 4/50\n",
      "1251/1251 [==============================] - 38s 30ms/step - loss: 0.0669 - accuracy: 0.9855\n",
      "Epoch 5/50\n",
      "1251/1251 [==============================] - 38s 31ms/step - loss: 0.0761 - accuracy: 0.9831\n",
      "Epoch 6/50\n",
      "1251/1251 [==============================] - 38s 30ms/step - loss: 0.0632 - accuracy: 0.9853\n",
      "Epoch 7/50\n",
      "1251/1251 [==============================] - 41s 32ms/step - loss: 0.0669 - accuracy: 0.9846\n",
      "Epoch 8/50\n",
      "1251/1251 [==============================] - 42s 33ms/step - loss: 0.0764 - accuracy: 0.9823\n",
      "Epoch 9/50\n",
      "1251/1251 [==============================] - 38s 30ms/step - loss: 0.0680 - accuracy: 0.9852\n",
      "Epoch 10/50\n",
      "1251/1251 [==============================] - 38s 31ms/step - loss: 0.0696 - accuracy: 0.9841\n",
      "Epoch 11/50\n",
      "1251/1251 [==============================] - 38s 30ms/step - loss: 0.0814 - accuracy: 0.9818\n",
      "Epoch 12/50\n",
      "1251/1251 [==============================] - 38s 31ms/step - loss: 0.0615 - accuracy: 0.9858\n",
      "Epoch 13/50\n",
      "1251/1251 [==============================] - 38s 31ms/step - loss: 0.0583 - accuracy: 0.9867\n",
      "Epoch 14/50\n",
      "1251/1251 [==============================] - 39s 31ms/step - loss: 0.0652 - accuracy: 0.9851\n",
      "Epoch 15/50\n",
      "1251/1251 [==============================] - 42s 34ms/step - loss: 0.0661 - accuracy: 0.9849\n",
      "Epoch 16/50\n",
      "1251/1251 [==============================] - 38s 31ms/step - loss: 0.0559 - accuracy: 0.9871\n",
      "Epoch 17/50\n",
      "1251/1251 [==============================] - 38s 31ms/step - loss: 0.0596 - accuracy: 0.9866\n",
      "Epoch 18/50\n",
      "1251/1251 [==============================] - 38s 30ms/step - loss: 0.0735 - accuracy: 0.9834\n",
      "Epoch 19/50\n",
      "1251/1251 [==============================] - 39s 31ms/step - loss: 0.0515 - accuracy: 0.9887\n",
      "Epoch 20/50\n",
      "1251/1251 [==============================] - 38s 31ms/step - loss: 0.0622 - accuracy: 0.9856\n",
      "Epoch 21/50\n",
      "1251/1251 [==============================] - 38s 31ms/step - loss: 0.0862 - accuracy: 0.9813\n",
      "Epoch 22/50\n",
      "1251/1251 [==============================] - 38s 31ms/step - loss: 0.0540 - accuracy: 0.9878\n",
      "Epoch 23/50\n",
      "1251/1251 [==============================] - 38s 30ms/step - loss: 0.0546 - accuracy: 0.9873\n",
      "Epoch 24/50\n",
      "1251/1251 [==============================] - 38s 31ms/step - loss: 0.0530 - accuracy: 0.9881\n",
      "Epoch 25/50\n",
      "1251/1251 [==============================] - 38s 31ms/step - loss: 0.0830 - accuracy: 0.9817\n",
      "Epoch 26/50\n",
      "1251/1251 [==============================] - 38s 30ms/step - loss: 0.0475 - accuracy: 0.9895\n",
      "Epoch 27/50\n",
      "1251/1251 [==============================] - 42s 33ms/step - loss: 0.0539 - accuracy: 0.9884\n",
      "Epoch 28/50\n",
      "1251/1251 [==============================] - 39s 31ms/step - loss: 0.0776 - accuracy: 0.9830\n",
      "Epoch 29/50\n",
      "1251/1251 [==============================] - 38s 31ms/step - loss: 0.0548 - accuracy: 0.9876\n",
      "Epoch 30/50\n",
      "1251/1251 [==============================] - 38s 31ms/step - loss: 0.0567 - accuracy: 0.9870\n",
      "Epoch 31/50\n",
      "1251/1251 [==============================] - 38s 31ms/step - loss: 0.0541 - accuracy: 0.9875\n",
      "Epoch 32/50\n",
      "1251/1251 [==============================] - 38s 31ms/step - loss: 0.0539 - accuracy: 0.9879\n",
      "Epoch 33/50\n",
      "1251/1251 [==============================] - 38s 31ms/step - loss: 0.0588 - accuracy: 0.9870\n",
      "Epoch 34/50\n",
      "1251/1251 [==============================] - 38s 31ms/step - loss: 0.0462 - accuracy: 0.9899\n",
      "Epoch 35/50\n",
      "1251/1251 [==============================] - 38s 30ms/step - loss: 0.0761 - accuracy: 0.9825\n",
      "Epoch 36/50\n",
      "1251/1251 [==============================] - 38s 30ms/step - loss: 0.0469 - accuracy: 0.9889\n",
      "Epoch 37/50\n",
      "1251/1251 [==============================] - 39s 31ms/step - loss: 0.0512 - accuracy: 0.9890\n",
      "Epoch 38/50\n",
      "1251/1251 [==============================] - 38s 31ms/step - loss: 0.0546 - accuracy: 0.9884\n",
      "Epoch 39/50\n",
      "1251/1251 [==============================] - 40s 32ms/step - loss: 0.0506 - accuracy: 0.9891\n",
      "Epoch 40/50\n",
      "1251/1251 [==============================] - 42s 34ms/step - loss: 0.0751 - accuracy: 0.9824\n",
      "Epoch 41/50\n",
      "1251/1251 [==============================] - 39s 31ms/step - loss: 0.0515 - accuracy: 0.9877\n",
      "Epoch 42/50\n",
      "1251/1251 [==============================] - 38s 31ms/step - loss: 0.0427 - accuracy: 0.9904\n",
      "Epoch 43/50\n",
      "1251/1251 [==============================] - 38s 31ms/step - loss: 0.0682 - accuracy: 0.9844\n",
      "Epoch 44/50\n",
      "1251/1251 [==============================] - 38s 31ms/step - loss: 0.0388 - accuracy: 0.9913\n",
      "Epoch 45/50\n",
      "1251/1251 [==============================] - 38s 31ms/step - loss: 0.0456 - accuracy: 0.9899\n",
      "Epoch 46/50\n",
      "1251/1251 [==============================] - 38s 31ms/step - loss: 0.0651 - accuracy: 0.9860\n",
      "Epoch 47/50\n",
      "1251/1251 [==============================] - 38s 30ms/step - loss: 0.0369 - accuracy: 0.9916\n",
      "Epoch 48/50\n",
      "1251/1251 [==============================] - 38s 31ms/step - loss: 0.0445 - accuracy: 0.9900\n",
      "Epoch 49/50\n",
      "1251/1251 [==============================] - 38s 31ms/step - loss: 0.0451 - accuracy: 0.9905\n",
      "Epoch 50/50\n",
      "1251/1251 [==============================] - 38s 31ms/step - loss: 0.0597 - accuracy: 0.9874\n",
      "For  50  Epochs:\n",
      "Log-loss for Train Dataset =  0.04090993619292738\n",
      "Log-loss for Test Dataset =  1.4976596719558481\n",
      "Accuracy for Train Dataset =  0.9898765185222217\n",
      "Accuracy for Test Dataset =  0.7998\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((df_train, y_train_oh)).batch(32)\n",
    "num_epochs = [10, 20, 30, 40, 50]\n",
    "train_loss, test_loss, train_acc, test_acc = [], [], [], []\n",
    "\n",
    "for epochs in num_epochs:\n",
    "    # Training the Model\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics='accuracy')\n",
    "    model.fit(train_dataset, epochs = epochs)\n",
    "    \n",
    "    # Predicting on the Train/Test Datasets\n",
    "    preds_train = model.predict(df_train)\n",
    "    preds_test = model.predict(df_test)\n",
    "\n",
    "    # Finding the Predicted Classes\n",
    "    cls_train = np.argmax(preds_train, axis = 1)\n",
    "    cls_test = np.argmax(preds_test, axis = 1)\n",
    "    \n",
    "    # Finding the Train/Test set Loss\n",
    "    train_loss.append(log_loss(y_train_oh, preds_train))\n",
    "    test_loss.append(log_loss(y_test_oh, preds_test))\n",
    "    train_acc.append(accuracy_score(y_train, cls_train))\n",
    "    test_acc.append(accuracy_score(y_test, cls_test))\n",
    "    \n",
    "    print(\"For \", epochs, \" Epochs:\")\n",
    "    print(\"Log-loss for Train Dataset = \", train_loss[-1])\n",
    "    print(\"Log-loss for Test Dataset = \", test_loss[-1])\n",
    "    print(\"Accuracy for Train Dataset = \", train_acc[-1])\n",
    "    print(\"Accuracy for Test Dataset = \", test_acc[-1])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "859c2eef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-09T17:15:39.928961Z",
     "iopub.status.busy": "2022-04-09T17:15:39.925503Z",
     "iopub.status.idle": "2022-04-09T17:52:05.796338Z",
     "shell.execute_reply": "2022-04-09T17:52:05.604920Z"
    },
    "papermill": {
     "duration": 2225.88683,
     "end_time": "2022-04-09T17:52:05.796642",
     "exception": false,
     "start_time": "2022-04-09T17:14:59.909812",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1251/1251 [==============================] - 41s 30ms/step - loss: 0.0488 - accuracy: 0.9893\n",
      "Epoch 2/50\n",
      "1251/1251 [==============================] - 38s 31ms/step - loss: 0.0448 - accuracy: 0.9905\n",
      "Epoch 3/50\n",
      "1251/1251 [==============================] - 38s 31ms/step - loss: 0.0538 - accuracy: 0.9889\n",
      "Epoch 4/50\n",
      "1251/1251 [==============================] - 38s 31ms/step - loss: 0.0441 - accuracy: 0.9906\n",
      "Epoch 5/50\n",
      "1251/1251 [==============================] - 38s 31ms/step - loss: 0.0719 - accuracy: 0.9852\n",
      "Epoch 6/50\n",
      "1251/1251 [==============================] - 38s 31ms/step - loss: 0.0344 - accuracy: 0.9925\n",
      "Epoch 7/50\n",
      "1251/1251 [==============================] - 38s 31ms/step - loss: 0.0430 - accuracy: 0.9908\n",
      "Epoch 8/50\n",
      "1251/1251 [==============================] - 38s 31ms/step - loss: 0.0361 - accuracy: 0.9920\n",
      "Epoch 9/50\n",
      "1251/1251 [==============================] - 38s 31ms/step - loss: 0.0478 - accuracy: 0.9895\n",
      "Epoch 10/50\n",
      "1251/1251 [==============================] - 38s 31ms/step - loss: 0.0435 - accuracy: 0.9905\n",
      "Epoch 11/50\n",
      "1251/1251 [==============================] - 38s 31ms/step - loss: 0.0500 - accuracy: 0.9892\n",
      "Epoch 12/50\n",
      "1251/1251 [==============================] - 38s 31ms/step - loss: 0.0472 - accuracy: 0.9897\n",
      "Epoch 13/50\n",
      "1251/1251 [==============================] - 42s 34ms/step - loss: 0.0398 - accuracy: 0.9910\n",
      "Epoch 14/50\n",
      "1251/1251 [==============================] - 38s 31ms/step - loss: 0.0528 - accuracy: 0.9889\n",
      "Epoch 15/50\n",
      "1251/1251 [==============================] - 38s 31ms/step - loss: 0.0330 - accuracy: 0.9928\n",
      "Epoch 16/50\n",
      "1251/1251 [==============================] - 38s 31ms/step - loss: 0.0378 - accuracy: 0.9912\n",
      "Epoch 17/50\n",
      "1251/1251 [==============================] - 39s 31ms/step - loss: 0.0675 - accuracy: 0.9858\n",
      "Epoch 18/50\n",
      "1251/1251 [==============================] - 38s 31ms/step - loss: 0.0239 - accuracy: 0.9954\n",
      "Epoch 19/50\n",
      "1251/1251 [==============================] - 38s 30ms/step - loss: 0.0486 - accuracy: 0.9895\n",
      "Epoch 20/50\n",
      "1251/1251 [==============================] - 38s 30ms/step - loss: 0.0591 - accuracy: 0.9875\n",
      "Epoch 21/50\n",
      "1251/1251 [==============================] - 38s 30ms/step - loss: 0.0351 - accuracy: 0.9929\n",
      "Epoch 22/50\n",
      "1251/1251 [==============================] - 38s 30ms/step - loss: 0.0484 - accuracy: 0.9902\n",
      "Epoch 23/50\n",
      "1251/1251 [==============================] - 38s 30ms/step - loss: 0.0403 - accuracy: 0.9917\n",
      "Epoch 24/50\n",
      "1251/1251 [==============================] - 38s 31ms/step - loss: 0.0399 - accuracy: 0.9914\n",
      "Epoch 25/50\n",
      "1251/1251 [==============================] - 40s 32ms/step - loss: 0.0471 - accuracy: 0.9894\n",
      "Epoch 26/50\n",
      "1251/1251 [==============================] - 38s 30ms/step - loss: 0.0286 - accuracy: 0.9934\n",
      "Epoch 27/50\n",
      "1251/1251 [==============================] - 38s 30ms/step - loss: 0.0398 - accuracy: 0.9915\n",
      "Epoch 28/50\n",
      "1251/1251 [==============================] - 38s 30ms/step - loss: 0.0436 - accuracy: 0.9905\n",
      "Epoch 29/50\n",
      "1251/1251 [==============================] - 38s 30ms/step - loss: 0.0392 - accuracy: 0.9917\n",
      "Epoch 30/50\n",
      "1251/1251 [==============================] - 38s 31ms/step - loss: 0.0411 - accuracy: 0.9905\n",
      "Epoch 31/50\n",
      "1251/1251 [==============================] - 38s 31ms/step - loss: 0.0442 - accuracy: 0.9908\n",
      "Epoch 32/50\n",
      "1251/1251 [==============================] - 38s 30ms/step - loss: 0.0349 - accuracy: 0.9924\n",
      "Epoch 33/50\n",
      "1251/1251 [==============================] - 38s 31ms/step - loss: 0.0337 - accuracy: 0.9926\n",
      "Epoch 34/50\n",
      "1251/1251 [==============================] - 38s 31ms/step - loss: 0.0363 - accuracy: 0.9926\n",
      "Epoch 35/50\n",
      "1251/1251 [==============================] - 39s 31ms/step - loss: 0.0336 - accuracy: 0.9930\n",
      "Epoch 36/50\n",
      "1251/1251 [==============================] - 39s 31ms/step - loss: 0.0530 - accuracy: 0.9893\n",
      "Epoch 37/50\n",
      "1251/1251 [==============================] - 39s 32ms/step - loss: 0.0307 - accuracy: 0.9939\n",
      "Epoch 38/50\n",
      "1251/1251 [==============================] - 43s 35ms/step - loss: 0.0400 - accuracy: 0.9911\n",
      "Epoch 39/50\n",
      "1251/1251 [==============================] - 38s 31ms/step - loss: 0.0399 - accuracy: 0.9918\n",
      "Epoch 40/50\n",
      "1251/1251 [==============================] - 38s 31ms/step - loss: 0.0378 - accuracy: 0.9921\n",
      "Epoch 41/50\n",
      "1251/1251 [==============================] - 38s 31ms/step - loss: 0.0377 - accuracy: 0.9922\n",
      "Epoch 42/50\n",
      "1251/1251 [==============================] - 38s 31ms/step - loss: 0.0374 - accuracy: 0.9922\n",
      "Epoch 43/50\n",
      "1251/1251 [==============================] - 38s 31ms/step - loss: 0.0460 - accuracy: 0.9902\n",
      "Epoch 44/50\n",
      "1251/1251 [==============================] - 38s 31ms/step - loss: 0.0390 - accuracy: 0.9919\n",
      "Epoch 45/50\n",
      "1251/1251 [==============================] - 38s 31ms/step - loss: 0.0298 - accuracy: 0.9931\n",
      "Epoch 46/50\n",
      "1251/1251 [==============================] - 39s 31ms/step - loss: 0.0367 - accuracy: 0.9920\n",
      "Epoch 47/50\n",
      "1251/1251 [==============================] - 38s 31ms/step - loss: 0.0331 - accuracy: 0.9932\n",
      "Epoch 48/50\n",
      "1251/1251 [==============================] - 39s 31ms/step - loss: 0.0353 - accuracy: 0.9926\n",
      "Epoch 49/50\n",
      "1251/1251 [==============================] - 39s 31ms/step - loss: 0.0411 - accuracy: 0.9914\n",
      "Epoch 50/50\n",
      "1251/1251 [==============================] - 39s 31ms/step - loss: 0.0291 - accuracy: 0.9936\n"
     ]
    }
   ],
   "source": [
    "# Training the Model with the best hyper-parameter settings\n",
    "ind = np.argmax(test_acc)\n",
    "best_num_epochs = num_epochs[ind]\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics='accuracy')\n",
    "model.fit(train_dataset, epochs = best_num_epochs)\n",
    "\n",
    "# Saving the model along with it's weights\n",
    "model.save('vgg16_model.h5')\n",
    "model = tf.keras.models.load_model('./vgg16_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d61cd0",
   "metadata": {
    "papermill": {
     "duration": 53.791648,
     "end_time": "2022-04-09T17:53:53.470348",
     "exception": false,
     "start_time": "2022-04-09T17:52:59.678700",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Prediction and evaluation on train/test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c99b50d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-09T17:55:39.889602Z",
     "iopub.status.busy": "2022-04-09T17:55:39.888556Z",
     "iopub.status.idle": "2022-04-09T17:55:54.463565Z",
     "shell.execute_reply": "2022-04-09T17:55:54.462409Z",
     "shell.execute_reply.started": "2022-03-12T17:25:38.835945Z"
    },
    "papermill": {
     "duration": 66.942179,
     "end_time": "2022-04-09T17:55:54.463731",
     "exception": false,
     "start_time": "2022-04-09T17:54:47.521552",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Predicting on the Train/Test Datasets\n",
    "preds_train = model.predict(df_train)\n",
    "preds_test = model.predict(df_test)\n",
    "\n",
    "# Finding the Predicted Classes\n",
    "cls_train = np.argmax(preds_train, axis = 1)\n",
    "cls_test = np.argmax(preds_test, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3fd02ee3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-09T17:57:41.128741Z",
     "iopub.status.busy": "2022-04-09T17:57:41.127701Z",
     "iopub.status.idle": "2022-04-09T17:57:41.203392Z",
     "shell.execute_reply": "2022-04-09T17:57:41.203997Z",
     "shell.execute_reply.started": "2022-03-12T17:25:52.178675Z"
    },
    "papermill": {
     "duration": 53.075819,
     "end_time": "2022-04-09T17:57:41.204149",
     "exception": false,
     "start_time": "2022-04-09T17:56:48.128330",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log-loss for Train Dataset =  0.04047456631034915\n",
      "Log-loss for Test Dataset =  1.682173362733447\n",
      "Accuracy for Train Dataset =  0.9916762485627156\n",
      "Accuracy for Test Dataset =  0.7992\n"
     ]
    }
   ],
   "source": [
    "# Finding the Train/Test set Loss\n",
    "print(\"Log-loss for Train Dataset = \", log_loss(y_train_oh, preds_train))\n",
    "print(\"Log-loss for Test Dataset = \", log_loss(y_test_oh, preds_test))\n",
    "print(\"Accuracy for Train Dataset = \", accuracy_score(y_train, cls_train))\n",
    "print(\"Accuracy for Test Dataset = \", accuracy_score(y_test, cls_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 9174.835974,
   "end_time": "2022-04-09T17:58:38.935958",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-04-09T15:25:44.099984",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
