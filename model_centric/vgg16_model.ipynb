{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# VGG16\n- CIFAR10 dataset is used to train the pre-trained model VGG16. \n- Only the labelled dataset is used in this model.\n- Fine-tuning of the model is also done, through freezing the layer, adding new layers to the model etc.","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"markdown","source":"## Importing the Packages","metadata":{}},{"cell_type":"code","source":"import os\nimport sys\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom tqdm import tqdm\nfrom tabulate import tabulate\nfrom sklearn.metrics import accuracy_score, log_loss\n\n# https://www.kaggle.com/c/ventilator-pressure-prediction/discussion/274717\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n\nimport tensorflow as tf\nimport keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.applications import VGG16","metadata":{"execution":{"iopub.status.busy":"2022-03-12T17:17:36.285418Z","iopub.execute_input":"2022-03-12T17:17:36.285727Z","iopub.status.idle":"2022-03-12T17:17:41.887331Z","shell.execute_reply.started":"2022-03-12T17:17:36.285622Z","shell.execute_reply":"2022-03-12T17:17:41.886567Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# Making sure that Tensorflow is able to detect the GPU\ndevice_name = tf.test.gpu_device_name()\nif \"GPU\" not in device_name:\n    print(\"GPU device not found\")\nprint('Found GPU at: {}'.format(device_name))","metadata":{"execution":{"iopub.status.busy":"2022-03-12T17:17:41.890162Z","iopub.execute_input":"2022-03-12T17:17:41.890687Z","iopub.status.idle":"2022-03-12T17:17:43.563678Z","shell.execute_reply.started":"2022-03-12T17:17:41.890648Z","shell.execute_reply":"2022-03-12T17:17:43.562778Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# These are the usual ipython objects\nipython_vars = ['In', 'Out', 'exit', 'quit', 'get_ipython', 'ipython_vars']\n\n# Defining a function to list the memory consumed\n# Only outputs variables taking at least 1MB space\ndef list_storage(inp_dir):\n    # Get a sorted list of the objects and their sizes\n    vars_defined = [x for x in inp_dir if not x.startswith('_') and x not in sys.modules and x not in ipython_vars]\n    sto = sorted([(x, sys.getsizeof(globals().get(x))) for x in vars_defined], key=lambda x: x[1], reverse=True)\n    sto = [(x[0], str(round((x[1] / 2**20), 2)) + ' MB') for x in sto if x[1] >= 2**20]\n    print(tabulate(sto, headers = ['Variable', 'Storage (in MB)']))\n\n# In order to use this function, use the below line of code\n# list_storage(dir())","metadata":{"execution":{"iopub.status.busy":"2022-03-12T17:17:43.564917Z","iopub.execute_input":"2022-03-12T17:17:43.565279Z","iopub.status.idle":"2022-03-12T17:17:43.583599Z","shell.execute_reply.started":"2022-03-12T17:17:43.565245Z","shell.execute_reply":"2022-03-12T17:17:43.582849Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Importing the Labelled Dataset\ndf_train = pd.read_csv(\"../input/cifar10/train_lab_x.csv\")\ny_train = pd.read_csv(\"../input/cifar10/train_lab_y.csv\")\n\n# Importing the Test Dataset\ndf_test = pd.read_csv(\"../input/cifar10/test_x.csv\")\ny_test = pd.read_csv(\"../input/cifar10/test_y.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-03-12T17:17:43.586414Z","iopub.execute_input":"2022-03-12T17:17:43.586754Z","iopub.status.idle":"2022-03-12T17:18:10.601065Z","shell.execute_reply.started":"2022-03-12T17:17:43.586646Z","shell.execute_reply":"2022-03-12T17:18:10.600289Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"## Basic Pre-processing","metadata":{}},{"cell_type":"code","source":"df_train = np.array(df_train)\ny_train = np.array(y_train)\nprint(df_train.shape, y_train.shape)\n\n# Reshaping the dataset\ndf_train = np.reshape(df_train, (-1, 3, 32, 32))\nprint(df_train.shape)\n\n# Visualizing a single image\nind = 89\nexample = df_train[ind, : , : , : ]\nexample = example.transpose((1, 2, 0))\nplt.figure(figsize=(1.5, 1.5))\nplt.imshow(example)\nprint(y_train[ind])","metadata":{"execution":{"iopub.status.busy":"2022-03-12T17:18:10.602222Z","iopub.execute_input":"2022-03-12T17:18:10.602467Z","iopub.status.idle":"2022-03-12T17:18:11.127482Z","shell.execute_reply.started":"2022-03-12T17:18:10.602434Z","shell.execute_reply":"2022-03-12T17:18:11.126764Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Creating a random permutation\nperm = np.random.permutation(df_train.shape[0])\n\n# Shuffling the training dataset\ndf_train = df_train[perm, : , : , : ]\ny_train = y_train[perm]\n\n# Reshaping, rescaling and one-hot encoding\ndf_train = np.transpose(np.array(df_train), (0, 2, 3, 1))\ndf_train = df_train / 255\ny_train_oh = tf.one_hot(np.ravel(y_train), depth = 10)\n\nprint(df_train.shape, y_train_oh.shape)","metadata":{"execution":{"iopub.status.busy":"2022-03-12T17:18:11.128616Z","iopub.execute_input":"2022-03-12T17:18:11.129232Z","iopub.status.idle":"2022-03-12T17:18:13.557596Z","shell.execute_reply.started":"2022-03-12T17:18:11.129192Z","shell.execute_reply":"2022-03-12T17:18:13.556498Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"df_test = np.array(df_test)\ny_test = np.array(y_test)\nprint(df_test.shape, y_test.shape)\n\n# Reshaping the dataset\ndf_test = np.reshape(df_test, (-1, 3, 32, 32))\nprint(df_test.shape)\n\n# Reshaping, rescaling and one-hot encoding\ndf_test = np.transpose(np.array(df_test), (0, 2, 3, 1))\ndf_test = df_test / 255\ny_test_oh = tf.one_hot(np.ravel(y_test), depth = 10)\nprint(df_test.shape, y_test_oh.shape)","metadata":{"execution":{"iopub.status.busy":"2022-03-12T17:18:13.559171Z","iopub.execute_input":"2022-03-12T17:18:13.559423Z","iopub.status.idle":"2022-03-12T17:18:13.896424Z","shell.execute_reply.started":"2022-03-12T17:18:13.559388Z","shell.execute_reply":"2022-03-12T17:18:13.895647Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"## Building the Model","metadata":{}},{"cell_type":"code","source":"input_t = tf.keras.Input(shape = (64,64,3))\nvgg_model = VGG16(weights='imagenet', include_top=False, input_tensor=input_t,\n                             pooling='max')\nvgg_model.summary()","metadata":{"scrolled":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-03-12T17:18:13.897757Z","iopub.execute_input":"2022-03-12T17:18:13.898008Z","iopub.status.idle":"2022-03-12T17:18:14.828469Z","shell.execute_reply.started":"2022-03-12T17:18:13.897972Z","shell.execute_reply":"2022-03-12T17:18:14.827750Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"for layer in vgg_model.layers:\n    layer.trainable = True\n\nfor i, layer in enumerate(vgg_model.layers):\n    print(i, layer.name, \"-\", layer.trainable)","metadata":{"scrolled":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-03-12T17:18:14.829805Z","iopub.execute_input":"2022-03-12T17:18:14.830056Z","iopub.status.idle":"2022-03-12T17:18:14.845407Z","shell.execute_reply.started":"2022-03-12T17:18:14.830020Z","shell.execute_reply":"2022-03-12T17:18:14.844429Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"to_res = (64,64)\nmodel = tf.keras.models.Sequential()\nmodel.add(layers.Lambda(lambda image: tf.image.resize(image, to_res))) \nmodel.add(vgg_model)\nmodel.add(layers.Flatten())\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.Dense(256, activation='relu'))\nmodel.add(layers.Dropout(0.5))\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.Dense(128, activation='relu'))\nmodel.add(layers.Dropout(0.5))\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.Dense(64, activation='relu'))\nmodel.add(layers.Dropout(0.5))\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.Dense(10, activation='softmax'))","metadata":{"execution":{"iopub.status.busy":"2022-03-12T17:18:14.846403Z","iopub.execute_input":"2022-03-12T17:18:14.846630Z","iopub.status.idle":"2022-03-12T17:18:14.875731Z","shell.execute_reply.started":"2022-03-12T17:18:14.846598Z","shell.execute_reply":"2022-03-12T17:18:14.875068Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"## Compiling and Training the Model","metadata":{}},{"cell_type":"code","source":"#compiling model \nloss = 'categorical_crossentropy'\nopt = tf.keras.optimizers.Adam(learning_rate=2e-5)\nmetrics = ['accuracy']\n\nmodel.compile(loss = loss, optimizer = opt, metrics = metrics)","metadata":{"scrolled":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-03-12T17:18:14.878100Z","iopub.execute_input":"2022-03-12T17:18:14.878424Z","iopub.status.idle":"2022-03-12T17:18:14.892689Z","shell.execute_reply.started":"2022-03-12T17:18:14.878388Z","shell.execute_reply":"2022-03-12T17:18:14.892024Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"train_dataset = tf.data.Dataset.from_tensor_slices((df_train, y_train_oh)).batch(32)\nhistory = model.fit(train_dataset, epochs = 10)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-03-12T17:18:14.893949Z","iopub.execute_input":"2022-03-12T17:18:14.894195Z","iopub.status.idle":"2022-03-12T17:25:38.010869Z","shell.execute_reply.started":"2022-03-12T17:18:14.894162Z","shell.execute_reply":"2022-03-12T17:25:38.010188Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"model.save('vgg16_model.h5')\nmodel = tf.keras.models.load_model('./vgg16_model.h5')","metadata":{"execution":{"iopub.status.busy":"2022-03-12T17:25:38.012327Z","iopub.execute_input":"2022-03-12T17:25:38.012588Z","iopub.status.idle":"2022-03-12T17:25:38.834506Z","shell.execute_reply.started":"2022-03-12T17:25:38.012552Z","shell.execute_reply":"2022-03-12T17:25:38.833755Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"## Prediction","metadata":{}},{"cell_type":"code","source":"# Predicting on the Train/Test Datasets\npreds_train = model.predict(df_train)\npreds_test = model.predict(df_test)\n\n# Finding the Predicted Classes\ntrain_cls = np.argmax(preds_train, axis = 1)\ntest_cls = np.argmax(preds_test, axis = 1)","metadata":{"execution":{"iopub.status.busy":"2022-03-12T17:25:38.835740Z","iopub.execute_input":"2022-03-12T17:25:38.835978Z","iopub.status.idle":"2022-03-12T17:25:52.175518Z","shell.execute_reply.started":"2022-03-12T17:25:38.835945Z","shell.execute_reply":"2022-03-12T17:25:52.174765Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# Finding the Train/Test set Loss\nprint(\"Log-loss for Train Dataset = \", log_loss(y_train_oh, preds_train))\nprint(\"Log-loss for Test Dataset = \", log_loss(y_test_oh, preds_test))\nprint(\"Accuracy for Train Dataset = \", accuracy_score(y_train, train_cls))\nprint(\"Accuracy for Test Dataset = \", accuracy_score(y_test, test_cls))","metadata":{"execution":{"iopub.status.busy":"2022-03-12T17:25:52.178469Z","iopub.execute_input":"2022-03-12T17:25:52.178720Z","iopub.status.idle":"2022-03-12T17:25:52.251061Z","shell.execute_reply.started":"2022-03-12T17:25:52.178675Z","shell.execute_reply":"2022-03-12T17:25:52.250354Z"},"trusted":true},"execution_count":15,"outputs":[]}]}