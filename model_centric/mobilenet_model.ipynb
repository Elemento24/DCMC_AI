{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "817f9a0a",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 0.027112,
     "end_time": "2022-04-09T11:21:08.293362",
     "exception": false,
     "start_time": "2022-04-09T11:21:08.266250",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# MobileNet\n",
    "- CIFAR10 dataset is used to train the pre-trained model **MobileNet**. \n",
    "- Only the labelled dataset is used in this model.\n",
    "- Fine-tuning of the model is also done, through freezing the layer, adding new layers to the model etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74cdf59f",
   "metadata": {
    "papermill": {
     "duration": 0.021669,
     "end_time": "2022-04-09T11:21:08.346914",
     "exception": false,
     "start_time": "2022-04-09T11:21:08.325245",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Importing the Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "766750e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-09T11:21:08.405793Z",
     "iopub.status.busy": "2022-04-09T11:21:08.404958Z",
     "iopub.status.idle": "2022-04-09T11:21:14.314638Z",
     "shell.execute_reply": "2022-04-09T11:21:14.314008Z",
     "shell.execute_reply.started": "2022-03-11T10:39:58.871693Z"
    },
    "papermill": {
     "duration": 5.942924,
     "end_time": "2022-04-09T11:21:14.314801",
     "exception": false,
     "start_time": "2022-04-09T11:21:08.371877",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from tabulate import tabulate\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "\n",
    "# https://www.kaggle.com/c/ventilator-pressure-prediction/discussion/274717\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.applications import  MobileNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65109c49",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-09T11:21:16.314846Z",
     "iopub.status.busy": "2022-04-09T11:21:16.313947Z",
     "iopub.status.idle": "2022-04-09T11:21:16.317519Z",
     "shell.execute_reply": "2022-04-09T11:21:16.317920Z",
     "shell.execute_reply.started": "2022-03-11T10:39:59.84454Z"
    },
    "papermill": {
     "duration": 1.987197,
     "end_time": "2022-04-09T11:21:16.318059",
     "exception": false,
     "start_time": "2022-04-09T11:21:14.330862",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU at: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "# Making sure that Tensorflow is able to detect the GPU\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if \"GPU\" not in device_name:\n",
    "    print(\"GPU device not found\")\n",
    "print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d4f65de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-09T11:21:16.357990Z",
     "iopub.status.busy": "2022-04-09T11:21:16.357198Z",
     "iopub.status.idle": "2022-04-09T11:21:16.359076Z",
     "shell.execute_reply": "2022-04-09T11:21:16.359531Z",
     "shell.execute_reply.started": "2022-03-11T10:40:00.353836Z"
    },
    "papermill": {
     "duration": 0.025129,
     "end_time": "2022-04-09T11:21:16.359648",
     "exception": false,
     "start_time": "2022-04-09T11:21:16.334519",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# These are the usual ipython objects\n",
    "ipython_vars = ['In', 'Out', 'exit', 'quit', 'get_ipython', 'ipython_vars']\n",
    "\n",
    "# Defining a function to list the memory consumed\n",
    "# Only outputs variables taking at least 1MB space\n",
    "def list_storage(inp_dir):\n",
    "    # Get a sorted list of the objects and their sizes\n",
    "    vars_defined = [x for x in inp_dir if not x.startswith('_') and x not in sys.modules and x not in ipython_vars]\n",
    "    sto = sorted([(x, sys.getsizeof(globals().get(x))) for x in vars_defined], key=lambda x: x[1], reverse=True)\n",
    "    sto = [(x[0], str(round((x[1] / 2**20), 2)) + ' MB') for x in sto if x[1] >= 2**20]\n",
    "    print(tabulate(sto, headers = ['Variable', 'Storage (in MB)']))\n",
    "\n",
    "# In order to use this function, use the below line of code\n",
    "# list_storage(dir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6013683",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-09T11:21:16.396373Z",
     "iopub.status.busy": "2022-04-09T11:21:16.395767Z",
     "iopub.status.idle": "2022-04-09T11:21:43.120477Z",
     "shell.execute_reply": "2022-04-09T11:21:43.118795Z",
     "shell.execute_reply.started": "2022-03-11T10:40:00.359464Z"
    },
    "papermill": {
     "duration": 26.7449,
     "end_time": "2022-04-09T11:21:43.120676",
     "exception": false,
     "start_time": "2022-04-09T11:21:16.375776",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Importing the Labelled Dataset\n",
    "df_train = pd.read_csv(\"../input/cifar10/train_lab_x.csv\")\n",
    "y_train = pd.read_csv(\"../input/cifar10/train_lab_y.csv\")\n",
    "\n",
    "# Importing the Test Dataset\n",
    "df_test = pd.read_csv(\"../input/cifar10/test_x.csv\")\n",
    "y_test = pd.read_csv(\"../input/cifar10/test_y.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b862f1",
   "metadata": {
    "papermill": {
     "duration": 0.039661,
     "end_time": "2022-04-09T11:21:43.189470",
     "exception": false,
     "start_time": "2022-04-09T11:21:43.149809",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Basic Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61a4ff08",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-09T11:21:43.270055Z",
     "iopub.status.busy": "2022-04-09T11:21:43.268826Z",
     "iopub.status.idle": "2022-04-09T11:21:43.894859Z",
     "shell.execute_reply": "2022-04-09T11:21:43.895276Z",
     "shell.execute_reply.started": "2022-03-11T10:40:00.361445Z"
    },
    "papermill": {
     "duration": 0.675045,
     "end_time": "2022-04-09T11:21:43.895434",
     "exception": false,
     "start_time": "2022-04-09T11:21:43.220389",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40006, 3072) (40006, 1)\n",
      "(40006, 3, 32, 32)\n",
      "[0]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHMAAABzCAYAAACrQz3mAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAsmElEQVR4nO29Xaht25bf9Wut9zHGXB9773POvbeuRerGlKSCDxIjFFFRUCKBQoTyQUJKDCUE6klQyINFXiIBIb74gQ/CBQtLEMtCI+YhIEUoib5I3UQhpIokZUyoW7neunXP/lprzTnG6L01H1ofY4659lr77HP2uWvvHHaHteacY445Zh+99fb9b22Ku/NhfDWGvusJfBhf3vhAzK/Q+EDMr9D4QMyv0PhAzK/Q+EDMr9B4K2KKyM+IyN8Rkd8WkV/8sib1YXyxIV/UzxSRBPxd4E8C3wV+A/g5d//NL296H8bnGfktPvvHgd92978PICK/AvwscC8xh/Mnfvbkm+DO/VvoNe8597znJw/rkHtf3P8Fn3nk9pBXruy3Jro+le25x2dbhvI4cO/3z1c/oOxf3Hkzb0PMPwD8zub1d4F//nUfOH/yTf6Vn/8vqVapVteJ+mZq3oi5vQl3b3/H5ydjeb89X4aIxAJKe94W0GGzln7cJNvrrP+PszleWggNFddUTcd54OCGeW3zXT4tkBKiikj8AVht92VGNcPdMXesfa9t1sIR/t+//B/eu74/cgNIRH5BRL4jIt8Zb56zLMAyTsgigJy+v3njlafLy6DW8ciy/Osi3MUlvHrsdBNJ+3/8wuOG2PCXyMn56/X89LVvN1TbZOvz9R627wXxtoT8rPE2xPxd4Fub1z/Rjp0Md/+2u/+0u//0cP6E42LcR7C7/m6duV2H9rjcbKxhvHGboHcS0jkl/rq4rAsrm0U+JejpHE+kCXdsji0Rt69v/fnt12+kIt6OmL8B/JSI/KSI9MCfBv7K6z5wn/7ZLmic50cR5ZtlubWRl3tcxK63f76IO9iITVYxGNffiOvbz++bty9cfj/ZFnWw/aA799/87e9YV6BdtX14vcRrrvOFdaa7FxH594D/FUjAL7n7336DTx51IOByXIRFNPmtRQdHRVBdvjuuYxZ/67HtYq8bARDBthy3zuTkfm7NMk49ak5vRJf1DHdfxawIuNtxY/lt4jpujuipVWCbe1305PbebSXmwqX3j7cxgHD3vwr81c/5GU601JGGgJ/ufHfcLZ5K6K9F+rgfhdspIe/7zqazlkufmDm3z1untp67tS+DoBsOxE7m/SohObnCaiit93iUDLdW5/S7P8ONfCtifvlDVkLFy+Piiwiq8X5KCQTKXONmDcxe5a7PGq/jzFfPa0RcuCwU7OZzcnL2MudVm8qyAby5KH6qx9cdKicb6WTI63Xne0bMGKuF6HIixkQgZWUYOlSFUWbMDBewxsGvvd4947WEvKV/QU5F+OnZpzodUAFzORHvi15+5QqLSFivtiX2a28BeGhi3rNmG69itdzW/356g9unIqCqGL6KYLi10FsdeZTNp8funJHfcd5tTjzVoVvm2kqZ5fVx+gvr3ZrM5mtvm1hvMt4pZwoC0vZ9M0/DI5BmgCho0xxeKcVwF3Q2VAVEGXY9Vg23Qq2OmWEWXCqryPKTb13Gbbv1KAWaobFQwrZm6ekdHE2lW++sHCrruXe5GCd6eTGGFp19QtzPJumDE3NrjPiyENt73BAVARVpERLHvAJCreAupNSTUqKKoskxq6ff1Tj21gTi4R6xtRIUaYv5OlbZ2rx3XfB4L36HqN8ScnntW6ZtBD3q1teT9J1x5p26QLbvCqu/uZ4fhC2lIgLVBK3gBm629fM5XejNwyqKj98pWwd2ncGrojr8Xjk5eNsmXr7RX9GTy5vHe9t+S1zbVomwWribzfRZwYOH50w2C8ota+7k2FHshMEQu9zcqFNp+s9ACoKgpKProu2q5pyyYGwOk2VrtMjDhj6v8FgzYJZPcCuydJzxVq8LttX9q1r15iueBgWc5m+u8WdbibmoDF8kxWt48+GJKb5sTlYj4vSM+H+UQcfdK4K70O6v7eQgpcga0ENkI6tu2U4uvorfU026CQbcnmv77ljNI8WP4vCUmLfNJ9nsEFmvf7z3UyPs1WPvpQHk0giy2Zm2znThvkXkLIbP8u4SeRREpe1apxiIV8wmxB1JoF07r3Hrck0RqLIQdNVm3K3vlggVuGo7TcDiXGMxUCpOBZy0UkzXzXrUHKfRonUzVzsaP0socRNaPM5MNn93j3fAmYSo8SDIarnFuycC69R4FJZQcuTFwyCqtYIZVibEKmlQtI8Uk5qefHoNq8nyXXcYSG0eJ0M2ROI0K+NiLUq1ygjYbJVXr9tcqLY/3DbqpN30nda3yD1zPY6HN4BETmOzywLTFHw7uNmc2w+3Y7EoKkJSBaxZQRUrhWkEFaVDSaInxs4axImvxReebzRYha8si9oEsqwnsPqQEnOpYW6vfnJEqdpn/Cj+V2vVNTi7GTWrBFi4fxHb7TtX7SuvJ+c7sWa3yv8YaObEchPuCpW1t9sGSCmRk+LVKWPB64GpzIz7EdXM47NM6rp14Zfvrut1QiSoONoIqcviiYWyEyLAv1zEYvFNw3CyakxWcDPUHTEn545d6lARRBz1EKXmFvcrCfMchFTBRWMvahNR6usmkKOFeEyN3TPeiTV7+8hpCmvRZJ+t9hVCfza96VYxm5nrREqR7V+sD2HDWeK4Cceozun3bUygo1EFJypr6wKtG9IMcVBr+ABxZDWOfGOl6sZuWIgU9x7fbEeuXiXJ60UsvCs/8970xvJPNqfede5i8RpiRp0P7F8+Y95fMXrhxme6PPBoN+ODkTSRc8IFJpuP1uiWZdt1/Sj41j9ZIkouTeiGbjQRVI2UNeKvDl5DPIo4KobbjNX5aORAg4U0OSAZJJ3eWpO5ztY1ucvyPR3vLAJ0PHDr8U0+s36g4l6wMrK/esb48jmjGHuMfjijlBlwNMEwJBzYzwUpCw23fqOvOnQlonhTbCVeu5DQ+GZJQVJ1NCcwx6qD1QYRscZcE1YPx22yuFeeYzOpAukIE1jNfDvO5L7A/K3x7rMmEpLwZKL3Me4rRA0uOiahQTXR5UzOXYQMPXggieMi5CRkBKtCsSCe+BITZuVUkeZKuFHnGbcSrocoiKJpoMtKSPIgvLR4cVjOFasVKxM2HxBVtOtJKsxp8XA8QFxiLYoFeIQl3S2S7zU2kjV37T3izFv7Sxaxtbx9OtGTpO0dN+HmVK+YGSIJTR1nZzsuLs9JuafLCepMRjjLHaKCZSVbx1SMmxvDahBNmo+0ZjxUUXVqKdy8eMq8v6ZLypDCqNrtvkZ/NrCfK9M+9GNKApJRKmW8oXqlHF5Q9y/Ifc+Tr3+Dfjew98SNQXWnlJliteVkW9SnliCoGV5LEHaJCHl9ZR2W8ZnEFJFfAv4N4Pfc/Z9pxz4B/gfgDwH/APhT7v70s661JYpsstCy5vHkTq58BdKxdUQXR1sEESV1Pf3ujJQyqgpuiBtZDFGlQ6gKbkJaDBpfHSPC7dik1Nwp08h0uIGUSDmDVxJGl2CuYQ0bHjBKBDEwm8EKdR4p0x5VJ6nTZWGuEnaZRx62LHDLGgSrteDNQrZSTsJ799obvBmg678BfubWsV8E/pq7/xTw19rrNxy3rTI5fXx9kGMzHERxSWgeOHv8CZcf/xhnlx/RDRfk7oysSgIoI/P1U+arT5Hpis5HBmZ2ydklyBhiczNWCqVUSq3xWIJDMKOMe66ff8r18x8yXT/HxiukHOgVhiwkN7zMeJmbeB2p0w1lvKKOV9h0g88HxApZhawS4tgKZjPmM+4zQkGkomp02egz9Nnps7/OM/lsznT3vy4if+jW4Z8F/tX2/JeB/w24H517z1j01DaBe5c4vY0UWCIuAXLKpE65/OjrYdkqFBUUJ5uR3WHaM00vQ909ekyvZygZzz1VhX0twQ0uFA9rVSyMTCsVr4a4M+9vGF8+JXeZy08uObvIiPacpQsqyn6cKHNsCpkPuM3U8Zqyf05iwsZrLCvSKV1/HivgAQhnCTzQjCcs/F/1Jjz8GEe4Z3xRnflNd/9ee/7/Ad+870QR+QXgFwB2j3/sJBrqx3Neq9i3KDjfiNZFOAqCSgKVFuFpsRsP48RrodRDiM++QxSqd4gr4glZrA+X8AFbmFHs+N2qCjhWZqo4dRop44hlcNmFwxJAJBZrRjx0npUZmzN1nihlomqI0AUYtlrOcYeo+BKvIHHUBG6vT4K9tQHk7i7Hmdz1/reBbwM8+fE/cnre6hFvyLulMkd9ac0RX9NCHuFta35ZsYSYYlSqGMkdoyJemW+uuHn+uyFGn1/gu4HcXTJc/hNIGqBE5AYXahGqg5iACmJG3w+ghu1fUucRqxMvn/0Qk5k0XJIfgWgHs5PNwQpYweuMHa4ZXzzFpj1Xzy4p84SfC+5nVBRxyLEPIxCBkETRFo1KIoh7iPy5bM3FV8YXJeb3ReTH3f17IvLjwO+92ceWWMYypSNuZt1yba4nKaDVqo0oS+xqMCRCcw5mAhbHbP28A0adRg4vn2M2UecDtu/pzyvd8BGphejEAYv0mq2pLkHd6XJCpQ+8kUVgf9xfo1noqqDDYyQ5VAmUi7U4sYdrMo83gDHubxBNkA7IMGOSAF0xwUnD+MoiKIGyyLSggTmu94PW4IsT868APw/8pfb4v7zRpxYfPGIbcWhB1S3ZAt+IUvdYmIWI7s3/Wrg0HHDcI/LiYBTMK4JRKBQqVQTpd4glpOuRlLFq3Lx8ieiBqYaF6aKoDogkJCU0JcQrWmaECaQ29kmIdkgaMBMO13tUZ3LO9JoRKSCGq3GdlixPwlwppjBX/HDAJFFEqQi+iR1U8TVNh4S+divgkWq7b7yJa/LfE8bO10Xku8BfaET8VRH5s8A/BP7UG9Iyqp4wlvqmFcW9zV+uuqcREW9xV2s+V23ZCsEsYqtUb2ov8ouCMTEDBVdBzi5JXvCUcFVKNfY//EH4d+062vX0lx+hXU+WgdT1YJU6HXDbAzOelqDBGSlfUItzePYCEeGjJ+ecX54hzGiOQMPLDtCES6J4RixRp0L1K0yUmpSqStKgRggYQwUUXxH/2BJ0fwtiuvvP3fPWv/YmBHx1LEVqi/nSAl0tdLaGS9vEpQWr13PwMFhW04fmr9HktUHbLCYWm0UEyR3u2oIB2ji9hKNubdOrkjCSOEnicdl4FYvgguaI8qSMao7SRJsj+iRGTmH4YPH9AWNJoKnlQyMlZ1aD+7TNe5PWCT+3GTtLCq0FWF6XBHvQCJDgJGYgQljAscxxO1oa310iuwGNA+OvNsYtc6G4YUI8rua9IeK4GFU8wmjpI0ScvuuQnKnTTJf3kf/c7yl1TyfK4wG6neCp4owYhYNXHCP3PbsnHyOaGR59TH/5BJ1GRF4iOBc7uDyr1DKzv76izhOi0J09Qrsd2l0g3XmIXXcEI4tCCzN2WVuO1kl6as2CImhATO8ZDx7OUyL4vVquLVe4ZIEktngQFAkwldOC0/E8oJbNFagFk+AddxCsxVsd07iMpIz0F6gK/dCTckftJsQEm2eYD7gXOqmcdc7QQ8Gbxp1RjOpGypnu/BGime7sgjych1tVbhAqQw9ngzFRuLEDtYyIQhrO0bxD8g50uLUejihkhT4lVI/WbZCPVuYQXP06dP6DElMFzodFsAYxXQmHbiMyMV2D5OZLNXHTlWaItBoTMVxDEHoWkrLmCiO4HkF2zDAvuAizSGCHpol5LtRSmObKVApME9dX18ylIH2P9h0gdN1A0oyrUcRAE12XQ3J2gp53qCQ0Q/XKXAr7/cg4TpSaSblDc4QXtdWZhP6LVFr4w6yAqDCsw34wX4xCwGWtertrPCgxc4JPnsSczRabtplAa+xRwBLiEnm/GrDKahWzimFUnzF3NNXI4rvQpUUML7aTQ50ilVRn5nIAYJ5mJCXKPDPtQ8zuDwcO+5E0FaZayTlz+dFHPPr4YzQlLs6eoCmzq86uNCszC6iRhkT/5AKVSubAVCeuxwM/fHrFfn8gdR/RD+dIDsC2qpA8guwCqEv8mSDVwWJDCGHs1VLBnLlUaqnUWu5f34cg4jJEoEstOdswNtUbZ7mHL9UcZ3ENMboYIWJhpovhEvrGxJvFR8AvVkKGu2L16N54be7M0kvAguur+/qHVaZpotbKMM9YrQEM00RKmU5akB6nSsXESAm6LqEN+lerUa0yl8o8G5IhaUIlHUVki0xBe2xc6QuGFGsxW6POsZnLXJjngr8vnIkbUg+I1+Y/GrS4pNuSVRdUctw8DoRITdp8LzWyBsG8FCabWqhLm05tvqcZZRzxWsAqYoGCz0lJfUfN4Q5YrcHBXiLBbBF+2++v0ReJnDvMjK4fkK5jN+xwhMkrxSPtlbqMYBxGZ94XDiOgAykrmofItIhSywzmFHeqRaSk1gJr0IBQPR4+pZlRS8HMmMYgptW3SIF9ucMRG2Nhl7TOkuIxw2oz/3OPphwc2fJ34RYcSxbMYJIKdWyvN9avh+tR5wNWSgTdMVSVPitd31EtkZJQzbAy4l6o88zhOjInh8Mex+m6npwUvNCnc4ZuF1Kg+fApSxALY65wvS+Ms4P0aE5o6tHU4QilRtA+pBEbSQK0oDp46PeVM2fMnHGcmcYS0NJ7xgNzpmOlUr0e26SUGuLOjFLr6kstBK41rNQotN3ANFvez6xiFhauLSLWWrDcWiHK4p+K03eJs12P4RTrMHfEC2CR8fBKmWc0KdUKWoVSRvLs1JJwm8AVwZr7IMFlDrUIpQpmimiHpsDvrtgfKxGgYAO7bDncLUBsAbKIBOQFgZQgJVkw2HeOh0W0mzMdDtTW88bcKaVQLQgzl3C+u07RJLhFgBkgeufImgpyd8bDRJkmqjnjVJv/2VJYHig58VgcFcgqPHm045OvPY5wXd/jwNNnlzx/8YJpmnj+9Ix5mthfv2R/9ZJaD/Q3M9QMeqAfKpoyuT8j547qwnQIg+4wKocxY1XQzpFkIB21VsxhLi1IQYuJtICCSFi5uTmXoc8rKYF3sRlEE6JOeV/8TMeppYmPxpm1HLmylMVSE1KDUdRqLd95rKL2tiBl4cxq1BoZ+zW77Ru4VhNjggX0ow/oRz47wwXGeWKqBc2J/WEPKoyHm5gnjtWRMs9Y6bAyAoZ6j0i3Wua1Qq1CtYjwRKTIoblK5ktI0o+EJOAqIgHaVt3kKxc7p5U0piwkOxYU3zUevHLazJhrZPLNnFIrtT3OJYydsnTl8MVlodVnssmqwDQVprmsOjNK83QtX8BCRJc6MR8OTCp8+vsJK1cM5+c8/sbX0ZyZ64HJZyabOZSZsUzQJc4fX6Bu4AfqNHHzojJNe1Luufjkm+wuYwmTDKCQc0/uzrBamnXcGlc4qDq5U5KH7tYUc005xeus5F6bAQRG2u5LyhzFxjf5fnDIg3NmaVw4TRPmUKq1x3DenebgL7FQUXBnnltdiUfYyKHl+KxFkLp2fmQ7cF+TzqVMjNcvQs/Jgf3V7/Hoo4/pLxJ52DGVkdkmRpu4KRNjmRhy4uLxI6gz9vKaOt0w7o3paSF3A6kf6PsO0hkpnyFJyXkgd47pHAYdNawkM0SFPsfcc07knBEVcpeRpMF5nUYNiugaVEG16duwgL+f073r++BQS2sprIjocHy0iPIckd4Q4KpFWBq1Ab11LaJZQifL6yMaQdp7AU0VUopEcCkjh5uJbujZ76/prDJNhdKgI7aEA1XbpqgUc+pcqS2iH+qhhMFUE2YjRuQ6w5CRCBCIUOqCqFvixt4QBoFsMK+oO+YBdRFnQXOGiNWl/HDbfO3u8bCc6RZcUEvUZzjMtRlCtTLXuOlILmgYGjnMep/3VKtRX9LtEFWcAEFFV5K0Gki1VEScTkGzkLXnLD/C68zV8+/z7PoZ1zfPsWR0ux0H7RmlYyqV6jMuAWzuhx314Iz7wvjiQO4z3dCRSEz7PVf6lELHxBWGgvYImZyEoTsDYL+/Yr8fm24fI39rCSWHCDVwcVKX6EhoUvou0/UB2vZm8FRK88PvT1A/MDGhWgmsa8tyhFviK8cCiLbSuJZqihSQtt0bRFZNAXYSa8ZE6JLwQ1taRRtXaqLPPTZDnSdurl5AgpcvntJNZ5ThnNqdNchjizBp+I+uiVqNeSqh23aKItS5MB5GCjN7m3FSQwVGxKhrBUvjpGsaLbCwFVOnxUeo3mSBKFI70hJQV23pwGOSGrnfx4R3oDN9yV+1SmfRCMDjyy48ohDElSh+E7qkWE6kpMFx6ngOrE4YGRY2D95EEwxdBN/VleQJzZmLy8eR4Tg/Y9f3pCUSpEaHQydUFQZ1KAXM0NST+jPSsCP350hOIF0EKkRJbd5Sx8C7poTYEKK6FrQV35p2oQ9Fo0zejyX2tYAfCpoiGuRLsw2xZgAVaqlHZMYd402QBt8C/lsCgefAt939v/hCQGgP6KIt0DM5ItHUQWtLcVFbsFnQZgj1SdAhk1QZUgCPU4aO+IyV4HRphoMIDJ0GytwEr+BJePLx17i8vCB10RxKkuAZSAUTYRgaeqE6zBOUSup25J2Tdzvy2WUg4yVKHEgR5Afw+RovBVJGhvPwH4s35KAiWcIoE29NqHyT1nN8qoiCl0oZAw0oEqqn1kotS4z5CxITKMCfc/e/KSKPgL8hIr8G/LsEEPovtf7sv8gbYWeXJhJHPyuwP0sozohMnjdDpxl1Iuvfcmxj8qAagjbi1/HZlDTqN0XWVFLqB+jCehzOUhAmKZ5kDTpUIlxYm1+hGlytuUNTDn29+Htr6KaJd4vaEJ/HQBiYRtKAEPdKisoxaYgLO6b4wp1pceoSCfYleuVlI9W+KDEbPvZ77flLEfktogv0zxLYIHhDILSIhO5KIcpEwxmWBFoDpujmjGVkttKSnVEv7m0HCEA1DFaLUlUZdmfklChlZp5HVJXz83N2/RDprvGA4Dy6eMT5LtEPiYvHPSkJ+3nkME9MU+Xpsz3jVJlaYENxut0O0Y5+d0Z/doGIRG+EJWOTgpA63uBlRMwoV8+DVv0jUn9Jzh354gnada1UIXZelCIY0zxyONzgXpG5rnHqlGJj2xhZmNdI2c+nMxuy/Z8D/k/eEAi9BUGfXz4hpS70QlIkCd2gpBQT6R3cjDwJ0zxhBqWVUyaRtTHSgt6zGr6niNB1ma7rQKIYJ6ky9AO73Y5ZFasVVXj0+IInjwZ2Z5mPPt6hSXh5c8X1/ob9fmJ/M+G1UoU1rpu7PtAA/Y7U7Vrmv6XuxDEpLcBhYDM+z9Sbm4hUXSQ0naG5ZzfsyLuzY4akuThWKyqJMs1Y1Za9saiFabBPm8FGP0aG3oaYInIJ/E/Af+DuL7bwhdcBobcg6K998yc8p46CYzWEKS2c1efEZd8hOMPYMdfKPFVubuawJseRWlqiutY1YV1qWK3mYYyUCtMcUaXDOCOSsGpoK5m/vDznk08uGM4yH320QxO4GMUqZsIw7DBLLE0jSolKM58NzXmNpYpEL4TItRJVZCnwRQA69JFU7jpKCwwEuj78ywWglVOGlHEzhn6HWQ1YjC1QmmZcsaD63zI2KyJdI+R/5+5/uR3+3EBoEY3Fmio2lYAP7uKmzs92/NjXLkmilDmsu+vrA7/PS6ZpZn9VmKco5NmPh3BjNErvTJxCIpGZqnO9n0OH6oFxcrpOORs6+l3mGz/2MX/wW58wDJknTwZUQXOiupPSzPWNkPNMv1OGM2GajcIeDqXBP/rIPzbQUgQEFPdK6gZS3ZFypUsBoJ6GM+bdgKeOYobPc7ClRPP9vhtIOZE1IRL51XHMlDKuocAokehQKQTE6+7xmVVgEtvhvwZ+y93/081bCxAa3hQILUFQYO3i3Iy6yDV2mb7P9F1H33XknMOsb+b7gomJwHaL2cbHWzQJqtFChtbivZGpWOpFur5jtxvY7XqGoafve3JKEQZsoUBNmaSB3UnNpxXVMGhaeGbhElleoy3mGtdIqYu/5k4t2B+W3G0pUZS0IA5USCnH96WMaEYk4UuhgiSQ1/Pem3DmvwT8GeBvicj/3Y79eb4IENqduRSmaWbcT2iG3OdYFHeGXU8Spc4Fq8Y8Fq5f3nAYZ+apAilSWXlAk4XoShFYGOdKsYn9WBinyAWmmymgGwKPH53RdR3n5+c8fvyI1n84jI8R9tfGYYQyZWoJcV1KbA5JHdoJIrn5h9KMMlaCinjAKYVIvPdzIHjTGZYzJhqwFwrjzQ2Hm2tElbPHT+iGHZIyqe8RPJAUKTOXyrSfsGqY5HCh5C0C7e7+f3C/oP5cQOjwpyplrszTHInfiVZhBUMXCLYDsXvLXNnvRw6HiVKayyIBDDOAJJAiWjLNYS2NU2UuzaWQmVIqu6FDVEk5s9sNXFycNw6ZKdUpM4wHY5qcWqJ0wapTajRbRHNkOVpjmdU4aE/WAH83oElWRGDg0zImCRdBGkB7Olzx8tPvgyaKG935BcP5BRcXZ+GbQoPNzMxeqR7dxmIHvidZE1VhdzZQKszFUYUuK0kV1TAuQNgfRp6/OPDyes/+MDGOc/iA0NJGzadUwZvDvviRUUreDIfNYueU6FImNxFa5on9zcg0zVxfHbi6mphnZ54CLVDKkmv1ZqQd0dotYLUOb7Uv1ZcgOtSWwpqXWpKYZbPCZ2qZQFMrtI0azblGTLnUGqrCPRparG7Z67XigxIz5czXvv4xu93IMOwBR7ogat/tSHmglsoPPn3BP/ru7/Py6sAPfviCUirdsKNrOz/lcPYrHrWS5pRmwc7VIre5JH8RupQ5G3ac7Xbs+oGhGxj3Ez/4/nOur/f8o+8+5XvffYaRcDnHSYzFOcxrDiVKGvzos6/NQcxa1bMzN9goknBNILIWY4g7yQviRp33TPsXSErM82O0dkxzhnEEVcZxDLR+NaqAqUYUibzJXr86HhgELQxDT5mNeQrlb1pbWC/K29wq4zhzdXMIIPE8U6uTulZA2wwZ0cDSRC1Ki6KYrSiECJw0gHFzvlPSBnuMjliH/cz+Zgz/cj/hdGhniCZqbZ1AVt14h65p1I3+d0H4Ci3OsfT6ipSZAurNAHKL2GvzZZfqtqWCulq4StVOjTzk9UmwhyVmEi4uB3JODENPrcZhnAJtUOH58xumcebpiz3Prg5MY6G03q3FA9OjeBgSGq3KJMlaUNTseLw2YLUZeOigTiNYn1RIKlgpvHj+gufPr3j29AXPnr1EU09/3qHZmWthrpWldCj4M/QmvuHMWrF5bsRsZ4bz2jC63owlJzxrIffnnD/6BDQxDOf0eQhXpUQFWx0P4VdXmKbYUJoGVOvbhfO+zKGqXFzu2A3G5XmgB549D2u1Fnj+fM9hHHn2Mohp1SkeyxbEbFxISzp3ORLIi1nSuIQaYbaonA2DJKfWA0iFJEIthZfPX/Ls0xc8e/qC58+uSN3AhZ6ReyhWKV7aFonNIa36YykWFpFIac1zpPAIcHdU3EZ/+XXthVYJBl13ztnlJ4gqu/6CnIfIpJQaMMzDSDnsKdWZp0jep2ykvHTQvHu8A6RB86lyQBSdECvTbPjNzDhOzc0IzE8Eu+PcYtbKxVsCezF6nED4Nd/VmlhbEAzQxPNG31g15rkwzTPzXCilRA1lLVALdUU9LAiIpWBNWo5RVilgrZrbWguZMLVLQD6amFRRPIc0QQJPG75qiz03Ue0L+j4m32pVid4Ird/CfeNBiWk4U610KQpvDJhq5WYcma9GxmnPOM18+mLPfj6CnSHisDPNAia6gWRVsnoUzo6BISpzYaoBrexrEN8spEJqLlCtxjQXnl/d8OzFFS+urnl5syd3FXbXdLU0/zXCeqUWzJ0kiayxuQKaAmWemcc5Es+0n3sSwbUAspblJ03o7iywPwx0fYvkWIqSGA+Ug5nh4wxTRaohc3TLtMmoPr51CuzLGy2CAy0bkAQzo5TKYZx5eb1nmktwpq+MB9BqMnzJaweXtOfVoFRvdR4ttb1Ei3wp1G0gamjxXWOeZsZpZtpyZimBqZVEah2nvWF8VRciLkZPbDJbuLOlspAj91rLtxK9oDCBKPrtYkkcvB6hmG4WN1QNsShb9FaHYtXfH51p7lwfKqWPnOE4FWZfzO8EeYeIcfZI8e58hVoihC/a4qEBFyFCZ5pIyeiKQK5oKkgqAZHUQsWYqrM/TPR95mY/cXMo7KfKVDW6lHQD3dkFKWckp7VBoWgOYqqHoUNDlHtARr0ac6kc5roSc+1uvRhlLdznFaa5NDzwESKz9GcILHEkEsZpDtjpBjfsjajvDTGrwctDZTYo5hHWM6Pg1JSgP0fNudQzhsvmZi+TbwW5TtT8h8lPCys5vXekYpS+kIYS9QrzNbVMTNW4ujmgSbm6mbi6mbg5VMaqTJbR7ozhMiJJ5BR6TVvEZeE+cUS0/dqfM1WLyqypcJhqLDqw/Fuq2TTHZUL8FkSCkGvmp5aGCd4cK0ujp0UyefshnvfIml3gEXOJOo1SLcJcqmhSNIfxkHEktfqMlZjtGji14X3CYAgOiEqrhqFF8VTBp5ai0ohzzoXDOHHTjCwjRW+CrqcbojApdYEk0BwBb9zRbJhqK14KPUpqYjBnJGdUbO08uYQrgNgg2rizHVswdqFjA27qzXBzX0ocj4SM51sI6t3jgYnp7KfCNDv7fbt5zXRnCXUlmwZsoy5WaWT7cd/cvLfaDV/DYG6Qu/6IfC8OVin7jM8T2inPrvaMpfA73/8hReDTpy/xbkc+Vy47yI8idCZZ2sZJEcnBoRayL79UArjT7SpaDC0FuZiiyKnUxkHt1488DC9VWWO6DliNTmJmElEeQpeahuipS8k/LaskNLCbvi6d+dDoPJiLMbfOWZETy2gXbc8Sud1s26EWluSyW43QMVHaYJQqzaIAumM2I8o+K4WC5QRS2E/hCz57eU2/67i6mXDtSL0ydLGZHHBdwg9Lk1/oWhhuiea4O5oMqoej33W4OTrNAVhrdZX40fASaPrPI6a8NiGGKmsnhnZMjsXDSwNjpMEY35NwXqyzbvbo4mfJRqSeTvb421xHYFdqIg9xZLXU2xlGoPGSkmyH5USmkCRBFm6mytOrPeNoFElYUpAcWQkWmKe3MkFpvqO2Ds6tx0IzhFwdz4HlDcMnIblEcKPVna5WtLfUmC8GUBDdkiAlEHjWLPbaNit+PEYT4UXfk6wJRMwSaAFjYWmOcvwloaPFtpQirHlD98CkahA/uVC9iR7ZELOGQy+dRp2HzVGxLcbzfeF6foGTMdnhXYIUSegQ4VOI9+LMZhgB3jKIUsRWye167O0iuSEG+9qKlZzUmv62m97cf/slwRobQ+aZXFv1eLN4FjVy7BNIex+m96bWZFXqt8XFsZfecuMNgBmSuBFygTQuvB3lbksUXI4ZBW/YoqSNxtHuDCSMp4Yb8qWoowGTw1hqOFxa8S6LscLR9fAtfZbiJlgBwPG7Fq+2K2/3tbbJ8Wi0GBHcpXlVbGDad4ltf+zt9cv78JxpEQmiEUcXe8O35I1ZLz1wHJoRcVo+YwjqK6yqBbQ5vaDQEth9bIy0RBw6kF1Yug0BYVaZ60S1Si3HfkNL9sSsUlbs6tpDC9Zf1ws7ddHxxzuJcdxrDavrHi1SWz1JvHY0t0B+s2JhydNGQdN9400Q7TvgrwNDO/9/dPe/ICI/CfwK8DXgbwB/xt2nz7reKjVi9hGPXr5rc96RKzeLwJH7Fu26VEjRwmmLtHU2hBUFidoPSdKImYEeEGqZmGulWlRvV7OI1tQtWn5pgL/Ue0TCeAlsrI5D645i3GKjTRrNdTHWvKEHlh5Ii3qR7Udi3Zr+XAh/1/hMQBcwAn/C3f9Z4I8BPyMi/wLwnwD/mbv/YeAp8Gff4FrH6ud274vDHK2zF2W/iKrGBW1XLvp063EtGNoltBeVD37s4rbQfyGyLESQVrHd/kpZDY/llwuWMFrgYf0odxc52+brmzkuSIeYod8mKUsPg+U226qsa3J0q09Vkb+iml4db4IBcuCqvezanwN/Avi32/FfBv4j4L/6rOupwPKr6rEetcVajy3+FgF1JBlHFm0UcmENbwVnxsm6iuvGJavR3KjaEHbVA0ZpDtM8M5Up2h1a635SBa9tnksWw4kmw5vZbQmw9DaitRg9CpJTmbP+qJ0f31tDl4QuPZY8bBfl9QR9E85ERFJD5v0e8GvA/wM8c/elCcF3iZKFuz77CyLyHRH5TlQvn9zXkUWP3h1HEm7fa68XPbJy6vEUWX6TZPt3ahM1rmnis+nD+KsrFy6RpaXR1Mp9fsybnkoIX+fktwlw360sh53NNt6s24Zwx+u9JWfGxbwCf0xEPgL+Z+CffpPPtc+uiPav/8QfdpX4CYpVJ/rqbZI2umK9dz8VVQsX+mLtLERsH1BfkOZxTWv1jbWljmqzTyOLT+t4MkdzJTfc46eeqIoXPVqv20eWDbG0nWpzk+Mst/bXq4vC2jtvQaxrY+P4jK4Wu60/JSV3bobt+FzWrLs/E5FfB/5F4CMRyY07fwL43Te5RitUW81v2RxXYMG5LAtmS6WwHO/Dm/PtBCHdiZ7qHHvQSqN1JC+iFYv5IprjR8jnWRqguqziFaJ3kFcNgrqstcrmW15sagJOevPI+rhp7Liaa+29ZSc3Xe/t/NRglLKU+a9f9Lous6dr+9ohIt9oHImInAF/Evgt4NeBf6ud9vO8aWvvu77jix57zS69fyxi8XgBv/X+XZe9O8P/6rGNGjw5uPWY3uAyX2jI62AIACLyRwkDJ+Bz8Kvu/hdF5J8iXJNPgP8L+HfcffyMa/0AuAZ+/0uY+/swvs7D38s/6e7fuOuNzyTmlz1E5Dvu/tMP+qU/ovG+3csbWbMfxj8e4wMxv0LjXRDz2+/gO39U4726lwfXmR/Gj258ELNfofGgxBSRnxGRvyMiv93azfxjMUTkWyLy6yLymyLyt0Xk32/HPxGRXxORv9ceP36n83woMSvRN/TvEkGH7wK/Afycu//mg0zgLUbr2fDj215IwL9J9EL6dNML6WN3/9y/I/pljYfkzD8O/La7//2W9/wVopfQez/c/Xvu/jfb85dEBGzphfTL7bRfJgj8zsZDEvMPAL+zeX1vpuV9Hl+kF9JDjQ8G0OcYt3shbd/zNXv+7sZDEvN3gW9tXr9xpuV9GK/rhdTe/xw/CvujGQ9JzN8AfkpEflJEeuBPE72E3vvxpfZC+hGOBw0aiMi/DvznRAbml9z9P36wL3+LISL/MvC/A3+LYyvmP0/ozV8F/iCtF5K7f/pOJsmHCNBXanwwgL5C4wMxv0LjAzG/QuMDMb9C4wMxv0LjAzG/QuMDMb9C4wMxv0Lj/wdu4Jf1Z+ZdgQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 108x108 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train = np.array(df_train)\n",
    "y_train = np.array(y_train)\n",
    "print(df_train.shape, y_train.shape)\n",
    "\n",
    "# Reshaping the dataset\n",
    "df_train = np.reshape(df_train, (-1, 3, 32, 32))\n",
    "print(df_train.shape)\n",
    "\n",
    "# Visualizing a single image\n",
    "ind = 15\n",
    "example = df_train[ind, : , : , : ]\n",
    "example = example.transpose((1, 2, 0))\n",
    "plt.figure(figsize=(1.5, 1.5))\n",
    "plt.imshow(example)\n",
    "print(y_train[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94e30da1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-09T11:21:43.938216Z",
     "iopub.status.busy": "2022-04-09T11:21:43.935171Z",
     "iopub.status.idle": "2022-04-09T11:21:46.368973Z",
     "shell.execute_reply": "2022-04-09T11:21:46.369915Z",
     "shell.execute_reply.started": "2022-03-11T10:40:00.363416Z"
    },
    "papermill": {
     "duration": 2.457005,
     "end_time": "2022-04-09T11:21:46.370135",
     "exception": false,
     "start_time": "2022-04-09T11:21:43.913130",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40006, 32, 32, 3) (40006, 10)\n"
     ]
    }
   ],
   "source": [
    "# Creating a random permutation\n",
    "perm = np.random.permutation(df_train.shape[0])\n",
    "\n",
    "# Shuffling the training dataset\n",
    "df_train = df_train[perm, : , : , : ]\n",
    "y_train = y_train[perm]\n",
    "\n",
    "# Reshaping, rescaling and one-hot encoding\n",
    "df_train = np.transpose(np.array(df_train), (0, 2, 3, 1))\n",
    "df_train = df_train / 255\n",
    "y_train_oh = tf.one_hot(np.ravel(y_train), depth = 10)\n",
    "\n",
    "print(df_train.shape, y_train_oh.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a210c948",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-09T11:21:46.411493Z",
     "iopub.status.busy": "2022-04-09T11:21:46.410678Z",
     "iopub.status.idle": "2022-04-09T11:21:46.694511Z",
     "shell.execute_reply": "2022-04-09T11:21:46.693548Z",
     "shell.execute_reply.started": "2022-03-11T10:40:00.365295Z"
    },
    "papermill": {
     "duration": 0.304578,
     "end_time": "2022-04-09T11:21:46.694650",
     "exception": false,
     "start_time": "2022-04-09T11:21:46.390072",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 3072) (10000, 1)\n",
      "(10000, 3, 32, 32)\n",
      "(10000, 32, 32, 3) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "df_test = np.array(df_test)\n",
    "y_test = np.array(y_test)\n",
    "print(df_test.shape, y_test.shape)\n",
    "\n",
    "# Reshaping the dataset\n",
    "df_test = np.reshape(df_test, (-1, 3, 32, 32))\n",
    "print(df_test.shape)\n",
    "\n",
    "# Reshaping, rescaling and one-hot encoding\n",
    "df_test = np.transpose(np.array(df_test), (0, 2, 3, 1))\n",
    "df_test = df_test / 255\n",
    "y_test_oh = tf.one_hot(np.ravel(y_test), depth = 10)\n",
    "print(df_test.shape, y_test_oh.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a18dea4",
   "metadata": {
    "papermill": {
     "duration": 0.019647,
     "end_time": "2022-04-09T11:21:46.733938",
     "exception": false,
     "start_time": "2022-04-09T11:21:46.714291",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Creating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48d6af07",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2022-04-09T11:21:46.777950Z",
     "iopub.status.busy": "2022-04-09T11:21:46.777245Z",
     "iopub.status.idle": "2022-04-09T11:21:47.802545Z",
     "shell.execute_reply": "2022-04-09T11:21:47.801991Z",
     "shell.execute_reply.started": "2022-03-11T10:40:00.367119Z"
    },
    "papermill": {
     "duration": 1.049293,
     "end_time": "2022-04-09T11:21:47.802675",
     "exception": false,
     "start_time": "2022-04-09T11:21:46.753382",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet/mobilenet_1_0_224_tf_no_top.h5\n",
      "17227776/17225924 [==============================] - 0s 0us/step\n",
      "17235968/17225924 [==============================] - 0s 0us/step\n",
      "Model: \"mobilenet_1.00_224\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 64, 64, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 32, 32, 32)        864       \n",
      "_________________________________________________________________\n",
      "conv1_bn (BatchNormalization (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv1_relu (ReLU)            (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_1 (DepthwiseConv2D)  (None, 32, 32, 32)        288       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_bn (BatchNormaliza (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_relu (ReLU)        (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_1 (Conv2D)           (None, 32, 32, 64)        2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_1_bn (BatchNormaliza (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv_pw_1_relu (ReLU)        (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_pad_2 (ZeroPadding2D)   (None, 33, 33, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_2 (DepthwiseConv2D)  (None, 16, 16, 64)        576       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_bn (BatchNormaliza (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_relu (ReLU)        (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_2 (Conv2D)           (None, 16, 16, 128)       8192      \n",
      "_________________________________________________________________\n",
      "conv_pw_2_bn (BatchNormaliza (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_2_relu (ReLU)        (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_3 (DepthwiseConv2D)  (None, 16, 16, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_3_bn (BatchNormaliza (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_dw_3_relu (ReLU)        (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_3 (Conv2D)           (None, 16, 16, 128)       16384     \n",
      "_________________________________________________________________\n",
      "conv_pw_3_bn (BatchNormaliza (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_3_relu (ReLU)        (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_4 (ZeroPadding2D)   (None, 17, 17, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_4 (DepthwiseConv2D)  (None, 8, 8, 128)         1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_4_bn (BatchNormaliza (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv_dw_4_relu (ReLU)        (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_4 (Conv2D)           (None, 8, 8, 256)         32768     \n",
      "_________________________________________________________________\n",
      "conv_pw_4_bn (BatchNormaliza (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_4_relu (ReLU)        (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_5 (DepthwiseConv2D)  (None, 8, 8, 256)         2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_bn (BatchNormaliza (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_relu (ReLU)        (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_5 (Conv2D)           (None, 8, 8, 256)         65536     \n",
      "_________________________________________________________________\n",
      "conv_pw_5_bn (BatchNormaliza (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_5_relu (ReLU)        (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv_pad_6 (ZeroPadding2D)   (None, 9, 9, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_6 (DepthwiseConv2D)  (None, 4, 4, 256)         2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_bn (BatchNormaliza (None, 4, 4, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_relu (ReLU)        (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_6 (Conv2D)           (None, 4, 4, 512)         131072    \n",
      "_________________________________________________________________\n",
      "conv_pw_6_bn (BatchNormaliza (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_6_relu (ReLU)        (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_7 (DepthwiseConv2D)  (None, 4, 4, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_bn (BatchNormaliza (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_relu (ReLU)        (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_7 (Conv2D)           (None, 4, 4, 512)         262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_7_bn (BatchNormaliza (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_7_relu (ReLU)        (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_8 (DepthwiseConv2D)  (None, 4, 4, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_bn (BatchNormaliza (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_relu (ReLU)        (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_8 (Conv2D)           (None, 4, 4, 512)         262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_8_bn (BatchNormaliza (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_8_relu (ReLU)        (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_9 (DepthwiseConv2D)  (None, 4, 4, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_bn (BatchNormaliza (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_relu (ReLU)        (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_9 (Conv2D)           (None, 4, 4, 512)         262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_9_bn (BatchNormaliza (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_9_relu (ReLU)        (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_10 (DepthwiseConv2D) (None, 4, 4, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_bn (BatchNormaliz (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_relu (ReLU)       (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_10 (Conv2D)          (None, 4, 4, 512)         262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_10_bn (BatchNormaliz (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_10_relu (ReLU)       (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_11 (DepthwiseConv2D) (None, 4, 4, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_bn (BatchNormaliz (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_relu (ReLU)       (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_11 (Conv2D)          (None, 4, 4, 512)         262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_11_bn (BatchNormaliz (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_11_relu (ReLU)       (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pad_12 (ZeroPadding2D)  (None, 5, 5, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_12 (DepthwiseConv2D) (None, 2, 2, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_bn (BatchNormaliz (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_relu (ReLU)       (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_12 (Conv2D)          (None, 2, 2, 1024)        524288    \n",
      "_________________________________________________________________\n",
      "conv_pw_12_bn (BatchNormaliz (None, 2, 2, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_12_relu (ReLU)       (None, 2, 2, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_13 (DepthwiseConv2D) (None, 2, 2, 1024)        9216      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_bn (BatchNormaliz (None, 2, 2, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_relu (ReLU)       (None, 2, 2, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_13 (Conv2D)          (None, 2, 2, 1024)        1048576   \n",
      "_________________________________________________________________\n",
      "conv_pw_13_bn (BatchNormaliz (None, 2, 2, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_13_relu (ReLU)       (None, 2, 2, 1024)        0         \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d (Global (None, 1024)              0         \n",
      "=================================================================\n",
      "Total params: 3,228,864\n",
      "Trainable params: 3,206,976\n",
      "Non-trainable params: 21,888\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_t = tf.keras.Input(shape = (64, 64, 3))\n",
    "mobilenet_model = MobileNet(weights='imagenet', include_top=False, input_tensor=input_t,\n",
    "                             pooling='max')\n",
    "mobilenet_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9cc359a1",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2022-04-09T11:21:47.855631Z",
     "iopub.status.busy": "2022-04-09T11:21:47.854765Z",
     "iopub.status.idle": "2022-04-09T11:21:47.901886Z",
     "shell.execute_reply": "2022-04-09T11:21:47.902515Z",
     "shell.execute_reply.started": "2022-03-11T10:40:00.369606Z"
    },
    "papermill": {
     "duration": 0.078523,
     "end_time": "2022-04-09T11:21:47.902689",
     "exception": false,
     "start_time": "2022-04-09T11:21:47.824166",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_1 - True\n",
      "1 conv1 - True\n",
      "2 conv1_bn - True\n",
      "3 conv1_relu - True\n",
      "4 conv_dw_1 - True\n",
      "5 conv_dw_1_bn - True\n",
      "6 conv_dw_1_relu - True\n",
      "7 conv_pw_1 - True\n",
      "8 conv_pw_1_bn - True\n",
      "9 conv_pw_1_relu - True\n",
      "10 conv_pad_2 - True\n",
      "11 conv_dw_2 - True\n",
      "12 conv_dw_2_bn - True\n",
      "13 conv_dw_2_relu - True\n",
      "14 conv_pw_2 - True\n",
      "15 conv_pw_2_bn - True\n",
      "16 conv_pw_2_relu - True\n",
      "17 conv_dw_3 - True\n",
      "18 conv_dw_3_bn - True\n",
      "19 conv_dw_3_relu - True\n",
      "20 conv_pw_3 - True\n",
      "21 conv_pw_3_bn - True\n",
      "22 conv_pw_3_relu - True\n",
      "23 conv_pad_4 - True\n",
      "24 conv_dw_4 - True\n",
      "25 conv_dw_4_bn - True\n",
      "26 conv_dw_4_relu - True\n",
      "27 conv_pw_4 - True\n",
      "28 conv_pw_4_bn - True\n",
      "29 conv_pw_4_relu - True\n",
      "30 conv_dw_5 - True\n",
      "31 conv_dw_5_bn - True\n",
      "32 conv_dw_5_relu - True\n",
      "33 conv_pw_5 - True\n",
      "34 conv_pw_5_bn - True\n",
      "35 conv_pw_5_relu - True\n",
      "36 conv_pad_6 - True\n",
      "37 conv_dw_6 - True\n",
      "38 conv_dw_6_bn - True\n",
      "39 conv_dw_6_relu - True\n",
      "40 conv_pw_6 - True\n",
      "41 conv_pw_6_bn - True\n",
      "42 conv_pw_6_relu - True\n",
      "43 conv_dw_7 - True\n",
      "44 conv_dw_7_bn - True\n",
      "45 conv_dw_7_relu - True\n",
      "46 conv_pw_7 - True\n",
      "47 conv_pw_7_bn - True\n",
      "48 conv_pw_7_relu - True\n",
      "49 conv_dw_8 - True\n",
      "50 conv_dw_8_bn - True\n",
      "51 conv_dw_8_relu - True\n",
      "52 conv_pw_8 - True\n",
      "53 conv_pw_8_bn - True\n",
      "54 conv_pw_8_relu - True\n",
      "55 conv_dw_9 - True\n",
      "56 conv_dw_9_bn - True\n",
      "57 conv_dw_9_relu - True\n",
      "58 conv_pw_9 - True\n",
      "59 conv_pw_9_bn - True\n",
      "60 conv_pw_9_relu - True\n",
      "61 conv_dw_10 - True\n",
      "62 conv_dw_10_bn - True\n",
      "63 conv_dw_10_relu - True\n",
      "64 conv_pw_10 - True\n",
      "65 conv_pw_10_bn - True\n",
      "66 conv_pw_10_relu - True\n",
      "67 conv_dw_11 - True\n",
      "68 conv_dw_11_bn - True\n",
      "69 conv_dw_11_relu - True\n",
      "70 conv_pw_11 - True\n",
      "71 conv_pw_11_bn - True\n",
      "72 conv_pw_11_relu - True\n",
      "73 conv_pad_12 - True\n",
      "74 conv_dw_12 - True\n",
      "75 conv_dw_12_bn - True\n",
      "76 conv_dw_12_relu - True\n",
      "77 conv_pw_12 - True\n",
      "78 conv_pw_12_bn - True\n",
      "79 conv_pw_12_relu - True\n",
      "80 conv_dw_13 - True\n",
      "81 conv_dw_13_bn - True\n",
      "82 conv_dw_13_relu - True\n",
      "83 conv_pw_13 - True\n",
      "84 conv_pw_13_bn - True\n",
      "85 conv_pw_13_relu - True\n",
      "86 global_max_pooling2d - True\n"
     ]
    }
   ],
   "source": [
    "for layer in mobilenet_model.layers:\n",
    "    layer.trainable = True\n",
    "\n",
    "for i, layer in enumerate(mobilenet_model.layers):\n",
    "    print(i, layer.name, \"-\", layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c7bbd20",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2022-04-09T11:21:47.954839Z",
     "iopub.status.busy": "2022-04-09T11:21:47.953768Z",
     "iopub.status.idle": "2022-04-09T11:21:47.982486Z",
     "shell.execute_reply": "2022-04-09T11:21:47.981913Z",
     "shell.execute_reply.started": "2022-03-11T10:40:00.371469Z"
    },
    "papermill": {
     "duration": 0.057948,
     "end_time": "2022-04-09T11:21:47.982599",
     "exception": false,
     "start_time": "2022-04-09T11:21:47.924651",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "to_res = (64, 64)\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(layers.Lambda(lambda image: tf.image.resize(image, to_res))) \n",
    "model.add(mobilenet_model)\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0e22d6",
   "metadata": {
    "papermill": {
     "duration": 0.021536,
     "end_time": "2022-04-09T11:21:48.025566",
     "exception": false,
     "start_time": "2022-04-09T11:21:48.004030",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training & Hyperparamater-Tuning for the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c564f685",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2022-04-09T11:21:48.079031Z",
     "iopub.status.busy": "2022-04-09T11:21:48.078307Z",
     "iopub.status.idle": "2022-04-09T11:21:48.085786Z",
     "shell.execute_reply": "2022-04-09T11:21:48.085329Z"
    },
    "papermill": {
     "duration": 0.0382,
     "end_time": "2022-04-09T11:21:48.085890",
     "exception": false,
     "start_time": "2022-04-09T11:21:48.047690",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#compiling model \n",
    "loss = 'categorical_crossentropy'\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=2e-5)\n",
    "metrics = ['accuracy']\n",
    "\n",
    "model.compile(loss = loss, optimizer = opt, metrics = metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "46d28467",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2022-04-09T11:21:48.148687Z",
     "iopub.status.busy": "2022-04-09T11:21:48.147759Z",
     "iopub.status.idle": "2022-04-09T12:43:15.956762Z",
     "shell.execute_reply": "2022-04-09T12:43:15.957204Z",
     "shell.execute_reply.started": "2022-03-11T10:40:00.375178Z"
    },
    "papermill": {
     "duration": 4887.844372,
     "end_time": "2022-04-09T12:43:15.957370",
     "exception": false,
     "start_time": "2022-04-09T11:21:48.112998",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1251/1251 [==============================] - 33s 19ms/step - loss: 1.4127 - accuracy: 0.5425\n",
      "Epoch 2/10\n",
      "1251/1251 [==============================] - 23s 19ms/step - loss: 0.9276 - accuracy: 0.7303\n",
      "Epoch 3/10\n",
      "1251/1251 [==============================] - 23s 19ms/step - loss: 0.7834 - accuracy: 0.7774\n",
      "Epoch 4/10\n",
      "1251/1251 [==============================] - 24s 19ms/step - loss: 0.7016 - accuracy: 0.8030\n",
      "Epoch 5/10\n",
      "1251/1251 [==============================] - 23s 19ms/step - loss: 0.6251 - accuracy: 0.8292\n",
      "Epoch 6/10\n",
      "1251/1251 [==============================] - 24s 19ms/step - loss: 0.5598 - accuracy: 0.8453\n",
      "Epoch 7/10\n",
      "1251/1251 [==============================] - 23s 19ms/step - loss: 0.4831 - accuracy: 0.8693\n",
      "Epoch 8/10\n",
      "1251/1251 [==============================] - 24s 19ms/step - loss: 0.4423 - accuracy: 0.8811\n",
      "Epoch 9/10\n",
      "1251/1251 [==============================] - 24s 19ms/step - loss: 0.3990 - accuracy: 0.8972\n",
      "Epoch 10/10\n",
      "1251/1251 [==============================] - 24s 19ms/step - loss: 0.3529 - accuracy: 0.9082\n",
      "For  10  Epochs:\n",
      "Log-loss for Train Dataset =  0.2595755375405253\n",
      "Log-loss for Test Dataset =  0.5999069228558838\n",
      "Accuracy for Train Dataset =  0.9231615257711343\n",
      "Accuracy for Test Dataset =  0.8405\n",
      "\n",
      "Epoch 1/20\n",
      "1251/1251 [==============================] - 27s 19ms/step - loss: 0.3283 - accuracy: 0.9160\n",
      "Epoch 2/20\n",
      "1251/1251 [==============================] - 23s 19ms/step - loss: 0.2989 - accuracy: 0.9232\n",
      "Epoch 3/20\n",
      "1251/1251 [==============================] - 24s 19ms/step - loss: 0.2699 - accuracy: 0.9313\n",
      "Epoch 4/20\n",
      "1251/1251 [==============================] - 24s 19ms/step - loss: 0.2522 - accuracy: 0.9372\n",
      "Epoch 5/20\n",
      "1251/1251 [==============================] - 24s 19ms/step - loss: 0.2379 - accuracy: 0.9397\n",
      "Epoch 6/20\n",
      "1251/1251 [==============================] - 24s 19ms/step - loss: 0.2150 - accuracy: 0.9465\n",
      "Epoch 7/20\n",
      "1251/1251 [==============================] - 25s 20ms/step - loss: 0.2063 - accuracy: 0.9483\n",
      "Epoch 8/20\n",
      "1251/1251 [==============================] - 23s 18ms/step - loss: 0.1849 - accuracy: 0.9539\n",
      "Epoch 9/20\n",
      "1251/1251 [==============================] - 24s 20ms/step - loss: 0.1609 - accuracy: 0.9619\n",
      "Epoch 10/20\n",
      "1251/1251 [==============================] - 24s 19ms/step - loss: 0.1777 - accuracy: 0.9566\n",
      "Epoch 11/20\n",
      "1251/1251 [==============================] - 24s 20ms/step - loss: 0.1524 - accuracy: 0.9619\n",
      "Epoch 12/20\n",
      "1251/1251 [==============================] - 24s 19ms/step - loss: 0.1487 - accuracy: 0.9649\n",
      "Epoch 13/20\n",
      "1251/1251 [==============================] - 25s 20ms/step - loss: 0.1288 - accuracy: 0.9681\n",
      "Epoch 14/20\n",
      "1251/1251 [==============================] - 25s 20ms/step - loss: 0.1399 - accuracy: 0.9662\n",
      "Epoch 15/20\n",
      "1251/1251 [==============================] - 25s 20ms/step - loss: 0.1189 - accuracy: 0.9709\n",
      "Epoch 16/20\n",
      "1251/1251 [==============================] - 25s 20ms/step - loss: 0.1199 - accuracy: 0.9718\n",
      "Epoch 17/20\n",
      "1251/1251 [==============================] - 25s 20ms/step - loss: 0.1225 - accuracy: 0.9715\n",
      "Epoch 18/20\n",
      "1251/1251 [==============================] - 25s 20ms/step - loss: 0.1044 - accuracy: 0.9755\n",
      "Epoch 19/20\n",
      "1251/1251 [==============================] - 25s 20ms/step - loss: 0.1020 - accuracy: 0.9773\n",
      "Epoch 20/20\n",
      "1251/1251 [==============================] - 23s 19ms/step - loss: 0.0968 - accuracy: 0.9772\n",
      "For  20  Epochs:\n",
      "Log-loss for Train Dataset =  0.06826280699751675\n",
      "Log-loss for Test Dataset =  0.7141647589109018\n",
      "Accuracy for Train Dataset =  0.9811278308253762\n",
      "Accuracy for Test Dataset =  0.8703\n",
      "\n",
      "Epoch 1/30\n",
      "1251/1251 [==============================] - 28s 20ms/step - loss: 0.0951 - accuracy: 0.9767\n",
      "Epoch 2/30\n",
      "1251/1251 [==============================] - 23s 18ms/step - loss: 0.0891 - accuracy: 0.9784\n",
      "Epoch 3/30\n",
      "1251/1251 [==============================] - 25s 20ms/step - loss: 0.0898 - accuracy: 0.9797\n",
      "Epoch 4/30\n",
      "1251/1251 [==============================] - 23s 18ms/step - loss: 0.0807 - accuracy: 0.9803\n",
      "Epoch 5/30\n",
      "1251/1251 [==============================] - 25s 20ms/step - loss: 0.1124 - accuracy: 0.9727\n",
      "Epoch 6/30\n",
      "1251/1251 [==============================] - 23s 18ms/step - loss: 0.0713 - accuracy: 0.9833\n",
      "Epoch 7/30\n",
      "1251/1251 [==============================] - 25s 20ms/step - loss: 0.0728 - accuracy: 0.9827\n",
      "Epoch 8/30\n",
      "1251/1251 [==============================] - 23s 18ms/step - loss: 0.0893 - accuracy: 0.9796\n",
      "Epoch 9/30\n",
      "1251/1251 [==============================] - 25s 20ms/step - loss: 0.0763 - accuracy: 0.9821\n",
      "Epoch 10/30\n",
      "1251/1251 [==============================] - 23s 18ms/step - loss: 0.0780 - accuracy: 0.9818\n",
      "Epoch 11/30\n",
      "1251/1251 [==============================] - 26s 21ms/step - loss: 0.0770 - accuracy: 0.9821\n",
      "Epoch 12/30\n",
      "1251/1251 [==============================] - 23s 19ms/step - loss: 0.0757 - accuracy: 0.9825\n",
      "Epoch 13/30\n",
      "1251/1251 [==============================] - 26s 21ms/step - loss: 0.0677 - accuracy: 0.9845\n",
      "Epoch 14/30\n",
      "1251/1251 [==============================] - 23s 18ms/step - loss: 0.0750 - accuracy: 0.9829\n",
      "Epoch 15/30\n",
      "1251/1251 [==============================] - 25s 20ms/step - loss: 0.0642 - accuracy: 0.9855\n",
      "Epoch 16/30\n",
      "1251/1251 [==============================] - 23s 18ms/step - loss: 0.0606 - accuracy: 0.9856\n",
      "Epoch 17/30\n",
      "1251/1251 [==============================] - 25s 20ms/step - loss: 0.0670 - accuracy: 0.9840\n",
      "Epoch 18/30\n",
      "1251/1251 [==============================] - 23s 19ms/step - loss: 0.0694 - accuracy: 0.9851\n",
      "Epoch 19/30\n",
      "1251/1251 [==============================] - 25s 20ms/step - loss: 0.0645 - accuracy: 0.9853\n",
      "Epoch 20/30\n",
      "1251/1251 [==============================] - 23s 18ms/step - loss: 0.0617 - accuracy: 0.9863\n",
      "Epoch 21/30\n",
      "1251/1251 [==============================] - 26s 21ms/step - loss: 0.0618 - accuracy: 0.9861\n",
      "Epoch 22/30\n",
      "1251/1251 [==============================] - 23s 18ms/step - loss: 0.0582 - accuracy: 0.9874\n",
      "Epoch 23/30\n",
      "1251/1251 [==============================] - 26s 21ms/step - loss: 0.0534 - accuracy: 0.9878\n",
      "Epoch 24/30\n",
      "1251/1251 [==============================] - 23s 18ms/step - loss: 0.0585 - accuracy: 0.9869\n",
      "Epoch 25/30\n",
      "1251/1251 [==============================] - 26s 21ms/step - loss: 0.0668 - accuracy: 0.9842\n",
      "Epoch 26/30\n",
      "1251/1251 [==============================] - 23s 19ms/step - loss: 0.0511 - accuracy: 0.9883\n",
      "Epoch 27/30\n",
      "1251/1251 [==============================] - 25s 20ms/step - loss: 0.0500 - accuracy: 0.9882\n",
      "Epoch 28/30\n",
      "1251/1251 [==============================] - 24s 20ms/step - loss: 0.0608 - accuracy: 0.9866\n",
      "Epoch 29/30\n",
      "1251/1251 [==============================] - 23s 18ms/step - loss: 0.0545 - accuracy: 0.9870\n",
      "Epoch 30/30\n",
      "1251/1251 [==============================] - 23s 18ms/step - loss: 0.0401 - accuracy: 0.9907\n",
      "For  30  Epochs:\n",
      "Log-loss for Train Dataset =  0.0786267110951886\n",
      "Log-loss for Test Dataset =  0.8901495393329224\n",
      "Accuracy for Train Dataset =  0.9815277708343748\n",
      "Accuracy for Test Dataset =  0.8631\n",
      "\n",
      "Epoch 1/40\n",
      "1251/1251 [==============================] - 27s 19ms/step - loss: 0.0519 - accuracy: 0.9881\n",
      "Epoch 2/40\n",
      "1251/1251 [==============================] - 25s 20ms/step - loss: 0.0569 - accuracy: 0.9876\n",
      "Epoch 3/40\n",
      "1251/1251 [==============================] - 24s 19ms/step - loss: 0.0468 - accuracy: 0.9894\n",
      "Epoch 4/40\n",
      "1251/1251 [==============================] - 23s 18ms/step - loss: 0.0545 - accuracy: 0.9881\n",
      "Epoch 5/40\n",
      "1251/1251 [==============================] - 23s 18ms/step - loss: 0.0458 - accuracy: 0.9892\n",
      "Epoch 6/40\n",
      "1251/1251 [==============================] - 23s 19ms/step - loss: 0.0468 - accuracy: 0.9905\n",
      "Epoch 7/40\n",
      "1251/1251 [==============================] - 27s 22ms/step - loss: 0.0514 - accuracy: 0.9879\n",
      "Epoch 8/40\n",
      "1251/1251 [==============================] - 23s 18ms/step - loss: 0.0505 - accuracy: 0.9887\n",
      "Epoch 9/40\n",
      "1251/1251 [==============================] - 23s 18ms/step - loss: 0.0372 - accuracy: 0.9917\n",
      "Epoch 10/40\n",
      "1251/1251 [==============================] - 23s 18ms/step - loss: 0.0528 - accuracy: 0.9882\n",
      "Epoch 11/40\n",
      "1251/1251 [==============================] - 25s 20ms/step - loss: 0.0468 - accuracy: 0.9900\n",
      "Epoch 12/40\n",
      "1251/1251 [==============================] - 23s 19ms/step - loss: 0.0421 - accuracy: 0.9906\n",
      "Epoch 13/40\n",
      "1251/1251 [==============================] - 23s 18ms/step - loss: 0.0462 - accuracy: 0.9897\n",
      "Epoch 14/40\n",
      "1251/1251 [==============================] - 23s 18ms/step - loss: 0.0518 - accuracy: 0.9892\n",
      "Epoch 15/40\n",
      "1251/1251 [==============================] - 23s 18ms/step - loss: 0.0380 - accuracy: 0.9915\n",
      "Epoch 16/40\n",
      "1251/1251 [==============================] - 27s 21ms/step - loss: 0.0431 - accuracy: 0.9906\n",
      "Epoch 17/40\n",
      "1251/1251 [==============================] - 23s 18ms/step - loss: 0.0429 - accuracy: 0.9906\n",
      "Epoch 18/40\n",
      "1251/1251 [==============================] - 23s 19ms/step - loss: 0.0450 - accuracy: 0.9894\n",
      "Epoch 19/40\n",
      "1251/1251 [==============================] - 23s 18ms/step - loss: 0.0438 - accuracy: 0.9902\n",
      "Epoch 20/40\n",
      "1251/1251 [==============================] - 23s 18ms/step - loss: 0.0398 - accuracy: 0.9912\n",
      "Epoch 21/40\n",
      "1251/1251 [==============================] - 25s 20ms/step - loss: 0.0416 - accuracy: 0.9908\n",
      "Epoch 22/40\n",
      "1251/1251 [==============================] - 23s 18ms/step - loss: 0.0435 - accuracy: 0.9905\n",
      "Epoch 23/40\n",
      "1251/1251 [==============================] - 23s 18ms/step - loss: 0.0450 - accuracy: 0.9907\n",
      "Epoch 24/40\n",
      "1251/1251 [==============================] - 23s 18ms/step - loss: 0.0333 - accuracy: 0.9926\n",
      "Epoch 25/40\n",
      "1251/1251 [==============================] - 28s 22ms/step - loss: 0.0402 - accuracy: 0.9906\n",
      "Epoch 26/40\n",
      "1251/1251 [==============================] - 23s 18ms/step - loss: 0.0395 - accuracy: 0.9915\n",
      "Epoch 27/40\n",
      "1251/1251 [==============================] - 23s 18ms/step - loss: 0.0289 - accuracy: 0.9934\n",
      "Epoch 28/40\n",
      "1251/1251 [==============================] - 23s 18ms/step - loss: 0.0474 - accuracy: 0.9892\n",
      "Epoch 29/40\n",
      "1251/1251 [==============================] - 23s 18ms/step - loss: 0.0334 - accuracy: 0.9918\n",
      "Epoch 30/40\n",
      "1251/1251 [==============================] - 28s 22ms/step - loss: 0.0333 - accuracy: 0.9918\n",
      "Epoch 31/40\n",
      "1251/1251 [==============================] - 23s 18ms/step - loss: 0.0291 - accuracy: 0.9933\n",
      "Epoch 32/40\n",
      "1251/1251 [==============================] - 23s 18ms/step - loss: 0.0381 - accuracy: 0.9916\n",
      "Epoch 33/40\n",
      "1251/1251 [==============================] - 23s 18ms/step - loss: 0.0311 - accuracy: 0.9936\n",
      "Epoch 34/40\n",
      "1251/1251 [==============================] - 23s 19ms/step - loss: 0.0336 - accuracy: 0.9927\n",
      "Epoch 35/40\n",
      "1251/1251 [==============================] - 28s 22ms/step - loss: 0.0522 - accuracy: 0.9885\n",
      "Epoch 36/40\n",
      "1251/1251 [==============================] - 23s 19ms/step - loss: 0.0346 - accuracy: 0.9921\n",
      "Epoch 37/40\n",
      "1251/1251 [==============================] - 23s 18ms/step - loss: 0.0286 - accuracy: 0.9938\n",
      "Epoch 38/40\n",
      "1251/1251 [==============================] - 23s 18ms/step - loss: 0.0337 - accuracy: 0.9926\n",
      "Epoch 39/40\n",
      "1251/1251 [==============================] - 26s 21ms/step - loss: 0.0389 - accuracy: 0.9923\n",
      "Epoch 40/40\n",
      "1251/1251 [==============================] - 26s 21ms/step - loss: 0.0394 - accuracy: 0.9915\n",
      "For  40  Epochs:\n",
      "Log-loss for Train Dataset =  0.020315099808681764\n",
      "Log-loss for Test Dataset =  0.8137969334396931\n",
      "Accuracy for Train Dataset =  0.993925911113333\n",
      "Accuracy for Test Dataset =  0.8768\n",
      "\n",
      "Epoch 1/50\n",
      "1251/1251 [==============================] - 26s 18ms/step - loss: 0.0336 - accuracy: 0.9927\n",
      "Epoch 2/50\n",
      "1251/1251 [==============================] - 23s 18ms/step - loss: 0.0299 - accuracy: 0.9933\n",
      "Epoch 3/50\n",
      "1251/1251 [==============================] - 23s 18ms/step - loss: 0.0311 - accuracy: 0.9935\n",
      "Epoch 4/50\n",
      "1251/1251 [==============================] - 30s 24ms/step - loss: 0.0363 - accuracy: 0.9922\n",
      "Epoch 5/50\n",
      "1251/1251 [==============================] - 23s 18ms/step - loss: 0.0322 - accuracy: 0.9924\n",
      "Epoch 6/50\n",
      "1251/1251 [==============================] - 23s 18ms/step - loss: 0.0387 - accuracy: 0.9913\n",
      "Epoch 7/50\n",
      "1251/1251 [==============================] - 23s 18ms/step - loss: 0.0337 - accuracy: 0.9921\n",
      "Epoch 8/50\n",
      "1251/1251 [==============================] - 29s 23ms/step - loss: 0.0279 - accuracy: 0.9940\n",
      "Epoch 9/50\n",
      "1251/1251 [==============================] - 23s 18ms/step - loss: 0.0416 - accuracy: 0.9916\n",
      "Epoch 10/50\n",
      "1251/1251 [==============================] - 23s 18ms/step - loss: 0.0294 - accuracy: 0.9938\n",
      "Epoch 11/50\n",
      "1251/1251 [==============================] - 23s 18ms/step - loss: 0.0279 - accuracy: 0.9937\n",
      "Epoch 12/50\n",
      "1251/1251 [==============================] - 23s 18ms/step - loss: 0.0299 - accuracy: 0.9940\n",
      "Epoch 13/50\n",
      "1251/1251 [==============================] - 23s 18ms/step - loss: 0.0300 - accuracy: 0.9935\n",
      "Epoch 14/50\n",
      "1251/1251 [==============================] - 30s 24ms/step - loss: 0.0405 - accuracy: 0.9910\n",
      "Epoch 15/50\n",
      "1251/1251 [==============================] - 23s 18ms/step - loss: 0.0266 - accuracy: 0.9940\n",
      "Epoch 16/50\n",
      "1251/1251 [==============================] - 23s 18ms/step - loss: 0.0341 - accuracy: 0.9926\n",
      "Epoch 17/50\n",
      "1251/1251 [==============================] - 23s 18ms/step - loss: 0.0270 - accuracy: 0.9944\n",
      "Epoch 18/50\n",
      "1251/1251 [==============================] - 30s 24ms/step - loss: 0.0318 - accuracy: 0.9933\n",
      "Epoch 19/50\n",
      "1251/1251 [==============================] - 23s 18ms/step - loss: 0.0256 - accuracy: 0.9949\n",
      "Epoch 20/50\n",
      "1251/1251 [==============================] - 23s 18ms/step - loss: 0.0357 - accuracy: 0.9931\n",
      "Epoch 21/50\n",
      "1251/1251 [==============================] - 23s 18ms/step - loss: 0.0323 - accuracy: 0.9929\n",
      "Epoch 22/50\n",
      "1251/1251 [==============================] - 23s 18ms/step - loss: 0.0340 - accuracy: 0.9915\n",
      "Epoch 23/50\n",
      "1251/1251 [==============================] - 23s 18ms/step - loss: 0.0272 - accuracy: 0.9938\n",
      "Epoch 24/50\n",
      "1251/1251 [==============================] - 23s 18ms/step - loss: 0.0242 - accuracy: 0.9945\n",
      "Epoch 25/50\n",
      "1251/1251 [==============================] - 29s 23ms/step - loss: 0.0265 - accuracy: 0.9945\n",
      "Epoch 26/50\n",
      "1251/1251 [==============================] - 24s 19ms/step - loss: 0.0262 - accuracy: 0.9940\n",
      "Epoch 27/50\n",
      "1251/1251 [==============================] - 23s 18ms/step - loss: 0.0403 - accuracy: 0.9912\n",
      "Epoch 28/50\n",
      "1251/1251 [==============================] - 23s 18ms/step - loss: 0.0201 - accuracy: 0.9961\n",
      "Epoch 29/50\n",
      "1251/1251 [==============================] - 23s 18ms/step - loss: 0.0290 - accuracy: 0.9937\n",
      "Epoch 30/50\n",
      "1251/1251 [==============================] - 23s 19ms/step - loss: 0.0224 - accuracy: 0.9951\n",
      "Epoch 31/50\n",
      "1251/1251 [==============================] - 23s 18ms/step - loss: 0.0313 - accuracy: 0.9934\n",
      "Epoch 32/50\n",
      "1251/1251 [==============================] - 24s 19ms/step - loss: 0.0227 - accuracy: 0.9949\n",
      "Epoch 33/50\n",
      "1251/1251 [==============================] - 23s 19ms/step - loss: 0.0256 - accuracy: 0.9944\n",
      "Epoch 34/50\n",
      "1251/1251 [==============================] - 23s 18ms/step - loss: 0.0260 - accuracy: 0.9945\n",
      "Epoch 35/50\n",
      "1251/1251 [==============================] - 23s 19ms/step - loss: 0.0259 - accuracy: 0.9946\n",
      "Epoch 36/50\n",
      "1251/1251 [==============================] - 29s 23ms/step - loss: 0.0317 - accuracy: 0.9932\n",
      "Epoch 37/50\n",
      "1251/1251 [==============================] - 26s 21ms/step - loss: 0.0281 - accuracy: 0.9935\n",
      "Epoch 38/50\n",
      "1251/1251 [==============================] - 23s 18ms/step - loss: 0.0286 - accuracy: 0.9941\n",
      "Epoch 39/50\n",
      "1251/1251 [==============================] - 23s 18ms/step - loss: 0.0152 - accuracy: 0.9962\n",
      "Epoch 40/50\n",
      "1251/1251 [==============================] - 23s 19ms/step - loss: 0.0356 - accuracy: 0.9931\n",
      "Epoch 41/50\n",
      "1251/1251 [==============================] - 23s 18ms/step - loss: 0.0248 - accuracy: 0.9943\n",
      "Epoch 42/50\n",
      "1251/1251 [==============================] - 24s 19ms/step - loss: 0.0274 - accuracy: 0.9942\n",
      "Epoch 43/50\n",
      "1251/1251 [==============================] - 23s 19ms/step - loss: 0.0274 - accuracy: 0.9937\n",
      "Epoch 44/50\n",
      "1251/1251 [==============================] - 25s 20ms/step - loss: 0.0174 - accuracy: 0.9963\n",
      "Epoch 45/50\n",
      "1251/1251 [==============================] - 23s 19ms/step - loss: 0.0258 - accuracy: 0.9948\n",
      "Epoch 46/50\n",
      "1251/1251 [==============================] - 23s 18ms/step - loss: 0.0280 - accuracy: 0.9935\n",
      "Epoch 47/50\n",
      "1251/1251 [==============================] - 23s 18ms/step - loss: 0.0232 - accuracy: 0.9950\n",
      "Epoch 48/50\n",
      "1251/1251 [==============================] - 23s 18ms/step - loss: 0.0258 - accuracy: 0.9950\n",
      "Epoch 49/50\n",
      "1251/1251 [==============================] - 23s 18ms/step - loss: 0.0289 - accuracy: 0.9947\n",
      "Epoch 50/50\n",
      "1251/1251 [==============================] - 24s 19ms/step - loss: 0.0186 - accuracy: 0.9963\n",
      "For  50  Epochs:\n",
      "Log-loss for Train Dataset =  0.03735311338626408\n",
      "Log-loss for Test Dataset =  1.0053337612657762\n",
      "Accuracy for Train Dataset =  0.9904764285357196\n",
      "Accuracy for Test Dataset =  0.8668\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((df_train, y_train_oh)).batch(32)\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((df_train, y_train_oh)).batch(32)\n",
    "num_epochs = [10, 20, 30, 40, 50]\n",
    "train_loss, test_loss, train_acc, test_acc = [], [], [], []\n",
    "\n",
    "for epochs in num_epochs:\n",
    "    # Training the Model\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics='accuracy')\n",
    "    model.fit(train_dataset, epochs = epochs)\n",
    "    \n",
    "    # Predicting on the Train/Test Datasets\n",
    "    preds_train = model.predict(df_train)\n",
    "    preds_test = model.predict(df_test)\n",
    "\n",
    "    # Finding the Predicted Classes\n",
    "    cls_train = np.argmax(preds_train, axis = 1)\n",
    "    cls_test = np.argmax(preds_test, axis = 1)\n",
    "    \n",
    "    # Finding the Train/Test set Loss\n",
    "    train_loss.append(log_loss(y_train_oh, preds_train))\n",
    "    test_loss.append(log_loss(y_test_oh, preds_test))\n",
    "    train_acc.append(accuracy_score(y_train, cls_train))\n",
    "    test_acc.append(accuracy_score(y_test, cls_test))\n",
    "    \n",
    "    print(\"For \", epochs, \" Epochs:\")\n",
    "    print(\"Log-loss for Train Dataset = \", train_loss[-1])\n",
    "    print(\"Log-loss for Test Dataset = \", test_loss[-1])\n",
    "    print(\"Accuracy for Train Dataset = \", train_acc[-1])\n",
    "    print(\"Accuracy for Test Dataset = \", test_acc[-1])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cfb75b57",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-09T12:43:57.573050Z",
     "iopub.status.busy": "2022-04-09T12:43:57.572204Z",
     "iopub.status.idle": "2022-04-09T12:43:58.967350Z",
     "shell.execute_reply": "2022-04-09T12:43:58.967762Z",
     "shell.execute_reply.started": "2022-03-11T10:40:00.376975Z"
    },
    "papermill": {
     "duration": 22.008848,
     "end_time": "2022-04-09T12:43:58.967925",
     "exception": false,
     "start_time": "2022-04-09T12:43:36.959077",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.save('mobilenet_model.h5')\n",
    "model = tf.keras.models.load_model('./mobilenet_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e483f485",
   "metadata": {
    "papermill": {
     "duration": 21.249087,
     "end_time": "2022-04-09T12:44:41.562142",
     "exception": false,
     "start_time": "2022-04-09T12:44:20.313055",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d550c753",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-09T12:45:23.207940Z",
     "iopub.status.busy": "2022-04-09T12:45:23.207057Z",
     "iopub.status.idle": "2022-04-09T12:45:31.900018Z",
     "shell.execute_reply": "2022-04-09T12:45:31.899170Z",
     "shell.execute_reply.started": "2022-03-11T10:40:00.378803Z"
    },
    "papermill": {
     "duration": 29.678579,
     "end_time": "2022-04-09T12:45:31.900181",
     "exception": false,
     "start_time": "2022-04-09T12:45:02.221602",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Predicting on the Train/Test Datasets\n",
    "preds_train = model.predict(df_train)\n",
    "preds_test = model.predict(df_test)\n",
    "\n",
    "# Finding the Predicted Classes\n",
    "train_cls = np.argmax(preds_train, axis = 1)\n",
    "test_cls = np.argmax(preds_test, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f4156820",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-09T12:46:13.580938Z",
     "iopub.status.busy": "2022-04-09T12:46:13.580017Z",
     "iopub.status.idle": "2022-04-09T12:46:13.646659Z",
     "shell.execute_reply": "2022-04-09T12:46:13.647084Z",
     "shell.execute_reply.started": "2022-03-11T10:40:00.380619Z"
    },
    "papermill": {
     "duration": 20.506866,
     "end_time": "2022-04-09T12:46:13.647256",
     "exception": false,
     "start_time": "2022-04-09T12:45:53.140390",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Train Dataset =  0.9904764285357196\n",
      "Accuracy for Test Dataset =  0.8668\n",
      "Log-loss for Train Dataset =  0.03735311338626408\n",
      "Log-loss for Test Dataset =  1.0053337612657762\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy for Train Dataset = \", accuracy_score(y_train, train_cls))\n",
    "print(\"Accuracy for Test Dataset = \", accuracy_score(y_test, test_cls))\n",
    "\n",
    "print(\"Log-loss for Train Dataset = \", log_loss(y_train_oh, preds_train))\n",
    "print(\"Log-loss for Test Dataset = \", log_loss(y_test_oh, preds_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 5138.112406,
   "end_time": "2022-04-09T12:46:38.115191",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-04-09T11:21:00.002785",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
