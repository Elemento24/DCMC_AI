{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2284408b",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 0.012238,
     "end_time": "2022-06-04T13:15:53.665668",
     "exception": false,
     "start_time": "2022-06-04T13:15:53.653430",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Hybridization of fine-tuned VGG16, MobileNet and Xception Networks\n",
    "- In this kernel, we will be performing Hybridization (Ensembling) of the fine-tuned models, namely VGG16, MobileNet and Xception.\n",
    "- We will be considering 2 different types of ensembling in this kernel. First, we will be performing relative weighting of the predictions from the 3 models, and then predicting the class labels. Second, we will be performing majority vote on the predicted class labels from the 3 models, in order to get the final class labels. \n",
    "\n",
    "### Reference Kernels\n",
    "- [Fine-tuned MobileNet](https://www.kaggle.com/code/mitishaagarwal/mobile-net-2)\n",
    "- [Fine-tuned VGG16](https://www.kaggle.com/code/mitishaagarwal/vgg16)\n",
    "- [Fine-tuned Xception](https://www.kaggle.com/code/mitishaagarwal/xception)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39de36f",
   "metadata": {
    "papermill": {
     "duration": 0.01076,
     "end_time": "2022-06-04T13:15:53.688286",
     "exception": false,
     "start_time": "2022-06-04T13:15:53.677526",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 1. Importing the Packages & Boilerplate Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "508b7ff1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-04T13:15:53.722762Z",
     "iopub.status.busy": "2022-06-04T13:15:53.721945Z",
     "iopub.status.idle": "2022-06-04T13:15:59.706462Z",
     "shell.execute_reply": "2022-06-04T13:15:59.705377Z",
     "shell.execute_reply.started": "2022-06-04T13:14:11.302219Z"
    },
    "papermill": {
     "duration": 6.007322,
     "end_time": "2022-06-04T13:15:59.706643",
     "exception": false,
     "start_time": "2022-06-04T13:15:53.699321",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "import statistics\n",
    "from tabulate import tabulate\n",
    "from sklearn.metrics import accuracy_score, log_loss,  f1_score\n",
    "\n",
    "# https://www.kaggle.com/c/ventilator-pressure-prediction/discussion/274717\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.applications import Xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d26fd0d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-04T13:16:02.127594Z",
     "iopub.status.busy": "2022-06-04T13:16:02.126928Z",
     "iopub.status.idle": "2022-06-04T13:16:02.130888Z",
     "shell.execute_reply": "2022-06-04T13:16:02.131388Z",
     "shell.execute_reply.started": "2022-06-04T13:14:13.263115Z"
    },
    "papermill": {
     "duration": 2.413369,
     "end_time": "2022-06-04T13:16:02.131537",
     "exception": false,
     "start_time": "2022-06-04T13:15:59.718168",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU at: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "# Making sure that Tensorflow is able to detect the GPU\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if \"GPU\" not in device_name:\n",
    "    print(\"GPU device not found\")\n",
    "print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2caa0bbb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-04T13:16:02.162413Z",
     "iopub.status.busy": "2022-06-04T13:16:02.161588Z",
     "iopub.status.idle": "2022-06-04T13:16:02.163433Z",
     "shell.execute_reply": "2022-06-04T13:16:02.163870Z",
     "shell.execute_reply.started": "2022-06-04T13:14:13.970183Z"
    },
    "papermill": {
     "duration": 0.020283,
     "end_time": "2022-06-04T13:16:02.164008",
     "exception": false,
     "start_time": "2022-06-04T13:16:02.143725",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# These are the usual ipython objects\n",
    "ipython_vars = ['In', 'Out', 'exit', 'quit', 'get_ipython', 'ipython_vars']\n",
    "\n",
    "# Defining a function to list the memory consumed\n",
    "# Only outputs variables taking at least 1MB space\n",
    "def list_storage(inp_dir):\n",
    "    # Get a sorted list of the objects and their sizes\n",
    "    vars_defined = [x for x in inp_dir if not x.startswith('_') and x not in sys.modules and x not in ipython_vars]\n",
    "    sto = sorted([(x, sys.getsizeof(globals().get(x))) for x in vars_defined], key=lambda x: x[1], reverse=True)\n",
    "    sto = [(x[0], str(round((x[1] / 2**20), 2)) + ' MB') for x in sto if x[1] >= 2**20]\n",
    "    print(tabulate(sto, headers = ['Variable', 'Storage (in MB)']))\n",
    "\n",
    "# In order to use this function, use the below line of code\n",
    "# list_storage(dir())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5088e5d",
   "metadata": {
    "papermill": {
     "duration": 0.01084,
     "end_time": "2022-06-04T13:16:02.185868",
     "exception": false,
     "start_time": "2022-06-04T13:16:02.175028",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 2. Importing the Train and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c215e34",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-04T13:16:02.218445Z",
     "iopub.status.busy": "2022-06-04T13:16:02.217824Z",
     "iopub.status.idle": "2022-06-04T13:16:31.929876Z",
     "shell.execute_reply": "2022-06-04T13:16:31.929412Z",
     "shell.execute_reply.started": "2022-06-04T13:14:13.982747Z"
    },
    "papermill": {
     "duration": 29.732768,
     "end_time": "2022-06-04T13:16:31.930015",
     "exception": false,
     "start_time": "2022-06-04T13:16:02.197247",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Train Dataset:\n",
      "(40006, 3072) (40006, 1)\n",
      "(40006, 32, 32, 3)\n",
      "For Test Dataset:\n",
      "(10000, 3072) (10000, 1)\n",
      "(10000, 3, 32, 32)\n",
      "(10000, 32, 32, 3) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "# Importing the Labelled Training Dataset\n",
    "print(\"For Train Dataset:\")\n",
    "df_train = pd.read_csv(\"../input/cifar10/train_lab_x.csv\")\n",
    "y_train = pd.read_csv(\"../input/cifar10/train_lab_y.csv\")\n",
    "df_train = np.array(df_train)\n",
    "y_train = np.array(y_train)\n",
    "print(df_train.shape, y_train.shape)\n",
    "\n",
    "# Reshaping, rescaling and one-hot encoding\n",
    "df_train = np.reshape(df_train, (-1, 3, 32, 32))\n",
    "df_train = np.transpose(np.array(df_train), (0, 2, 3, 1))\n",
    "df_train = df_train / 255\n",
    "print(df_train.shape)\n",
    "\n",
    "# Importing the Test Dataset\n",
    "print(\"For Test Dataset:\")\n",
    "df_test = pd.read_csv(\"../input/cifar10/test_x.csv\")\n",
    "y_test = pd.read_csv(\"../input/cifar10/test_y.csv\")\n",
    "df_test = np.array(df_test)\n",
    "y_test = np.array(y_test)\n",
    "print(df_test.shape, y_test.shape)\n",
    "\n",
    "# Reshaping the dataset\n",
    "df_test = np.reshape(df_test, (-1, 3, 32, 32))\n",
    "print(df_test.shape)\n",
    "\n",
    "# Reshaping, rescaling and one-hot encoding\n",
    "df_test = np.transpose(np.array(df_test), (0, 2, 3, 1))\n",
    "df_test = df_test / 255\n",
    "y_test_oh = tf.one_hot(np.ravel(y_test), depth = 10)\n",
    "print(df_test.shape, y_test_oh.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7f17cb",
   "metadata": {
    "papermill": {
     "duration": 0.012673,
     "end_time": "2022-06-04T13:16:31.955750",
     "exception": false,
     "start_time": "2022-06-04T13:16:31.943077",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 3. Loading the fine-tuned Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3af7e9a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-04T13:16:31.986365Z",
     "iopub.status.busy": "2022-06-04T13:16:31.985789Z",
     "iopub.status.idle": "2022-06-04T13:16:40.337363Z",
     "shell.execute_reply": "2022-06-04T13:16:40.336861Z",
     "shell.execute_reply.started": "2022-06-04T13:14:38.402454Z"
    },
    "papermill": {
     "duration": 8.368976,
     "end_time": "2022-06-04T13:16:40.337497",
     "exception": false,
     "start_time": "2022-06-04T13:16:31.968521",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "to_res = (64,64)\n",
    "model1 = tf.keras.models.load_model('../input/dcai-rw/xcptn_model.h5')\n",
    "model2 = tf.keras.models.load_model('../input/dcai-rw/mobilenet_model.h5')\n",
    "model3 = tf.keras.models.load_model('../input/dcai-rw/vgg16_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ed6bcf7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-04T13:16:40.371816Z",
     "iopub.status.busy": "2022-06-04T13:16:40.370937Z",
     "iopub.status.idle": "2022-06-04T13:16:57.267692Z",
     "shell.execute_reply": "2022-06-04T13:16:57.268222Z",
     "shell.execute_reply.started": "2022-06-04T13:14:46.005355Z"
    },
    "papermill": {
     "duration": 16.917801,
     "end_time": "2022-06-04T13:16:57.268412",
     "exception": false,
     "start_time": "2022-06-04T13:16:40.350611",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Xception Model:\n",
      "Accuracy for Test Dataset:  0.8957\n",
      "Log-loss for Test Dataset:  0.8017136794626224\n",
      "Weighted F1 Score for Test Dataset =  0.8956651393697893\n",
      "\n",
      "For MobileNet Model:\n",
      "Accuracy for Test Dataset:  0.8668\n",
      "Log-loss for Test Dataset:  1.0053337612657762\n",
      "Weighted F1 Score for Test Dataset =  0.8667049942870388\n",
      "\n",
      "For VGG16 Model:\n",
      "Accuracy for Test Dataset:  0.7992\n",
      "Log-loss for Test Dataset:  1.6821733511582482\n",
      "Weighted F1 Score for Test Dataset =  0.798454250467614\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds_test1 = model1.predict(df_test)\n",
    "cls_test1 = np.argmax(preds_test1, axis = 1)\n",
    "print(\"For Xception Model:\")\n",
    "print(\"Accuracy for Test Dataset: \", accuracy_score(y_test, cls_test1))\n",
    "print(\"Log-loss for Test Dataset: \", log_loss(y_test_oh, preds_test1))\n",
    "print(\"Weighted F1 Score for Test Dataset = \", f1_score(y_test, cls_test1, average = 'weighted'))\n",
    "print()\n",
    "\n",
    "preds_test2 = model2.predict(df_test)\n",
    "cls_test2 = np.argmax(preds_test2, axis = 1)\n",
    "print(\"For MobileNet Model:\")\n",
    "print(\"Accuracy for Test Dataset: \", accuracy_score(y_test, cls_test2))\n",
    "print(\"Log-loss for Test Dataset: \", log_loss(y_test_oh, preds_test2))\n",
    "print(\"Weighted F1 Score for Test Dataset = \", f1_score(y_test, cls_test2, average = 'weighted'))\n",
    "print()\n",
    "\n",
    "preds_test3 = model3.predict(df_test)\n",
    "cls_test3 = np.argmax(preds_test3, axis = 1)\n",
    "print(\"For VGG16 Model:\")\n",
    "print(\"Accuracy for Test Dataset: \", accuracy_score(y_test, cls_test3))\n",
    "print(\"Log-loss for Test Dataset: \", log_loss(y_test_oh, preds_test3))\n",
    "print(\"Weighted F1 Score for Test Dataset = \", f1_score(y_test, cls_test3, average = 'weighted'))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb87e0a",
   "metadata": {
    "papermill": {
     "duration": 0.014811,
     "end_time": "2022-06-04T13:16:57.297377",
     "exception": false,
     "start_time": "2022-06-04T13:16:57.282566",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 4. Performing the Ensembling\n",
    "## 4.1. Relative Weighting of the Predictions\n",
    "- Since the Xception Model has the largest test set accuracy, followed by the MobileNet model, and then lastly, the VGG16 Model, hence, we will be using relative weights inspired by this intuition only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "061854d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-04T13:16:57.336321Z",
     "iopub.status.busy": "2022-06-04T13:16:57.335622Z",
     "iopub.status.idle": "2022-06-04T13:16:57.441698Z",
     "shell.execute_reply": "2022-06-04T13:16:57.441256Z",
     "shell.execute_reply.started": "2022-06-04T13:14:57.494555Z"
    },
    "papermill": {
     "duration": 0.129012,
     "end_time": "2022-06-04T13:16:57.441841",
     "exception": false,
     "start_time": "2022-06-04T13:16:57.312829",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xception:  0.5  MobileNet:  0.3  VGG16:  0.2\n",
      "Accuracy for Test Dataset:  0.905\n",
      "Log-loss for Test Dataset:  0.4107004970640091\n",
      "Weighted F1 Score for Test Dataset =  0.90481535464968\n",
      "\n",
      "Xception:  0.45  MobileNet:  0.35  VGG16:  0.2\n",
      "Accuracy for Test Dataset:  0.9025\n",
      "Log-loss for Test Dataset:  0.4111881832950033\n",
      "Weighted F1 Score for Test Dataset =  0.9022976729760547\n",
      "\n",
      "Xception:  0.4  MobileNet:  0.35  VGG16:  0.25\n",
      "Accuracy for Test Dataset:  0.9013\n",
      "Log-loss for Test Dataset:  0.4162126540434949\n",
      "Weighted F1 Score for Test Dataset =  0.9010838673888512\n",
      "\n",
      "Xception:  0.35  MobileNet:  0.35  VGG16:  0.3\n",
      "Accuracy for Test Dataset:  0.9016\n",
      "Log-loss for Test Dataset:  0.4232345016994275\n",
      "Weighted F1 Score for Test Dataset =  0.9014082700565781\n",
      "\n",
      "Xception:  0.6  MobileNet:  0.3  VGG16:  0.1\n",
      "Accuracy for Test Dataset:  0.9026\n",
      "Log-loss for Test Dataset:  0.4093135084820644\n",
      "Weighted F1 Score for Test Dataset =  0.9024842394961444\n",
      "\n",
      "For ensembling based on Relative Weighting:\n",
      "The optimal relative weights are  [0.5, 0.3, 0.2]\n",
      "Accuracy for Test Dataset:  0.905\n",
      "Log-loss for Test Dataset:  0.4107004970640091\n",
      "Weighted F1 Score for Test Dataset =  0.90481535464968\n"
     ]
    }
   ],
   "source": [
    "# List of relative weighting to try\n",
    "rel_weights = [\n",
    "    [0.5, 0.3, 0.2],\n",
    "    [0.45, 0.35, 0.2],\n",
    "    [0.40, 0.35, 0.25],\n",
    "    [0.35, 0.35, 0.3],\n",
    "    [0.6, 0.3, 0.1]\n",
    "]\n",
    "\n",
    "test_acc, test_log_loss, test_f1_score = [], [], []\n",
    "\n",
    "for weights in rel_weights:\n",
    "    print(\"Xception: \", weights[0], \" MobileNet: \", weights[1], \" VGG16: \", weights[2])\n",
    "    preds_test = weights[0] * preds_test1 + weights[1] * preds_test2 + weights[2] * preds_test3\n",
    "    cls_test = np.argmax(preds_test, axis = 1)\n",
    "    test_acc.append(accuracy_score(y_test, cls_test))\n",
    "    test_log_loss.append(log_loss(y_test_oh, preds_test))\n",
    "    test_f1_score.append(f1_score(y_test, cls_test, average = 'weighted'))\n",
    "    print(\"Accuracy for Test Dataset: \", test_acc[-1])\n",
    "    print(\"Log-loss for Test Dataset: \", test_log_loss[-1])\n",
    "    print(\"Weighted F1 Score for Test Dataset = \", test_f1_score[-1])\n",
    "    print()\n",
    "    \n",
    "best_index = np.argmax(test_acc)\n",
    "print(\"For ensembling based on Relative Weighting:\")\n",
    "print(\"The optimal relative weights are \", rel_weights[best_index])\n",
    "print(\"Accuracy for Test Dataset: \", test_acc[best_index])\n",
    "print(\"Log-loss for Test Dataset: \", test_log_loss[best_index])\n",
    "print(\"Weighted F1 Score for Test Dataset = \", test_f1_score[best_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44c2027",
   "metadata": {
    "papermill": {
     "duration": 0.0137,
     "end_time": "2022-06-04T13:16:57.470075",
     "exception": false,
     "start_time": "2022-06-04T13:16:57.456375",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 4.2. Majority Vote of the Predicted Class Labels\n",
    "- In the previous method, we were able to find out the log-loss and accuracy both, since, we have performed ensembling on the predictions themselves.\n",
    "- In this method, we can only find the accuracy, since, we are performing the ensembling only on the predicted classes, and not on the predicted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "722e6b5e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-04T13:16:57.526641Z",
     "iopub.status.busy": "2022-06-04T13:16:57.511381Z",
     "iopub.status.idle": "2022-06-04T13:16:57.757836Z",
     "shell.execute_reply": "2022-06-04T13:16:57.758837Z",
     "shell.execute_reply.started": "2022-06-04T13:14:57.608945Z"
    },
    "papermill": {
     "duration": 0.27506,
     "end_time": "2022-06-04T13:16:57.759048",
     "exception": false,
     "start_time": "2022-06-04T13:16:57.483988",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For ensembling based on Majority Vote:\n",
      "Accuracy for Test Dataset:  0.9001\n",
      "Weighted F1 Score for Test Dataset =  0.8999355290166248\n"
     ]
    }
   ],
   "source": [
    "cls_test = []\n",
    "for i in range(len(cls_test1)):\n",
    "    classes = [cls_test1[i], cls_test2[i], cls_test3[i]]\n",
    "    \n",
    "    # Case 1: When the 3 models predict different class labels\n",
    "    # Selecting the class label corresponding to Xception Net\n",
    "    if len(np.unique(classes)) == len(classes):\n",
    "        cls_test.append(cls_test1[i])\n",
    "    \n",
    "    # Case 2: When at least 2 models predict the same class label\n",
    "    # Selecting the majority class\n",
    "    else:\n",
    "        cls_test.append(np.bincount(classes).argmax())\n",
    "        \n",
    "print(\"For ensembling based on Majority Vote:\")\n",
    "print(\"Accuracy for Test Dataset: \", accuracy_score(y_test, cls_test))\n",
    "print(\"Weighted F1 Score for Test Dataset = \", f1_score(y_test, cls_test, average = 'weighted'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 76.309003,
   "end_time": "2022-06-04T13:17:01.300117",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-06-04T13:15:44.991114",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
