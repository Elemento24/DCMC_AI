{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# A Simple Framework for Contrastive Learning of Visual Representations\n* In this notebook, we will be implementing the code for SimCLR.\n* We have done the augmentation, as per the original code provided the researchers behind this paper.\n* [Reference](http://proceedings.mlr.press/v119/chen20j.html) for the paper","metadata":{}},{"cell_type":"markdown","source":"# Importing Packages and Boilerplate code","metadata":{}},{"cell_type":"code","source":"pip install imutils","metadata":{"execution":{"iopub.status.busy":"2022-04-15T16:21:16.679109Z","iopub.execute_input":"2022-04-15T16:21:16.679398Z","iopub.status.idle":"2022-04-15T16:21:24.037153Z","shell.execute_reply.started":"2022-04-15T16:21:16.679366Z","shell.execute_reply":"2022-04-15T16:21:24.036305Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"Requirement already satisfied: imutils in /opt/conda/lib/python3.7/site-packages (0.5.4)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Basic Imports \nimport math\nimport numpy as np \nimport pandas as pd\nimport tensorflow as tf\nimport tensorflow_datasets as tfds\nfrom tensorflow.keras.models import *\n\n# Plotting libraries\nimport seaborn as sns \nimport matplotlib.pyplot as plt\nplt.style.use('seaborn')\n\n# Utilities\nimport datetime\nimport os,sys\nimport tempfile\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\nsys.path.append(\"/kaggle/input/helper-files\")\nimport random \nimport gc\nimport time\nimport functools\nfrom imutils import paths\nfrom tqdm import tqdm\nfrom typing import Callable\n\n# Random seed fixation for experiment result repitition\ntf.random.set_seed(10)\nnp.random.seed(10)\n\nprint(\"Tensorflow version : \",tf.__version__)\nfrom shutil import copyfile\nfrom tabulate import tabulate\nfrom sklearn.metrics import accuracy_score, log_loss, confusion_matrix\nimport tensorflow.keras.layers as tfl","metadata":{"execution":{"iopub.status.busy":"2022-04-15T16:29:17.316293Z","iopub.execute_input":"2022-04-15T16:29:17.316666Z","iopub.status.idle":"2022-04-15T16:29:17.327455Z","shell.execute_reply.started":"2022-04-15T16:29:17.316530Z","shell.execute_reply":"2022-04-15T16:29:17.326577Z"},"trusted":true},"execution_count":56,"outputs":[{"name":"stdout","text":"Tensorflow version :  2.6.2\n","output_type":"stream"}]},{"cell_type":"code","source":"# Setting the seeds\nSEED = 0\nos.environ['PYTHONHASHSEED']=str(SEED)\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntf.random.set_seed(SEED)","metadata":{"execution":{"iopub.status.busy":"2022-04-15T16:21:24.054604Z","iopub.execute_input":"2022-04-15T16:21:24.054894Z","iopub.status.idle":"2022-04-15T16:21:24.061897Z","shell.execute_reply.started":"2022-04-15T16:21:24.054854Z","shell.execute_reply":"2022-04-15T16:21:24.061129Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"# Making sure that Tensorflow is able to detect the GPU\ndevice_name = tf.test.gpu_device_name()\nif \"GPU\" not in device_name:\n    print(\"GPU device not found\")\nprint('Found GPU at: {}'.format(device_name))","metadata":{"execution":{"iopub.status.busy":"2022-04-15T16:21:24.064857Z","iopub.execute_input":"2022-04-15T16:21:24.065415Z","iopub.status.idle":"2022-04-15T16:21:24.075387Z","shell.execute_reply.started":"2022-04-15T16:21:24.065372Z","shell.execute_reply":"2022-04-15T16:21:24.074637Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"Found GPU at: /device:GPU:0\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Importing Train/Test Sets","metadata":{}},{"cell_type":"code","source":"# These are the usual ipython objects\nipython_vars = ['In', 'Out', 'exit', 'quit', 'get_ipython', 'ipython_vars']\n\n# Defining a function to list the memory consumed\n# Only outputs variables taking at least 1MB space\ndef list_storage(inp_dir):\n    # Get a sorted list of the objects and their sizes\n    vars_defined = [x for x in inp_dir if not x.startswith('_') and x not in sys.modules and x not in ipython_vars]\n    sto = sorted([(x, sys.getsizeof(globals().get(x))) for x in vars_defined], key=lambda x: x[1], reverse=True)\n    sto = [(x[0], str(round((x[1] / 2**20), 2)) + ' MB') for x in sto if x[1] >= 2**20]\n    print(tabulate(sto, headers = ['Variable', 'Storage (in MB)']))\n\n# In order to use this function, use the below line of code\n# list_storage(dir())","metadata":{"execution":{"iopub.status.busy":"2022-04-15T16:21:24.077175Z","iopub.execute_input":"2022-04-15T16:21:24.077757Z","iopub.status.idle":"2022-04-15T16:21:24.086861Z","shell.execute_reply.started":"2022-04-15T16:21:24.077718Z","shell.execute_reply":"2022-04-15T16:21:24.086059Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"# Importing the Labelled Dataset\ndf_train = pd.read_csv(\"../input/cifar10/train_lab_x.csv\")\ny_train = pd.read_csv(\"../input/cifar10/train_lab_y.csv\")\n\n# Importing the Test Dataset\ndf_test = pd.read_csv(\"../input/cifar10/test_x.csv\")\ny_test = pd.read_csv(\"../input/cifar10/test_y.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-04-15T16:21:24.088498Z","iopub.execute_input":"2022-04-15T16:21:24.089108Z","iopub.status.idle":"2022-04-15T16:21:46.855987Z","shell.execute_reply.started":"2022-04-15T16:21:24.089067Z","shell.execute_reply":"2022-04-15T16:21:46.855043Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"markdown","source":"# Basic Augmentation Pipeline","metadata":{}},{"cell_type":"code","source":"df_train = np.array(df_train)\ny_train = np.array(y_train)\nprint(df_train.shape, y_train.shape)\n\n# Reshaping the dataset\ndf_train = np.reshape(df_train, (-1, 3, 32, 32))\nprint(df_train.shape)\n\n# Visualizing a single image\nind = 11\nexample = df_train[ind, : , : , : ]\nexample = example.transpose((1, 2, 0))\nplt.figure(figsize=(1.5, 1.5))\nplt.imshow(example)\nprint(y_train[ind])\n\n# Creating a random permutation\nperm = np.random.permutation(df_train.shape[0])\n\n# Shuffling the training dataset\ndf_train = df_train[perm, : , : , : ]\ny_train = y_train[perm]\n\n# Reshaping, rescaling and one-hot encoding\ndf_train = np.transpose(np.array(df_train), (0, 2, 3, 1))\ndf_train = df_train / 255\ny_train_oh = tf.one_hot(np.ravel(y_train), depth = 10)\n\nprint(df_train.shape, y_train_oh.shape)\n\ndf_test = np.array(df_test)\ny_test = np.array(y_test)\nprint(df_test.shape, y_test.shape)\n\n# Reshaping the dataset\ndf_test = np.reshape(df_test, (-1, 3, 32, 32))\nprint(df_test.shape)\n\n# Reshaping, rescaling and one-hot encoding\ndf_test = np.transpose(np.array(df_test), (0, 2, 3, 1))\ndf_test = df_test / 255\ny_test_oh = tf.one_hot(np.ravel(y_test), depth = 10)\nprint(df_test.shape, y_test_oh.shape)\n\n# Random seed fixation for experiment result repitition\ntf.random.set_seed(10)\nnp.random.seed(10)\n\nprint(\"Tensorflow version : \",tf.__version__)\n\n# In-order run function decorators in tf2.0\ntf.config.run_functions_eagerly(False)","metadata":{"execution":{"iopub.status.busy":"2022-04-15T16:21:46.857414Z","iopub.execute_input":"2022-04-15T16:21:46.857696Z","iopub.status.idle":"2022-04-15T16:21:50.100791Z","shell.execute_reply.started":"2022-04-15T16:21:46.857659Z","shell.execute_reply":"2022-04-15T16:21:50.099958Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"(40006, 3072) (40006, 1)\n(40006, 3, 32, 32)\n[0]\n(40006, 32, 32, 3) (40006, 10)\n(10000, 3072) (10000, 1)\n(10000, 3, 32, 32)\n(10000, 32, 32, 3) (10000, 10)\nTensorflow version :  2.6.2\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 108x108 with 1 Axes>","image/png":"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\n"},"metadata":{}}]},{"cell_type":"markdown","source":"## Helper Code","metadata":{}},{"cell_type":"code","source":"# Image training properties \nIMG_H, IMG_W = (32, 32)\n\n# How powerful you want the colour augmentations to be\ncolor_jitter_strength = 0.3\n\n# Minimum crop area you want\nminimum_object_coverage = 0.7\n\n# Range of crop area\narea_range = (minimum_object_coverage, 1.0)\nBATCH_SIZE = 32","metadata":{"execution":{"iopub.status.busy":"2022-04-15T16:21:50.102214Z","iopub.execute_input":"2022-04-15T16:21:50.102685Z","iopub.status.idle":"2022-04-15T16:21:50.108924Z","shell.execute_reply.started":"2022-04-15T16:21:50.102646Z","shell.execute_reply":"2022-04-15T16:21:50.107662Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"markdown","source":"# Model Building\n## Model Helper Functions","metadata":{}},{"cell_type":"code","source":"# Helper functions\n@tf.function\ndef input_image_loader(image):\n    image_norm = tf.image.convert_image_dtype(image, tf.float32)\n    \n    # The IMG_H & IMG_W are constants that will be read only once during graph tracing step\n    image_norm = tf.image.resize(image_norm, size=[IMG_H, IMG_W])\n    \n\n    aug_image_1 = preprocess_image(image = image_norm, \n                                    height = IMG_H, \n                                    width  = IMG_W, \n                                    cjs = color_jitter_strength,\n                                    m_obj_cov = minimum_object_coverage,\n                                    a_range = area_range)\n\n    aug_image_2 = preprocess_image(image = image_norm, \n                                    height = IMG_H, \n                                    width  = IMG_W, \n                                    cjs = color_jitter_strength,\n                                    m_obj_cov = minimum_object_coverage,\n                                    a_range = area_range)\n    # view 1 & view 2\n    return aug_image_1, aug_image_2","metadata":{"execution":{"iopub.status.busy":"2022-04-15T16:21:50.110941Z","iopub.execute_input":"2022-04-15T16:21:50.111527Z","iopub.status.idle":"2022-04-15T16:21:50.122222Z","shell.execute_reply.started":"2022-04-15T16:21:50.111482Z","shell.execute_reply":"2022-04-15T16:21:50.121195Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"# adding l2 reg\ndef add_regularization(model, regularizer = tf.keras.regularizers.l2(0.0001)):\n    \"\"\"\n    Helper function to add l2 regularisation to each layer of a either a preTrained or \n    randomly initialised built in model\n    Arguments:\n        model : (keras.model) input model \n        regularizer : ( tf.keras.regularizers.l2) object from keras that defines a l2 regularizer\n    Returns:\n        model : all layers contain the \"regularizer\" object & incase we pass a pretrained model then the \n                original weights are preserved\n    \"\"\"\n\n    if not isinstance(regularizer, tf.keras.regularizers.Regularizer):\n        print(\"Regularizer must be a subclass of tf.keras.regularizers.Regularizer\")\n        return model\n\n    for layer in model.layers:\n        for attr in ['kernel_regularizer']:\n            if hasattr(layer, attr):\n                setattr(layer, attr, regularizer)\n\n    # When we change the layers attributes, the change only happens in the model config file\n    model_json = model.to_json()\n\n    # Save the weights before reloading the model.\n    tmp_weights_path = os.path.join(tempfile.gettempdir(), 'tmp_weights.h5')\n    model.save_weights(tmp_weights_path)\n\n    # load the model from the config\n    model = tf.keras.models.model_from_json(model_json)\n    \n    # Reload the model weights\n    model.load_weights(tmp_weights_path, by_name=True)\n    return model\n\n# Architecture utils\n# def get_simclr(hidden_1, \n#                hidden_2, \n#                l2_penalty = 10e-6):\ndef simclr_model(input_shape):\n    \"\"\"\n    Main function to define the entire network backbone to train\n    Arguments:\n        hidden_1-2 : (int) variable to define number of neurons in the projection head dense layer\n        l2_penalty : (float) to define the amount of l2 penalty applied to each layer's weights\n    Returns:\n        final_model : (tf.keras.Model) final model that will be trained \n    \"\"\"\n    \n#     # encoder network\n#     base_model = tf.keras.applications.ResNet50V2(include_top = False, \n#                                                   weights = None, \n#                                                   input_shape = (IMG_H, IMG_W, 3))\n    \n#     # defining l2 regularization\n#     regularizer = tf.keras.regularizers.l2(l2_penalty)\n#     reg_base_model = add_regularization(base_model,regularizer)\n#     reg_base_model.trainable = True\n\n#     # Joining the entire pipeline using functional API\n    inputs = Input((IMG_H, IMG_W, 3))\n#     h = reg_base_model(inputs, training=True)\n#     h = GlobalAveragePooling2D()(h)\n    \n#     # Non linear projection layer to improve the quality of embeddings being produced\n#     projection_1 = Dense(hidden_1, kernel_regularizer = regularizer)(h)\n#     projection_1 = tf.keras.layers.BatchNormalization()(projection_1)\n#     projection_1 = Activation(\"relu\")(projection_1)\n#     projection_2 = Dense(hidden_2, kernel_regularizer = regularizer)(projection_1)\n#     projection_2 = tf.keras.layers.BatchNormalization()(projection_2)\n#     projection_2 = Activation(\"relu\")(projection_2)\n\n    input_img = tf.keras.Input(shape = input_shape)\n    \n    Z1 = tfl.Conv2D(16, kernel_size=3, strides=1, padding='same', activation='relu')(input_img)\n    B1 = tfl.BatchNormalization(axis=-1)(Z1)\n    Z2 = tfl.Conv2D(16, kernel_size=3, strides=1, padding='same', activation='relu')(B1)\n    B2 = tfl.BatchNormalization(axis=-1)(Z2)\n    P1 = tfl.MaxPool2D(pool_size=2, strides=2, padding='valid')(B2)\n    D1 = tfl.Dropout(0.25)(P1)\n    # (16, 16, 16)\n    \n    Z3 = tfl.Conv2D(32, kernel_size=2, strides=1, padding='valid', activation='relu')(D1)\n    B3 = tfl.BatchNormalization(axis=-1)(Z3)\n    Z4 = tfl.Conv2D(32, kernel_size=2, strides=1, padding='valid', activation='relu')(B3)\n    B4 = tfl.BatchNormalization(axis=-1)(Z4)\n    P2 = tfl.MaxPool2D(pool_size=2, strides=2, padding='valid')(B4)\n    D2 = tfl.Dropout(0.25)(P2)\n    # (7, 7, 32)\n    \n    F1 = tfl.Flatten()(D2)\n    Den1 = tfl.Dense(256, activation='relu')(F1)\n    Drop1 = tfl.Dropout(0.25)(Den1)\n    Den2 = tfl.Dense(64, activation='relu')(Drop1)\n    Drop2 = tfl.Dropout(0.25)(Den2)\n    outputs = tfl.Dense(10, activation='softmax')(Drop2)\n    \n    model = tf.keras.Model(inputs = input_img, outputs = outputs)\n    return model\n\n    # Final Model\n    final_model = Model(inputs, outputs)\n    return final_model","metadata":{"execution":{"iopub.status.busy":"2022-04-15T16:21:50.126050Z","iopub.execute_input":"2022-04-15T16:21:50.126942Z","iopub.status.idle":"2022-04-15T16:21:50.148071Z","shell.execute_reply.started":"2022-04-15T16:21:50.126897Z","shell.execute_reply":"2022-04-15T16:21:50.146806Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"markdown","source":"## Train Step Functions","metadata":{}},{"cell_type":"code","source":"# Mask to remove positive examples from the batch of negative samples\n# negative_mask = helpers.get_negative_mask(BATCH_SIZE)","metadata":{"execution":{"iopub.status.busy":"2022-04-15T16:21:50.150061Z","iopub.execute_input":"2022-04-15T16:21:50.150434Z","iopub.status.idle":"2022-04-15T16:21:50.159896Z","shell.execute_reply.started":"2022-04-15T16:21:50.150376Z","shell.execute_reply":"2022-04-15T16:21:50.158826Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"@tf.function\ndef train_step(xis, \n               xjs, \n               model, \n               optimizer, \n               criterion, \n               temperature):\n\n    with tf.GradientTape() as tape:\n        zis = model(xis)\n        zjs = model(xjs)\n\n        # normalize projection feature vectors : onto a unit hypersphere\n        zis = tf.math.l2_normalize(zis, axis=1)\n        zjs = tf.math.l2_normalize(zjs, axis=1)\n          \n        # calculating over set of all positive pairs ( computing all numerators of softmax)\n        l_pos = sim_func_dim1(zis, zjs)\n        l_pos = tf.reshape(l_pos, (BATCH_SIZE, 1))\n\n        # temperature scaling\n        l_pos /= temperature\n        \n        # make the batch dimension 2*n\n        negatives = tf.concat([zjs, zis], axis=0)\n\n        loss = 0\n        for positives in [zis, zjs]:\n            # computing similarity with a data point & all the possible negatives\n            l_neg = sim_func_dim2(positives, negatives)\n            \n            # since each data point is its own class\n            labels = tf.zeros(BATCH_SIZE, dtype=tf.int32)\n            \n            # using the negative mask to remove itself & its positve counterpart to compute negative sim\n            l_neg = tf.boolean_mask(l_neg, negative_mask)\n            l_neg = tf.reshape(l_neg, (BATCH_SIZE, -1))\n\n            # temperature scaling\n            l_neg /= temperature\n\n            logits = tf.concat([l_pos, l_neg], axis=1) \n            loss += criterion(y_pred = logits, y_true = labels)\n\n        # since for every data point including its augmentation we compute the loss thus divide by 2*BatchSize\n        loss = loss / (2 * BATCH_SIZE)\n    \n    # Compute & apply the gradients on traininable paramters of the model\n    gradients = tape.gradient(loss, model.trainable_variables)\n    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n    \n    # updated model along with gradients so that we can visualise them on tensorboard.\n    return loss, gradients","metadata":{"execution":{"iopub.status.busy":"2022-04-15T16:21:50.162936Z","iopub.execute_input":"2022-04-15T16:21:50.163341Z","iopub.status.idle":"2022-04-15T16:21:50.177345Z","shell.execute_reply.started":"2022-04-15T16:21:50.163293Z","shell.execute_reply":"2022-04-15T16:21:50.176050Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"def train_simclr(model, \n                 train_dataset, \n                 optimizer, \n                 criterion,\n                 temperature=0.1, \n                 epochs=100,\n                 num_train_samples_viz = 5,\n                 num_test_samples_viz = 2):\n    \n    \"\"\"\n      Training the model function\n    \"\"\"\n    \n \n    print(\"Starting training procedure .... : \")\n    print(\"Number of steps per epoch : \",len(train_dataset))\n    \n    # To measure per epoch time taken\n    t_start = time.time()\n    \n    # Visualisation lists\n    lr_epoch = []\n    epoch_wise_loss = []\n\n    for epoch in range(0, epochs):\n        \n        # Reset loss collection each step\n        step_wise_loss = []\n\n        # Number of grad descent steps in 1 epoch\n        num_train_steps = len(train_dataset) \n\n        # Picking up random batches & taking first image for input check\n        random_batches_train = random.sample(range(len(train_dataset)),num_train_samples_viz)\n        cnt = 0\n\n        # Arrays for tensorboard visualisation\n        random_collection_train_sample_1 = []\n        random_collection_train_sample_2 = []\n        gradArray = None\n        loss = None \n\n        # Training loop\n        for image_batch in tqdm(train_dataset):\n\n            # Fetching both views for input\n            a = image_batch[0]\n            b = image_batch[1]\n\n            # Train one batch\n            loss, gradArray = train_step(a, b, model, optimizer, criterion, temperature)\n            step_wise_loss.append(loss)\n\n            # Check whether to take image from this batch or not\n            if cnt in random_batches_train:\n                random_collection_train_sample_1.append(image_batch[0][0])\n                random_collection_train_sample_2.append(image_batch[1][0])\n            cnt+=1\n        \n        # Average loss throughout the whole process\n        if not len(epoch_wise_loss):\n            epoch_wise_loss.append(np.mean(step_wise_loss))\n        else:\n            # Adding the mean of previous ones\n            mean_value = (np.sum(step_wise_loss) + epoch_wise_loss[-1]*(epoch)*num_train_steps)/((epoch+1)*num_train_steps)\n            epoch_wise_loss.append(mean_value)\n        \n        # Printing the loss progression\n        print(\"\\n epoch: {} | train loss: {:.8f} | lr : {} | {:.4f} mins\"\n              .format(epoch + 1,epoch_wise_loss[-1],optimizer._decayed_lr(tf.float32).numpy(), (time.time()-t_start)/60.0))    \n   \n        # Appending the value of learning rate for warmup + cosine decay visualisation\n        lr_epoch.append(optimizer._decayed_lr(tf.float32).numpy())\n        \n        # Tensorfboard visualisations\n        tf.summary.experimental.set_step(epoch)\n        with train_summary_writer.as_default():\n            tf.summary.scalar('LOSS', epoch_wise_loss[-1], step=epoch)\n            tf.summary.scalar('LEARNING RATE PROGRESSION', lr_epoch[-1], step = epoch)\n            tf.summary.image('VIEW 1', random_collection_train_sample_1, step=epoch)\n            tf.summary.image('VIEW 2', random_collection_train_sample_2, step=epoch)\n\n            # global variable defined later\n            for name in layer_names:\n                tf.summary.histogram(name+\"_gradients\",gradArray[layer_to_index[name]])\n                \n            for layer in model.layers:\n                for tl in layer.trainable_weights:\n                    if tl.name in layer_names:\n                        tf.summary.histogram(tl.name+\"_weights\",tl.numpy())\n        \n        # saving models \n        print(\"Saving Base Model.....\")\n        \n        # Saving the entire model for checkpointing reasons\n        model.save(\"./\" + modelNameStr + \".h5\")\n\n        # saving the state of optimizer\n        np.save(\"./\" + modelNameStr + \"_optimizer.npy\", optimizer.get_weights())\n\n    \n    return epoch_wise_loss, model","metadata":{"execution":{"iopub.status.busy":"2022-04-15T16:21:50.179636Z","iopub.execute_input":"2022-04-15T16:21:50.180493Z","iopub.status.idle":"2022-04-15T16:21:50.202682Z","shell.execute_reply.started":"2022-04-15T16:21:50.180446Z","shell.execute_reply":"2022-04-15T16:21:50.201914Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"class WarmUp(tf.keras.optimizers.schedules.LearningRateSchedule):\n  def __init__(self,\n               initial_learning_rate: float,\n               decay_schedule_fn: Callable,\n               warmup_steps: int,\n               power: float = 1.0,\n               name: str = None,):\n    \n    super().__init__()\n    self.initial_learning_rate = initial_learning_rate\n    self.warmup_steps = warmup_steps\n    self.power = power\n    self.decay_schedule_fn = decay_schedule_fn\n    self.name = name\n\n  def __call__(self, step):\n    with tf.name_scope(self.name or \"WarmUp\") as name:\n        # Implements polynomial warmup. i.e., if global_step < warmup_steps, the\n        # learning rate will be `global_step/num_warmup_steps * init_lr`.\n        global_step_float = tf.cast(step, tf.float32)\n        warmup_steps_float = tf.cast(self.warmup_steps, tf.float32)\n        warmup_percent_done = global_step_float / warmup_steps_float\n        warmup_learning_rate = self.initial_learning_rate * tf.math.pow(warmup_percent_done, self.power)\n        return tf.cond(\n            global_step_float < warmup_steps_float,\n            lambda: warmup_learning_rate,\n            lambda: self.decay_schedule_fn(step - self.warmup_steps),\n            name=name,\n        )\n\n  def get_config(self):\n    return {\n        \"initial_learning_rate\": self.initial_learning_rate,\n        \"decay_schedule_fn\": self.decay_schedule_fn,\n        \"warmup_steps\": self.warmup_steps,\n        \"power\": self.power,\n        \"name\": self.name,\n    }","metadata":{"execution":{"iopub.status.busy":"2022-04-15T16:21:50.206207Z","iopub.execute_input":"2022-04-15T16:21:50.206557Z","iopub.status.idle":"2022-04-15T16:21:50.219424Z","shell.execute_reply.started":"2022-04-15T16:21:50.206512Z","shell.execute_reply":"2022-04-15T16:21:50.218411Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"# Defining the loss function\ncriterion = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, \n                                                          reduction=tf.keras.losses.Reduction.SUM)\n# Number of epochs\ntot_epochs = 5\n\n# temperature in NTXent\nloss_temp = 0.2\n\n# Defining the SimCLR model\n# Differentiating models via their hyper-parameter values\n# simclr_2 = simclr_model((32, 32))\n\n\n# optimiser decay schedule\ndecay_steps = (len(df_train))*tot_epochs\nwarmup_steps = (len(df_train))*10\ninitial_lr = 0.5e-3\n\n# Cosine decay function\nlr_decayed_fn = tf.keras.experimental.CosineDecay(initial_learning_rate = initial_lr, \n                                                  decay_steps = decay_steps)\ncosine_with_warmUp = WarmUp(initial_learning_rate = initial_lr,\n                            decay_schedule_fn = lr_decayed_fn,\n                            warmup_steps = warmup_steps)\n\nprint(\"Decay Steps : \",decay_steps)\noptimizer = tf.keras.optimizers.Adam(cosine_with_warmUp)","metadata":{"execution":{"iopub.status.busy":"2022-04-15T16:21:50.223163Z","iopub.execute_input":"2022-04-15T16:21:50.223947Z","iopub.status.idle":"2022-04-15T16:21:50.235519Z","shell.execute_reply.started":"2022-04-15T16:21:50.223873Z","shell.execute_reply":"2022-04-15T16:21:50.234603Z"},"trusted":true},"execution_count":47,"outputs":[{"name":"stdout","text":"Decay Steps :  200030\n","output_type":"stream"}]},{"cell_type":"code","source":"simclr = simclr_model((32, 32, 3))\nsimclr.compile(optimizer='adam', loss='categorical_crossentropy', metrics='accuracy')\nsimclr.summary()","metadata":{"execution":{"iopub.status.busy":"2022-04-15T16:21:50.237544Z","iopub.execute_input":"2022-04-15T16:21:50.237910Z","iopub.status.idle":"2022-04-15T16:21:50.383110Z","shell.execute_reply.started":"2022-04-15T16:21:50.237870Z","shell.execute_reply":"2022-04-15T16:21:50.382278Z"},"trusted":true},"execution_count":48,"outputs":[{"name":"stdout","text":"Model: \"model_5\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_12 (InputLayer)        [(None, 32, 32, 3)]       0         \n_________________________________________________________________\nconv2d_20 (Conv2D)           (None, 32, 32, 16)        448       \n_________________________________________________________________\nbatch_normalization_20 (Batc (None, 32, 32, 16)        64        \n_________________________________________________________________\nconv2d_21 (Conv2D)           (None, 32, 32, 16)        2320      \n_________________________________________________________________\nbatch_normalization_21 (Batc (None, 32, 32, 16)        64        \n_________________________________________________________________\nmax_pooling2d_10 (MaxPooling (None, 16, 16, 16)        0         \n_________________________________________________________________\ndropout_20 (Dropout)         (None, 16, 16, 16)        0         \n_________________________________________________________________\nconv2d_22 (Conv2D)           (None, 15, 15, 32)        2080      \n_________________________________________________________________\nbatch_normalization_22 (Batc (None, 15, 15, 32)        128       \n_________________________________________________________________\nconv2d_23 (Conv2D)           (None, 14, 14, 32)        4128      \n_________________________________________________________________\nbatch_normalization_23 (Batc (None, 14, 14, 32)        128       \n_________________________________________________________________\nmax_pooling2d_11 (MaxPooling (None, 7, 7, 32)          0         \n_________________________________________________________________\ndropout_21 (Dropout)         (None, 7, 7, 32)          0         \n_________________________________________________________________\nflatten_5 (Flatten)          (None, 1568)              0         \n_________________________________________________________________\ndense_15 (Dense)             (None, 256)               401664    \n_________________________________________________________________\ndropout_22 (Dropout)         (None, 256)               0         \n_________________________________________________________________\ndense_16 (Dense)             (None, 64)                16448     \n_________________________________________________________________\ndropout_23 (Dropout)         (None, 64)                0         \n_________________________________________________________________\ndense_17 (Dense)             (None, 10)                650       \n=================================================================\nTotal params: 428,122\nTrainable params: 427,930\nNon-trainable params: 192\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Training SimCLR","metadata":{}},{"cell_type":"code","source":"# Composing the Train Dataset\ntrain_dataset = tf.data.Dataset.from_tensor_slices((df_train, y_train_oh)).batch(32)","metadata":{"execution":{"iopub.status.busy":"2022-04-15T16:21:50.384796Z","iopub.execute_input":"2022-04-15T16:21:50.385062Z","iopub.status.idle":"2022-04-15T16:21:52.554802Z","shell.execute_reply.started":"2022-04-15T16:21:50.385023Z","shell.execute_reply":"2022-04-15T16:21:52.554011Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"num_epochs = [10, 20]\ntrain_loss, test_loss, train_acc, test_acc = [], [], [], []\n\nfor epochs in num_epochs:\n    # Training the Model\n    simclr = simclr_model((32, 32, 3))\n    simclr.compile(optimizer='adam', loss='categorical_crossentropy', metrics='accuracy')\n    simclr.fit(train_dataset, epochs = epochs)\n    \n    # Predicting on the Train/Test Datasets\n    preds_train = simclr.predict(df_train)\n    preds_test = simclr.predict(df_test)\n\n    # Finding the Predicted Classes\n    cls_train = np.argmax(preds_train, axis = 1)\n    cls_test = np.argmax(preds_test, axis = 1)\n    \n    # Finding the Train/Test set Loss\n    train_loss.append(log_loss(y_train_oh, preds_train))\n    test_loss.append(log_loss(y_test_oh, preds_test))\n    train_acc.append(accuracy_score(y_train, cls_train))\n    test_acc.append(accuracy_score(y_test, cls_test))\n    \n    print(\"For \", epochs, \" Epochs:\")\n    print(\"Log-loss for Train Dataset = \", train_loss[-1])\n    print(\"Log-loss for Test Dataset = \", test_loss[-1])\n    print(\"Accuracy for Train Dataset = \", train_acc[-1])\n    print(\"Accuracy for Test Dataset = \", test_acc[-1])\n    print()","metadata":{"execution":{"iopub.status.busy":"2022-04-15T16:21:52.556226Z","iopub.execute_input":"2022-04-15T16:21:52.556507Z","iopub.status.idle":"2022-04-15T16:26:23.332063Z","shell.execute_reply.started":"2022-04-15T16:21:52.556466Z","shell.execute_reply":"2022-04-15T16:26:23.331279Z"},"trusted":true},"execution_count":50,"outputs":[{"name":"stdout","text":"Epoch 1/10\n1251/1251 [==============================] - 7s 5ms/step - loss: 1.7116 - accuracy: 0.3785\nEpoch 2/10\n1251/1251 [==============================] - 7s 5ms/step - loss: 1.3008 - accuracy: 0.5412\nEpoch 3/10\n1251/1251 [==============================] - 6s 5ms/step - loss: 1.1237 - accuracy: 0.6080\nEpoch 4/10\n1251/1251 [==============================] - 6s 5ms/step - loss: 1.0189 - accuracy: 0.6499\nEpoch 5/10\n1251/1251 [==============================] - 6s 5ms/step - loss: 0.9364 - accuracy: 0.6765\nEpoch 6/10\n1251/1251 [==============================] - 7s 6ms/step - loss: 0.8787 - accuracy: 0.6990\nEpoch 7/10\n1251/1251 [==============================] - 6s 5ms/step - loss: 0.8349 - accuracy: 0.7098\nEpoch 8/10\n1251/1251 [==============================] - 6s 5ms/step - loss: 0.7949 - accuracy: 0.7275\nEpoch 9/10\n1251/1251 [==============================] - 6s 5ms/step - loss: 0.7559 - accuracy: 0.7365\nEpoch 10/10\n1251/1251 [==============================] - 7s 6ms/step - loss: 0.7260 - accuracy: 0.7495\nFor  10  Epochs:\nLog-loss for Train Dataset =  0.5958936470976424\nLog-loss for Test Dataset =  0.8895000920530299\nAccuracy for Train Dataset =  0.7929060640903864\nAccuracy for Test Dataset =  0.7165\n\nEpoch 1/20\n1251/1251 [==============================] - 7s 5ms/step - loss: 1.7433 - accuracy: 0.3712\nEpoch 2/20\n1251/1251 [==============================] - 6s 5ms/step - loss: 1.3161 - accuracy: 0.5348\nEpoch 3/20\n1251/1251 [==============================] - 7s 5ms/step - loss: 1.1371 - accuracy: 0.6037\nEpoch 4/20\n1251/1251 [==============================] - 6s 5ms/step - loss: 1.0359 - accuracy: 0.6408\nEpoch 5/20\n1251/1251 [==============================] - 6s 5ms/step - loss: 0.9520 - accuracy: 0.6703\nEpoch 6/20\n1251/1251 [==============================] - 6s 5ms/step - loss: 0.8879 - accuracy: 0.6947\nEpoch 7/20\n1251/1251 [==============================] - 6s 5ms/step - loss: 0.8332 - accuracy: 0.7098\nEpoch 8/20\n1251/1251 [==============================] - 6s 5ms/step - loss: 0.7983 - accuracy: 0.7230\nEpoch 9/20\n1251/1251 [==============================] - 6s 5ms/step - loss: 0.7497 - accuracy: 0.7377\nEpoch 10/20\n1251/1251 [==============================] - 6s 5ms/step - loss: 0.7192 - accuracy: 0.7488\nEpoch 11/20\n1251/1251 [==============================] - 6s 5ms/step - loss: 0.6853 - accuracy: 0.7604\nEpoch 12/20\n1251/1251 [==============================] - 6s 5ms/step - loss: 0.6658 - accuracy: 0.7664\nEpoch 13/20\n1251/1251 [==============================] - 6s 5ms/step - loss: 0.6423 - accuracy: 0.7758\nEpoch 14/20\n1251/1251 [==============================] - 7s 5ms/step - loss: 0.6198 - accuracy: 0.7852\nEpoch 15/20\n1251/1251 [==============================] - 6s 5ms/step - loss: 0.5946 - accuracy: 0.7932\nEpoch 16/20\n1251/1251 [==============================] - 6s 5ms/step - loss: 0.5839 - accuracy: 0.7954\nEpoch 17/20\n1251/1251 [==============================] - 6s 5ms/step - loss: 0.5602 - accuracy: 0.8051\nEpoch 18/20\n1251/1251 [==============================] - 7s 5ms/step - loss: 0.5503 - accuracy: 0.8089\nEpoch 19/20\n1251/1251 [==============================] - 6s 5ms/step - loss: 0.5312 - accuracy: 0.8132\nEpoch 20/20\n1251/1251 [==============================] - 6s 5ms/step - loss: 0.5137 - accuracy: 0.8218\nFor  20  Epochs:\nLog-loss for Train Dataset =  0.27193687687881013\nLog-loss for Test Dataset =  0.7668295637582345\nAccuracy for Train Dataset =  0.9083887416887467\nAccuracy for Test Dataset =  0.7577\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# Training the Model with the best hyper-parameter settings\nind = np.argmax(test_acc)\nbest_num_epochs = num_epochs[ind]\nsimclr = simclr_model((32, 32, 3))\nsimclr.compile(optimizer='adam', loss='categorical_crossentropy', metrics='accuracy')\nsimclr.fit(train_dataset, epochs = best_num_epochs)\n\n# Saving the model along with it's weights\nsimclr.save('simclr_model.h5')\n\n# Predicting on the Train/Test Datasets\npreds_train = simclr.predict(df_train)\npreds_test = simclr.predict(df_test)\n\n# Finding the Predicted Classes\ncls_train = np.argmax(preds_train, axis = 1)\ncls_test = np.argmax(preds_test, axis = 1)","metadata":{"execution":{"iopub.status.busy":"2022-04-15T16:26:23.333608Z","iopub.execute_input":"2022-04-15T16:26:23.333876Z","iopub.status.idle":"2022-04-15T16:29:16.435885Z","shell.execute_reply.started":"2022-04-15T16:26:23.333840Z","shell.execute_reply":"2022-04-15T16:29:16.435101Z"},"trusted":true},"execution_count":51,"outputs":[{"name":"stdout","text":"Epoch 1/20\n1251/1251 [==============================] - 7s 5ms/step - loss: 1.7422 - accuracy: 0.3701\nEpoch 2/20\n1251/1251 [==============================] - 7s 5ms/step - loss: 1.2988 - accuracy: 0.5387\nEpoch 3/20\n1251/1251 [==============================] - 6s 5ms/step - loss: 1.1090 - accuracy: 0.6137\nEpoch 4/20\n1251/1251 [==============================] - 6s 5ms/step - loss: 1.0028 - accuracy: 0.6520\nEpoch 5/20\n1251/1251 [==============================] - 6s 5ms/step - loss: 0.9253 - accuracy: 0.6827\nEpoch 6/20\n1251/1251 [==============================] - 7s 6ms/step - loss: 0.8691 - accuracy: 0.6980\nEpoch 7/20\n1251/1251 [==============================] - 6s 5ms/step - loss: 0.8148 - accuracy: 0.7183\nEpoch 8/20\n1251/1251 [==============================] - 6s 5ms/step - loss: 0.7824 - accuracy: 0.7303\nEpoch 9/20\n1251/1251 [==============================] - 6s 5ms/step - loss: 0.7446 - accuracy: 0.7393\nEpoch 10/20\n1251/1251 [==============================] - 6s 5ms/step - loss: 0.7145 - accuracy: 0.7501\nEpoch 11/20\n1251/1251 [==============================] - 7s 5ms/step - loss: 0.6847 - accuracy: 0.7630\nEpoch 12/20\n1251/1251 [==============================] - 6s 5ms/step - loss: 0.6626 - accuracy: 0.7715\nEpoch 13/20\n1251/1251 [==============================] - 7s 5ms/step - loss: 0.6319 - accuracy: 0.7806\nEpoch 14/20\n1251/1251 [==============================] - 7s 5ms/step - loss: 0.6175 - accuracy: 0.7865\nEpoch 15/20\n1251/1251 [==============================] - 6s 5ms/step - loss: 0.5942 - accuracy: 0.7957\nEpoch 16/20\n1251/1251 [==============================] - 6s 5ms/step - loss: 0.5790 - accuracy: 0.7989\nEpoch 17/20\n1251/1251 [==============================] - 6s 5ms/step - loss: 0.5616 - accuracy: 0.8071\nEpoch 18/20\n1251/1251 [==============================] - 7s 5ms/step - loss: 0.5463 - accuracy: 0.8101\nEpoch 19/20\n1251/1251 [==============================] - 6s 5ms/step - loss: 0.5220 - accuracy: 0.8189\nEpoch 20/20\n1251/1251 [==============================] - 6s 5ms/step - loss: 0.5167 - accuracy: 0.8203\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Final Predictions","metadata":{}},{"cell_type":"code","source":"# Finding the Train/Test set Loss\nprint(\"Log-loss for Train Dataset = \", log_loss(y_train_oh, preds_train))\nprint(\"Log-loss for Test Dataset = \", log_loss(y_test_oh, preds_test))\nprint(\"Accuracy for Train Dataset = \", accuracy_score(y_train, cls_train))\nprint(\"Accuracy for Test Dataset = \", accuracy_score(y_test, cls_test))","metadata":{"execution":{"iopub.status.busy":"2022-04-15T16:29:16.437166Z","iopub.execute_input":"2022-04-15T16:29:16.437447Z","iopub.status.idle":"2022-04-15T16:29:16.513090Z","shell.execute_reply.started":"2022-04-15T16:29:16.437412Z","shell.execute_reply":"2022-04-15T16:29:16.512288Z"},"trusted":true},"execution_count":52,"outputs":[{"name":"stdout","text":"Log-loss for Train Dataset =  0.27172134258553937\nLog-loss for Test Dataset =  0.7683091839501851\nAccuracy for Train Dataset =  0.9085387191921211\nAccuracy for Test Dataset =  0.7573\n","output_type":"stream"}]}]}