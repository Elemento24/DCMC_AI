# Data-Centric
- In this folder, we will be adding the code for all the methods from **Data-Centric Approach** that we will be trying.

## File Descriptions
- `trad_aug.ipynb` -- This `.ipynb` notebook covers the code for applying the Traditional Augmentation approaches on the Dataset and then training the Baseline Model on the Augmented Dataset. The kernel consists of 3 different approaches, random-sampling based augmentation, augmentation for class balancing, and augmentation based on class-wise performance. Out of the 3 approaches, none of them gave any boost in terms of accuracy and/or log-loss. **Augmentation for class balancing** gave the highest **test accuracy of 0.7746** among the 3 with a **log-loss of 0.8160** on the test dataset.
- `gan_aug_1.ipynb` -- This `.ipynb` notebook covers the code for applying the GAN-Based Augmentation approaches. In this kernel, we have used PyTorch to train a GAN for 1000 epochs on the CIFAR-10 Dataset, and then used the fake images from the GAN to augment the existing dataset. This is the first kernel for the approach in which we have prepared the augmented datasets. 
- `gan_aug_2.ipynb` -- This `.ipynb` notebook is the second kernel for the GAN-Based Augmentation approach, in which, we have trained the models on the augmented datasets. Just like the traditional augmentation, we have tried 3 different approaches, random-sampling based augmentation, augmentation for class balancing, and augmentation based on class-wise performance, however, none of them gave any boost in terms of log-loss and/or accuracy for the test dataset. **Augmentation based on class-wise performance** gave the highest **test accuracy of 0.7664** among the 3 with a **log-loss of 0.8320** on the test dataset.
- `hybrid_trad_gan_aug.ipynb` -- This `.ipynb` notebook consists of code for the hybridization between the Traditional Augmentation and the GAN-Based Augmentation approaches. We have elaborated upon the strategy employed to perform the hybridization in the notebook itself. The hybrid approach, like it's children approaches, also didn't give any improvement in terms of log-loss and/or accuracy. In fact, the hybrid approach performed worse than both of the children approaches, giving a **test accuracy of 0.7595** with a **log-loss of 0.8253** on the test dataset.
- `simclr_model.ipynb` -- This `.ipynb` notebook consists of code for the SimCLR. We have elaborated upon the code provided by the authors of the paper - 'A simple framework for contrastive learning of visual representations'. The SimCLR based model, gave a **test accuracy of 0.7489** with a **log-loss of 0.7697** on the test dataset.