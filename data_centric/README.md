# Data-Centric
- In this folder, we will be adding the code for all the methods from **Data-Centric Approach** that we will be trying.

## File Descriptions
- `trad_aug.ipynb` -- This `.ipynb` notebook covers the code for applying the Traditional Augmentation approaches on the Dataset and then training the Baseline Model on the Augmented Dataset. The kernel consists of 3 different approaches, random-sampling based augmentation, augmentation for class balancing, and augmentation based on class-wise performance. Out of the 3 approaches, **Augmentation based on class-wise performance** gave a slight boost in terms of log-loss over the baseline model. It gave the best performance among the 3, with a **test accuracy of 0.7739**, a **weighted f1-score of 0.7727** and a **log-loss of 0.7304** on the test dataset.
- `gan_aug_1.ipynb` -- This `.ipynb` notebook covers the code for applying the GAN-Based Augmentation approaches. In this kernel, we have used PyTorch to train a GAN for 1000 epochs on the CIFAR-10 Dataset, and then used the fake images from the GAN to augment the existing dataset. This is the first kernel for the approach in which we have prepared the augmented datasets. 
- `gan_aug_2.ipynb` -- This `.ipynb` notebook is the second kernel for the GAN-Based Augmentation approach, in which, we have trained the models on the augmented datasets. Just like the traditional augmentation, we have tried 3 different approaches, random-sampling based augmentation, augmentation for class balancing, and augmentation based on class-wise performance, however, none of them gave any boost in terms of log-loss and/or weighted f1-score and/or accuracy for the test dataset. **Augmentation based on class-wise performance** gave the highest **test accuracy of 0.7664** among the 3 with a **weighted f1-score of 0.7646** and a **log-loss of 0.8320** on the test dataset.
- `hybrid_trad_gan_aug.ipynb` -- This `.ipynb` notebook consists of code for the hybridization between the Traditional Augmentation and the GAN-Based Augmentation approaches. We have elaborated upon the strategy employed to perform the hybridization in the notebook itself. The hybrid approach gave a very slight boost in terms of log-loss over the baseline model, giving a **test accuracy of 0.7698** with a **weighted f1-score of 0.7666** and a **log-loss of 0.7709** on the test dataset.
- `iterative_sampling.ipynb` -- This `.ipynb` notebook consists of code for the Iterative Sampling approach. We have elaborated upon the algorithm provided by the authors of the paper - 'Increasing Data Diversity with Iterative Sampling to Improve Performance'. It gave a **test accuracy of 0.7727** with a **weighted f1-score of 0.7700** and a **log-loss of 0.7760** on the test dataset.
- `simclr_model.ipynb` -- This `.ipynb` notebook consists of code for the SimCLR. We have elaborated upon the code provided by the authors of the paper - 'A simple framework for contrastive learning of visual representations'. The SimCLR based model, gave a **test accuracy of 0.7747** with a **weighted f1-score of 0.7733** and a **log-loss of 0.7864** on the test dataset.
- `autoaugment.ipynb` -- This `.ipynb` notebook consists of code for the AutoAugment policy in addition to the baseline model for training. We have elaborated upon the code provided by the authors of the paper - 'AutoAugment: Learning Augmentation Policies from Data'. The AutoAugment based model, gave a **test accuracy of 0.7775** with a **weighted f1-score of 0.7777** and a **log-loss of 0.6538** on the test dataset.
