{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e46b73bd",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 0.022215,
     "end_time": "2022-04-08T17:30:43.110654",
     "exception": false,
     "start_time": "2022-04-08T17:30:43.088439",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Hybridization of Traditional and GAN-based Augmentations\n",
    "- In this kernel, we will be performing the Hybridization of **Traditional Augmentation** and **GAN-Based Augmentation** approaches. \n",
    "- In the traditional and GAN-based augmentation kernels, we have tried 3 different approaches in each. In this manner, we can have 9 different combinations for this hybridization. However, in this kernel, we will only be using a single combination. From both the kernels, we will be selecting the approach with the best test-set accuracies, and combining them only. \n",
    "- From the traditional augmentation kernel, we will be selecting 'Augmentation for class balancing' (**77.46% accuracy**), and from the GAN-based augmentation kernel, we will be selecting 'Augmentation based on class-wise performance' (**76.64% accuracy**).\n",
    "- We will apply the aforementioned approaches individually on the training dataset, and then will be merging both of the augmented datasets with the training set.\n",
    "\n",
    "### Reference Kernels\n",
    "- [Traditional Augmentation](https://www.kaggle.com/code/elemento/rw-tradaug)\n",
    "- [GANs Augmentation 1](https://www.kaggle.com/code/elemento/rw-ganaug-1) and [GANs Augmentation 2](https://www.kaggle.com/code/elemento/rw-ganaug-2)\n",
    "\n",
    "# 1. Importing the Packages & Boilerplate Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f1d6db2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-08T17:30:43.173877Z",
     "iopub.status.busy": "2022-04-08T17:30:43.173117Z",
     "iopub.status.idle": "2022-04-08T17:30:49.075162Z",
     "shell.execute_reply": "2022-04-08T17:30:49.074563Z"
    },
    "papermill": {
     "duration": 5.941817,
     "end_time": "2022-04-08T17:30:49.075296",
     "exception": false,
     "start_time": "2022-04-08T17:30:43.133479",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from shutil import copyfile\n",
    "from tabulate import tabulate\n",
    "from sklearn.metrics import accuracy_score, log_loss, confusion_matrix\n",
    "\n",
    "# https://www.kaggle.com/c/ventilator-pressure-prediction/discussion/274717\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as tfl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1aa2f95f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-08T17:30:49.107049Z",
     "iopub.status.busy": "2022-04-08T17:30:49.105289Z",
     "iopub.status.idle": "2022-04-08T17:30:49.109377Z",
     "shell.execute_reply": "2022-04-08T17:30:49.108839Z"
    },
    "papermill": {
     "duration": 0.020173,
     "end_time": "2022-04-08T17:30:49.109488",
     "exception": false,
     "start_time": "2022-04-08T17:30:49.089315",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setting the seeds\n",
    "SEED = 0\n",
    "os.environ['PYTHONHASHSEED']=str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9afeae6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-08T17:30:50.989393Z",
     "iopub.status.busy": "2022-04-08T17:30:50.988806Z",
     "iopub.status.idle": "2022-04-08T17:30:50.994048Z",
     "shell.execute_reply": "2022-04-08T17:30:50.993528Z"
    },
    "papermill": {
     "duration": 1.871818,
     "end_time": "2022-04-08T17:30:50.994177",
     "exception": false,
     "start_time": "2022-04-08T17:30:49.122359",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU at: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "# Making sure that Tensorflow is able to detect the GPU\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if \"GPU\" not in device_name:\n",
    "    print(\"GPU device not found\")\n",
    "print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "981667c9",
   "metadata": {
    "papermill": {
     "duration": 0.013076,
     "end_time": "2022-04-08T17:30:51.021475",
     "exception": false,
     "start_time": "2022-04-08T17:30:51.008399",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 2. Importing the Train and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8f4122b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-08T17:30:51.057302Z",
     "iopub.status.busy": "2022-04-08T17:30:51.056782Z",
     "iopub.status.idle": "2022-04-08T17:31:19.259680Z",
     "shell.execute_reply": "2022-04-08T17:31:19.259185Z"
    },
    "papermill": {
     "duration": 28.224867,
     "end_time": "2022-04-08T17:31:19.259823",
     "exception": false,
     "start_time": "2022-04-08T17:30:51.034956",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Train Dataset:\n",
      "(40006, 3072) (40006, 1)\n",
      "(40006, 32, 32, 3)\n",
      "For Test Dataset:\n",
      "(10000, 3072) (10000, 1)\n",
      "(10000, 3, 32, 32)\n",
      "(10000, 32, 32, 3) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "# Importing the Labelled Training Dataset\n",
    "print(\"For Train Dataset:\")\n",
    "df_train = pd.read_csv(\"../input/cifar10/train_lab_x.csv\")\n",
    "y_train = pd.read_csv(\"../input/cifar10/train_lab_y.csv\")\n",
    "df_train = np.array(df_train)\n",
    "y_train = np.array(y_train)\n",
    "print(df_train.shape, y_train.shape)\n",
    "\n",
    "# Reshaping, rescaling and one-hot encoding\n",
    "df_train = np.reshape(df_train, (-1, 3, 32, 32))\n",
    "df_train = np.transpose(np.array(df_train), (0, 2, 3, 1))\n",
    "df_train = df_train / 255\n",
    "print(df_train.shape)\n",
    "\n",
    "# Importing the Test Dataset\n",
    "print(\"For Test Dataset:\")\n",
    "df_test = pd.read_csv(\"../input/cifar10/test_x.csv\")\n",
    "y_test = pd.read_csv(\"../input/cifar10/test_y.csv\")\n",
    "df_test = np.array(df_test)\n",
    "y_test = np.array(y_test)\n",
    "print(df_test.shape, y_test.shape)\n",
    "\n",
    "# Reshaping the dataset\n",
    "df_test = np.reshape(df_test, (-1, 3, 32, 32))\n",
    "print(df_test.shape)\n",
    "\n",
    "# Reshaping, rescaling and one-hot encoding\n",
    "df_test = np.transpose(np.array(df_test), (0, 2, 3, 1))\n",
    "df_test = df_test / 255\n",
    "y_test_oh = tf.one_hot(np.ravel(y_test), depth = 10)\n",
    "print(df_test.shape, y_test_oh.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea60641",
   "metadata": {
    "papermill": {
     "duration": 0.016831,
     "end_time": "2022-04-08T17:31:19.293491",
     "exception": false,
     "start_time": "2022-04-08T17:31:19.276660",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 3. Performing the Augmentations on the Training Set\n",
    "## 3.1. GAN-Based Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1403d699",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-08T17:31:19.330612Z",
     "iopub.status.busy": "2022-04-08T17:31:19.330071Z",
     "iopub.status.idle": "2022-04-08T17:31:29.174309Z",
     "shell.execute_reply": "2022-04-08T17:31:29.174925Z"
    },
    "papermill": {
     "duration": 9.865234,
     "end_time": "2022-04-08T17:31:29.175081",
     "exception": false,
     "start_time": "2022-04-08T17:31:19.309847",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10048, 32, 32, 3) (10048, 1)\n"
     ]
    }
   ],
   "source": [
    "df_gan_aug = pd.read_csv(\"../input/cifar10/df_clsper_aug.csv\")\n",
    "y_gan_aug = pd.read_csv(\"../input/cifar10/y_clsper_aug.csv\")\n",
    "df_gan_aug = np.array(df_gan_aug)\n",
    "y_gan_aug = np.array(y_gan_aug)\n",
    "\n",
    "# Reshaping, rescaling and one-hot encoding\n",
    "df_gan_aug = np.reshape(df_gan_aug, (-1, 3, 32, 32))\n",
    "df_gan_aug = np.transpose(np.array(df_gan_aug), (0, 2, 3, 1))\n",
    "print(df_gan_aug.shape, y_gan_aug.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0e2878",
   "metadata": {
    "papermill": {
     "duration": 0.015427,
     "end_time": "2022-04-08T17:31:29.206220",
     "exception": false,
     "start_time": "2022-04-08T17:31:29.190793",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3.2. Traditional Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4fe6d2c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-08T17:31:29.292963Z",
     "iopub.status.busy": "2022-04-08T17:31:29.280502Z",
     "iopub.status.idle": "2022-04-08T17:31:29.305188Z",
     "shell.execute_reply": "2022-04-08T17:31:29.304437Z"
    },
    "papermill": {
     "duration": 0.083757,
     "end_time": "2022-04-08T17:31:29.305317",
     "exception": false,
     "start_time": "2022-04-08T17:31:29.221560",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4109 3839 4022 4116 4312 3952 4290 3552 3436 4378]\n",
      "[269, 539, 356, 262, 66, 426, 88, 826, 942, 0] 3774\n",
      "10 4109\n",
      "3774 3774\n"
     ]
    }
   ],
   "source": [
    "y_train_reshape = np.reshape(y_train, (-1))\n",
    "num_examples = np.zeros((10,))\n",
    "\n",
    "for i in y_train_reshape:\n",
    "    num_examples[i] += 1\n",
    "\n",
    "# Number of examples from each class\n",
    "num_exa = num_examples.astype('int32')\n",
    "\n",
    "# Finding out the maximum number of examples for any class\n",
    "max_exa = max(num_exa)\n",
    "\n",
    "# Number of examples that needs to be added to each of the classes\n",
    "aug_exa = [max_exa - num_exa[i] for i in range(10)]\n",
    "\n",
    "# Creating a list of lists for storing the indices of data-points in the training dataset, class-wise\n",
    "classes_ind = []\n",
    "for i in range(10):\n",
    "    classes_ind.append([])\n",
    "\n",
    "for ind, clss in enumerate(y_train_reshape):\n",
    "    classes_ind[clss].append(ind)\n",
    "\n",
    "# # Transforming list of lists into numpy array\n",
    "# classes_ind = np.array([np.array(xi) for xi in classes_ind])\n",
    "\n",
    "print(num_exa)\n",
    "print(aug_exa, sum(aug_exa))\n",
    "print(len(classes_ind), len(classes_ind[0]))\n",
    "\n",
    "# Creating a list for indices of images and their labels on which augmentation needs to be done\n",
    "# These are randomly chosen from each class\n",
    "aug_ind = []\n",
    "y_trad_aug = []\n",
    "\n",
    "for i in range(10):\n",
    "    indices = random.choices(classes_ind[i], k = aug_exa[i])\n",
    "    aug_ind.extend(indices)\n",
    "    y_trad_aug.extend([i]*aug_exa[i])\n",
    "\n",
    "print(len(aug_ind), len(y_trad_aug))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "541c1b18",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-08T17:31:29.342965Z",
     "iopub.status.busy": "2022-04-08T17:31:29.342415Z",
     "iopub.status.idle": "2022-04-08T17:31:58.412399Z",
     "shell.execute_reply": "2022-04-08T17:31:58.412824Z"
    },
    "papermill": {
     "duration": 29.091861,
     "end_time": "2022-04-08T17:31:58.412984",
     "exception": false,
     "start_time": "2022-04-08T17:31:29.321123",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3774/3774 [00:28<00:00, 130.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3774, 32, 32, 3) (3774, 1)\n"
     ]
    }
   ],
   "source": [
    "data_augmentation = tf.keras.Sequential([\n",
    "    tfl.RandomFlip(\"horizontal\"),\n",
    "    tfl.RandomRotation(0.1),\n",
    "])\n",
    "\n",
    "# Creating an empty list\n",
    "df_trad_aug = []\n",
    "\n",
    "# Iterating over all the images in the dataset\n",
    "for ind in tqdm(aug_ind):\n",
    "    aug_image = data_augmentation(df_train[ind, : , : , : ])\n",
    "    df_trad_aug.append(aug_image)\n",
    "\n",
    "# Sanity Checks and Transformations\n",
    "df_trad_aug = np.array(df_trad_aug)\n",
    "y_trad_aug = np.reshape(np.array(y_trad_aug), (-1, 1))\n",
    "print(df_trad_aug.shape, y_trad_aug.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ab5d21",
   "metadata": {
    "papermill": {
     "duration": 0.098925,
     "end_time": "2022-04-08T17:31:58.615044",
     "exception": false,
     "start_time": "2022-04-08T17:31:58.516119",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3.3. Preparing the Augmented Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44d87812",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-08T17:31:58.820386Z",
     "iopub.status.busy": "2022-04-08T17:31:58.819497Z",
     "iopub.status.idle": "2022-04-08T17:32:00.805815Z",
     "shell.execute_reply": "2022-04-08T17:32:00.806226Z"
    },
    "papermill": {
     "duration": 2.091309,
     "end_time": "2022-04-08T17:32:00.806389",
     "exception": false,
     "start_time": "2022-04-08T17:31:58.715080",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53828, 32, 32, 3) (53828, 1) (53828, 10)\n"
     ]
    }
   ],
   "source": [
    "# Concatenating the Training with Augmenting Dataset\n",
    "df_aug = np.concatenate([df_train, df_gan_aug, df_trad_aug], axis=0)\n",
    "y_aug = np.concatenate([y_train, y_gan_aug, y_trad_aug], axis=0)\n",
    "\n",
    "# Creating a random permutation & shuffling the dataset\n",
    "perm = np.random.permutation(df_aug.shape[0])\n",
    "df_aug = np.array(df_aug[perm, : , : , : ])\n",
    "y_aug = y_aug[perm]\n",
    "\n",
    "# One-Hot Encoding\n",
    "y_aug_oh = tf.one_hot(np.ravel(y_aug), depth = 10)\n",
    "print(df_aug.shape, y_aug.shape, y_aug_oh.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0522dcfa",
   "metadata": {
    "papermill": {
     "duration": 0.100214,
     "end_time": "2022-04-08T17:32:01.008530",
     "exception": false,
     "start_time": "2022-04-08T17:32:00.908316",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 4. Training the Model\n",
    "## 4.1. Preparing the Baseline Model and the Augmented Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67ffe53e",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2022-04-08T17:32:01.213377Z",
     "iopub.status.busy": "2022-04-08T17:32:01.212811Z",
     "iopub.status.idle": "2022-04-08T17:32:03.540873Z",
     "shell.execute_reply": "2022-04-08T17:32:03.540238Z"
    },
    "papermill": {
     "duration": 2.432265,
     "end_time": "2022-04-08T17:32:03.541011",
     "exception": false,
     "start_time": "2022-04-08T17:32:01.108746",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Importing the Baseline Model Architecture\n",
    "copyfile(src = \"../input/dcai-rw/baseline_arch.py\", dst = \"../working/baseline_arch.py\")\n",
    "from baseline_arch import cnn_model\n",
    "\n",
    "# Creating Batches from the Augmented Dataset\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((df_aug, y_aug_oh)).batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9515c64d",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2022-04-08T17:32:03.772958Z",
     "iopub.status.busy": "2022-04-08T17:32:03.772144Z",
     "iopub.status.idle": "2022-04-08T17:57:56.923257Z",
     "shell.execute_reply": "2022-04-08T17:57:56.923765Z"
    },
    "papermill": {
     "duration": 1553.266031,
     "end_time": "2022-04-08T17:57:56.923937",
     "exception": false,
     "start_time": "2022-04-08T17:32:03.657906",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1683/1683 [==============================] - 15s 5ms/step - loss: 1.6599 - accuracy: 0.3938\n",
      "Epoch 2/10\n",
      "1683/1683 [==============================] - 8s 5ms/step - loss: 1.2409 - accuracy: 0.5636\n",
      "Epoch 3/10\n",
      "1683/1683 [==============================] - 8s 5ms/step - loss: 1.0746 - accuracy: 0.6251\n",
      "Epoch 4/10\n",
      "1683/1683 [==============================] - 8s 5ms/step - loss: 0.9646 - accuracy: 0.6678\n",
      "Epoch 5/10\n",
      "1683/1683 [==============================] - 8s 5ms/step - loss: 0.8887 - accuracy: 0.6913\n",
      "Epoch 6/10\n",
      "1683/1683 [==============================] - 8s 5ms/step - loss: 0.8369 - accuracy: 0.7121\n",
      "Epoch 7/10\n",
      "1683/1683 [==============================] - 8s 5ms/step - loss: 0.7903 - accuracy: 0.7267\n",
      "Epoch 8/10\n",
      "1683/1683 [==============================] - 8s 5ms/step - loss: 0.7503 - accuracy: 0.7436\n",
      "Epoch 9/10\n",
      "1683/1683 [==============================] - 8s 5ms/step - loss: 0.7206 - accuracy: 0.7530\n",
      "Epoch 10/10\n",
      "1683/1683 [==============================] - 8s 5ms/step - loss: 0.6851 - accuracy: 0.7624\n",
      "For  10  Epochs:\n",
      "Log-loss for Train Dataset =  0.4559950406188158\n",
      "Log-loss for Test Dataset =  0.7846033715799916\n",
      "Accuracy for Train Dataset =  0.8395073196106115\n",
      "Accuracy for Test Dataset =  0.7329\n",
      "\n",
      "Epoch 1/20\n",
      "1683/1683 [==============================] - 9s 5ms/step - loss: 1.6557 - accuracy: 0.3916\n",
      "Epoch 2/20\n",
      "1683/1683 [==============================] - 8s 5ms/step - loss: 1.2679 - accuracy: 0.5489\n",
      "Epoch 3/20\n",
      "1683/1683 [==============================] - 8s 5ms/step - loss: 1.0873 - accuracy: 0.6224\n",
      "Epoch 4/20\n",
      "1683/1683 [==============================] - 8s 5ms/step - loss: 0.9743 - accuracy: 0.6625\n",
      "Epoch 5/20\n",
      "1683/1683 [==============================] - 8s 5ms/step - loss: 0.8932 - accuracy: 0.6903\n",
      "Epoch 6/20\n",
      "1683/1683 [==============================] - 8s 5ms/step - loss: 0.8347 - accuracy: 0.7129\n",
      "Epoch 7/20\n",
      "1683/1683 [==============================] - 8s 5ms/step - loss: 0.7883 - accuracy: 0.7315\n",
      "Epoch 8/20\n",
      "1683/1683 [==============================] - 9s 5ms/step - loss: 0.7462 - accuracy: 0.7452\n",
      "Epoch 9/20\n",
      "1683/1683 [==============================] - 7s 4ms/step - loss: 0.7140 - accuracy: 0.7549\n",
      "Epoch 10/20\n",
      "1683/1683 [==============================] - 7s 4ms/step - loss: 0.6818 - accuracy: 0.7654\n",
      "Epoch 11/20\n",
      "1683/1683 [==============================] - 8s 5ms/step - loss: 0.6538 - accuracy: 0.7761\n",
      "Epoch 12/20\n",
      "1683/1683 [==============================] - 9s 5ms/step - loss: 0.6316 - accuracy: 0.7828\n",
      "Epoch 13/20\n",
      "1683/1683 [==============================] - 8s 5ms/step - loss: 0.6090 - accuracy: 0.7910\n",
      "Epoch 14/20\n",
      "1683/1683 [==============================] - 8s 5ms/step - loss: 0.5921 - accuracy: 0.7966\n",
      "Epoch 15/20\n",
      "1683/1683 [==============================] - 9s 5ms/step - loss: 0.5744 - accuracy: 0.8032\n",
      "Epoch 16/20\n",
      "1683/1683 [==============================] - 8s 5ms/step - loss: 0.5631 - accuracy: 0.8059\n",
      "Epoch 17/20\n",
      "1683/1683 [==============================] - 8s 4ms/step - loss: 0.5417 - accuracy: 0.8130\n",
      "Epoch 18/20\n",
      "1683/1683 [==============================] - 9s 5ms/step - loss: 0.5259 - accuracy: 0.8209\n",
      "Epoch 19/20\n",
      "1683/1683 [==============================] - 8s 5ms/step - loss: 0.5186 - accuracy: 0.8213\n",
      "Epoch 20/20\n",
      "1683/1683 [==============================] - 7s 4ms/step - loss: 0.5081 - accuracy: 0.8261\n",
      "For  20  Epochs:\n",
      "Log-loss for Train Dataset =  0.25285143427824347\n",
      "Log-loss for Test Dataset =  0.7247940823813778\n",
      "Accuracy for Train Dataset =  0.917645091773798\n",
      "Accuracy for Test Dataset =  0.757\n",
      "\n",
      "Epoch 1/30\n",
      "1683/1683 [==============================] - 10s 5ms/step - loss: 1.6474 - accuracy: 0.3954\n",
      "Epoch 2/30\n",
      "1683/1683 [==============================] - 8s 5ms/step - loss: 1.2406 - accuracy: 0.5604\n",
      "Epoch 3/30\n",
      "1683/1683 [==============================] - 7s 4ms/step - loss: 1.0624 - accuracy: 0.6322\n",
      "Epoch 4/30\n",
      "1683/1683 [==============================] - 8s 5ms/step - loss: 0.9595 - accuracy: 0.6698\n",
      "Epoch 5/30\n",
      "1683/1683 [==============================] - 9s 5ms/step - loss: 0.8803 - accuracy: 0.6960\n",
      "Epoch 6/30\n",
      "1683/1683 [==============================] - 8s 5ms/step - loss: 0.8214 - accuracy: 0.7175\n",
      "Epoch 7/30\n",
      "1683/1683 [==============================] - 8s 5ms/step - loss: 0.7777 - accuracy: 0.7308\n",
      "Epoch 8/30\n",
      "1683/1683 [==============================] - 9s 6ms/step - loss: 0.7433 - accuracy: 0.7453\n",
      "Epoch 9/30\n",
      "1683/1683 [==============================] - 8s 5ms/step - loss: 0.7110 - accuracy: 0.7536\n",
      "Epoch 10/30\n",
      "1683/1683 [==============================] - 8s 5ms/step - loss: 0.6773 - accuracy: 0.7668\n",
      "Epoch 11/30\n",
      "1683/1683 [==============================] - 8s 5ms/step - loss: 0.6530 - accuracy: 0.7749\n",
      "Epoch 12/30\n",
      "1683/1683 [==============================] - 8s 5ms/step - loss: 0.6330 - accuracy: 0.7805\n",
      "Epoch 13/30\n",
      "1683/1683 [==============================] - 7s 4ms/step - loss: 0.6058 - accuracy: 0.7897\n",
      "Epoch 14/30\n",
      "1683/1683 [==============================] - 8s 5ms/step - loss: 0.5922 - accuracy: 0.7939\n",
      "Epoch 15/30\n",
      "1683/1683 [==============================] - 9s 6ms/step - loss: 0.5679 - accuracy: 0.8029\n",
      "Epoch 16/30\n",
      "1683/1683 [==============================] - 8s 5ms/step - loss: 0.5526 - accuracy: 0.8091\n",
      "Epoch 17/30\n",
      "1683/1683 [==============================] - 8s 5ms/step - loss: 0.5393 - accuracy: 0.8134\n",
      "Epoch 18/30\n",
      "1683/1683 [==============================] - 8s 5ms/step - loss: 0.5224 - accuracy: 0.8191\n",
      "Epoch 19/30\n",
      "1683/1683 [==============================] - 9s 5ms/step - loss: 0.5152 - accuracy: 0.8228\n",
      "Epoch 20/30\n",
      "1683/1683 [==============================] - 8s 4ms/step - loss: 0.4982 - accuracy: 0.8268\n",
      "Epoch 21/30\n",
      "1683/1683 [==============================] - 8s 5ms/step - loss: 0.4942 - accuracy: 0.8300\n",
      "Epoch 22/30\n",
      "1683/1683 [==============================] - 8s 5ms/step - loss: 0.4819 - accuracy: 0.8349\n",
      "Epoch 23/30\n",
      "1683/1683 [==============================] - 8s 5ms/step - loss: 0.4673 - accuracy: 0.8370\n",
      "Epoch 24/30\n",
      "1683/1683 [==============================] - 8s 5ms/step - loss: 0.4639 - accuracy: 0.8405\n",
      "Epoch 25/30\n",
      "1683/1683 [==============================] - 8s 5ms/step - loss: 0.4583 - accuracy: 0.8439\n",
      "Epoch 26/30\n",
      "1683/1683 [==============================] - 10s 6ms/step - loss: 0.4442 - accuracy: 0.8462\n",
      "Epoch 27/30\n",
      "1683/1683 [==============================] - 8s 5ms/step - loss: 0.4347 - accuracy: 0.8499\n",
      "Epoch 28/30\n",
      "1683/1683 [==============================] - 8s 5ms/step - loss: 0.4354 - accuracy: 0.8515\n",
      "Epoch 29/30\n",
      "1683/1683 [==============================] - 7s 4ms/step - loss: 0.4213 - accuracy: 0.8542\n",
      "Epoch 30/30\n",
      "1683/1683 [==============================] - 9s 6ms/step - loss: 0.4158 - accuracy: 0.8572\n",
      "For  30  Epochs:\n",
      "Log-loss for Train Dataset =  0.18565019231277266\n",
      "Log-loss for Test Dataset =  0.7807499957267662\n",
      "Accuracy for Train Dataset =  0.9414988481831017\n",
      "Accuracy for Test Dataset =  0.7572\n",
      "\n",
      "Epoch 1/40\n",
      "1683/1683 [==============================] - 9s 5ms/step - loss: 1.6795 - accuracy: 0.3816\n",
      "Epoch 2/40\n",
      "1683/1683 [==============================] - 8s 5ms/step - loss: 1.2935 - accuracy: 0.5395\n",
      "Epoch 3/40\n",
      "1683/1683 [==============================] - 10s 6ms/step - loss: 1.1173 - accuracy: 0.6067\n",
      "Epoch 4/40\n",
      "1683/1683 [==============================] - 8s 4ms/step - loss: 1.0010 - accuracy: 0.6531\n",
      "Epoch 5/40\n",
      "1683/1683 [==============================] - 8s 5ms/step - loss: 0.9156 - accuracy: 0.6843\n",
      "Epoch 6/40\n",
      "1683/1683 [==============================] - 8s 5ms/step - loss: 0.8551 - accuracy: 0.7030\n",
      "Epoch 7/40\n",
      "1683/1683 [==============================] - 8s 4ms/step - loss: 0.8051 - accuracy: 0.7203\n",
      "Epoch 8/40\n",
      "1683/1683 [==============================] - 8s 5ms/step - loss: 0.7592 - accuracy: 0.7382\n",
      "Epoch 9/40\n",
      "1683/1683 [==============================] - 9s 5ms/step - loss: 0.7232 - accuracy: 0.7507\n",
      "Epoch 10/40\n",
      "1683/1683 [==============================] - 8s 5ms/step - loss: 0.6901 - accuracy: 0.7619\n",
      "Epoch 11/40\n",
      "1683/1683 [==============================] - 8s 4ms/step - loss: 0.6653 - accuracy: 0.7710\n",
      "Epoch 12/40\n",
      "1683/1683 [==============================] - 10s 6ms/step - loss: 0.6403 - accuracy: 0.7778\n",
      "Epoch 13/40\n",
      "1683/1683 [==============================] - 8s 5ms/step - loss: 0.6212 - accuracy: 0.7850\n",
      "Epoch 14/40\n",
      "1683/1683 [==============================] - 8s 5ms/step - loss: 0.5974 - accuracy: 0.7937\n",
      "Epoch 15/40\n",
      "1683/1683 [==============================] - 8s 5ms/step - loss: 0.5825 - accuracy: 0.7991\n",
      "Epoch 16/40\n",
      "1683/1683 [==============================] - 8s 5ms/step - loss: 0.5646 - accuracy: 0.8049\n",
      "Epoch 17/40\n",
      "1683/1683 [==============================] - 8s 5ms/step - loss: 0.5469 - accuracy: 0.8105\n",
      "Epoch 18/40\n",
      "1683/1683 [==============================] - 11s 6ms/step - loss: 0.5380 - accuracy: 0.8146\n",
      "Epoch 19/40\n",
      "1683/1683 [==============================] - 8s 4ms/step - loss: 0.5278 - accuracy: 0.8168\n",
      "Epoch 20/40\n",
      "1683/1683 [==============================] - 8s 5ms/step - loss: 0.5117 - accuracy: 0.8229\n",
      "Epoch 21/40\n",
      "1683/1683 [==============================] - 8s 5ms/step - loss: 0.5044 - accuracy: 0.8245\n",
      "Epoch 22/40\n",
      "1683/1683 [==============================] - 8s 5ms/step - loss: 0.4912 - accuracy: 0.8300\n",
      "Epoch 23/40\n",
      "1683/1683 [==============================] - 8s 5ms/step - loss: 0.4824 - accuracy: 0.8325\n",
      "Epoch 24/40\n",
      "1683/1683 [==============================] - 10s 6ms/step - loss: 0.4727 - accuracy: 0.8374\n",
      "Epoch 25/40\n",
      "1683/1683 [==============================] - 8s 5ms/step - loss: 0.4692 - accuracy: 0.8374\n",
      "Epoch 26/40\n",
      "1683/1683 [==============================] - 8s 5ms/step - loss: 0.4565 - accuracy: 0.8413\n",
      "Epoch 27/40\n",
      "1683/1683 [==============================] - 8s 5ms/step - loss: 0.4443 - accuracy: 0.8474\n",
      "Epoch 28/40\n",
      "1683/1683 [==============================] - 8s 5ms/step - loss: 0.4367 - accuracy: 0.8499\n",
      "Epoch 29/40\n",
      "1683/1683 [==============================] - 7s 4ms/step - loss: 0.4352 - accuracy: 0.8501\n",
      "Epoch 30/40\n",
      "1683/1683 [==============================] - 8s 5ms/step - loss: 0.4252 - accuracy: 0.8528\n",
      "Epoch 31/40\n",
      "1683/1683 [==============================] - 11s 6ms/step - loss: 0.4182 - accuracy: 0.8549\n",
      "Epoch 32/40\n",
      "1683/1683 [==============================] - 8s 5ms/step - loss: 0.4169 - accuracy: 0.8575\n",
      "Epoch 33/40\n",
      "1683/1683 [==============================] - 8s 5ms/step - loss: 0.4074 - accuracy: 0.8605\n",
      "Epoch 34/40\n",
      "1683/1683 [==============================] - 8s 5ms/step - loss: 0.4053 - accuracy: 0.8607\n",
      "Epoch 35/40\n",
      "1683/1683 [==============================] - 8s 5ms/step - loss: 0.3905 - accuracy: 0.8659\n",
      "Epoch 36/40\n",
      "1683/1683 [==============================] - 7s 4ms/step - loss: 0.3930 - accuracy: 0.8643\n",
      "Epoch 37/40\n",
      "1683/1683 [==============================] - 8s 5ms/step - loss: 0.3893 - accuracy: 0.8673\n",
      "Epoch 38/40\n",
      "1683/1683 [==============================] - 9s 5ms/step - loss: 0.3838 - accuracy: 0.8684\n",
      "Epoch 39/40\n",
      "1683/1683 [==============================] - 9s 5ms/step - loss: 0.3776 - accuracy: 0.8710\n",
      "Epoch 40/40\n",
      "1683/1683 [==============================] - 8s 5ms/step - loss: 0.3702 - accuracy: 0.8732\n",
      "For  40  Epochs:\n",
      "Log-loss for Train Dataset =  0.1293708211748821\n",
      "Log-loss for Test Dataset =  0.7864242589716581\n",
      "Accuracy for Train Dataset =  0.961005424686037\n",
      "Accuracy for Test Dataset =  0.7689\n",
      "\n",
      "Epoch 1/50\n",
      "1683/1683 [==============================] - 8s 4ms/step - loss: 1.6508 - accuracy: 0.3933\n",
      "Epoch 2/50\n",
      "1683/1683 [==============================] - 8s 4ms/step - loss: 1.2533 - accuracy: 0.5557\n",
      "Epoch 3/50\n",
      "1683/1683 [==============================] - 8s 5ms/step - loss: 1.0890 - accuracy: 0.6205\n",
      "Epoch 4/50\n",
      "1683/1683 [==============================] - 8s 5ms/step - loss: 0.9828 - accuracy: 0.6615\n",
      "Epoch 5/50\n",
      "1683/1683 [==============================] - 10s 6ms/step - loss: 0.9088 - accuracy: 0.6872\n",
      "Epoch 6/50\n",
      "1683/1683 [==============================] - 8s 5ms/step - loss: 0.8490 - accuracy: 0.7081\n",
      "Epoch 7/50\n",
      "1683/1683 [==============================] - 8s 5ms/step - loss: 0.8026 - accuracy: 0.7244\n",
      "Epoch 8/50\n",
      "1683/1683 [==============================] - 8s 4ms/step - loss: 0.7582 - accuracy: 0.7388\n",
      "Epoch 9/50\n",
      "1683/1683 [==============================] - 8s 5ms/step - loss: 0.7314 - accuracy: 0.7480\n",
      "Epoch 10/50\n",
      "1683/1683 [==============================] - 8s 5ms/step - loss: 0.6934 - accuracy: 0.7616\n",
      "Epoch 11/50\n",
      "1683/1683 [==============================] - 8s 5ms/step - loss: 0.6732 - accuracy: 0.7691\n",
      "Epoch 12/50\n",
      "1683/1683 [==============================] - 9s 5ms/step - loss: 0.6415 - accuracy: 0.7780\n",
      "Epoch 13/50\n",
      "1683/1683 [==============================] - 10s 6ms/step - loss: 0.6205 - accuracy: 0.7870\n",
      "Epoch 14/50\n",
      "1683/1683 [==============================] - 8s 5ms/step - loss: 0.6009 - accuracy: 0.7932\n",
      "Epoch 15/50\n",
      "1683/1683 [==============================] - 8s 5ms/step - loss: 0.5836 - accuracy: 0.7999\n",
      "Epoch 16/50\n",
      "1683/1683 [==============================] - 8s 5ms/step - loss: 0.5667 - accuracy: 0.8053\n",
      "Epoch 17/50\n",
      "1683/1683 [==============================] - 8s 5ms/step - loss: 0.5498 - accuracy: 0.8120\n",
      "Epoch 18/50\n",
      "1683/1683 [==============================] - 8s 5ms/step - loss: 0.5377 - accuracy: 0.8152\n",
      "Epoch 19/50\n",
      "1683/1683 [==============================] - 8s 5ms/step - loss: 0.5244 - accuracy: 0.8206\n",
      "Epoch 20/50\n",
      "1683/1683 [==============================] - 10s 6ms/step - loss: 0.5124 - accuracy: 0.8243\n",
      "Epoch 21/50\n",
      "1683/1683 [==============================] - 8s 4ms/step - loss: 0.4981 - accuracy: 0.8286\n",
      "Epoch 22/50\n",
      "1683/1683 [==============================] - 8s 5ms/step - loss: 0.4883 - accuracy: 0.8325\n",
      "Epoch 23/50\n",
      "1683/1683 [==============================] - 8s 5ms/step - loss: 0.4785 - accuracy: 0.8331\n",
      "Epoch 24/50\n",
      "1683/1683 [==============================] - 8s 5ms/step - loss: 0.4688 - accuracy: 0.8388\n",
      "Epoch 25/50\n",
      "1683/1683 [==============================] - 8s 5ms/step - loss: 0.4595 - accuracy: 0.8410\n",
      "Epoch 26/50\n",
      "1683/1683 [==============================] - 10s 6ms/step - loss: 0.4495 - accuracy: 0.8463\n",
      "Epoch 27/50\n",
      "1683/1683 [==============================] - 9s 6ms/step - loss: 0.4480 - accuracy: 0.8451\n",
      "Epoch 28/50\n",
      "1683/1683 [==============================] - 8s 5ms/step - loss: 0.4340 - accuracy: 0.8500\n",
      "Epoch 29/50\n",
      "1683/1683 [==============================] - 8s 5ms/step - loss: 0.4292 - accuracy: 0.8531\n",
      "Epoch 30/50\n",
      "1683/1683 [==============================] - 8s 5ms/step - loss: 0.4213 - accuracy: 0.8570\n",
      "Epoch 31/50\n",
      "1683/1683 [==============================] - 8s 5ms/step - loss: 0.4191 - accuracy: 0.8561\n",
      "Epoch 32/50\n",
      "1683/1683 [==============================] - 8s 5ms/step - loss: 0.4074 - accuracy: 0.8584\n",
      "Epoch 33/50\n",
      "1683/1683 [==============================] - 9s 5ms/step - loss: 0.4079 - accuracy: 0.8595\n",
      "Epoch 34/50\n",
      "1683/1683 [==============================] - 10s 6ms/step - loss: 0.4058 - accuracy: 0.8614\n",
      "Epoch 35/50\n",
      "1683/1683 [==============================] - 8s 5ms/step - loss: 0.3945 - accuracy: 0.8667\n",
      "Epoch 36/50\n",
      "1683/1683 [==============================] - 8s 5ms/step - loss: 0.3874 - accuracy: 0.8684\n",
      "Epoch 37/50\n",
      "1683/1683 [==============================] - 8s 5ms/step - loss: 0.3892 - accuracy: 0.8681\n",
      "Epoch 38/50\n",
      "1683/1683 [==============================] - 8s 5ms/step - loss: 0.3807 - accuracy: 0.8707\n",
      "Epoch 39/50\n",
      "1683/1683 [==============================] - 8s 5ms/step - loss: 0.3820 - accuracy: 0.8693\n",
      "Epoch 40/50\n",
      "1683/1683 [==============================] - 8s 5ms/step - loss: 0.3726 - accuracy: 0.8736\n",
      "Epoch 41/50\n",
      "1683/1683 [==============================] - 9s 6ms/step - loss: 0.3749 - accuracy: 0.8735\n",
      "Epoch 42/50\n",
      "1683/1683 [==============================] - 8s 5ms/step - loss: 0.3611 - accuracy: 0.8771\n",
      "Epoch 43/50\n",
      "1683/1683 [==============================] - 8s 5ms/step - loss: 0.3561 - accuracy: 0.8792\n",
      "Epoch 44/50\n",
      "1683/1683 [==============================] - 8s 5ms/step - loss: 0.3604 - accuracy: 0.8769\n",
      "Epoch 45/50\n",
      "1683/1683 [==============================] - 8s 5ms/step - loss: 0.3601 - accuracy: 0.8779\n",
      "Epoch 46/50\n",
      "1683/1683 [==============================] - 8s 5ms/step - loss: 0.3491 - accuracy: 0.8807\n",
      "Epoch 47/50\n",
      "1683/1683 [==============================] - 9s 5ms/step - loss: 0.3478 - accuracy: 0.8803\n",
      "Epoch 48/50\n",
      "1683/1683 [==============================] - 10s 6ms/step - loss: 0.3417 - accuracy: 0.8855\n",
      "Epoch 49/50\n",
      "1683/1683 [==============================] - 8s 5ms/step - loss: 0.3445 - accuracy: 0.8839\n",
      "Epoch 50/50\n",
      "1683/1683 [==============================] - 8s 5ms/step - loss: 0.3400 - accuracy: 0.8832\n",
      "For  50  Epochs:\n",
      "Log-loss for Train Dataset =  0.13997735739697664\n",
      "Log-loss for Test Dataset =  0.883477612489017\n",
      "Accuracy for Train Dataset =  0.9565839340120383\n",
      "Accuracy for Test Dataset =  0.745\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = [10, 20, 30, 40, 50]\n",
    "train_loss, test_loss, train_acc, test_acc = [], [], [], []\n",
    "\n",
    "for epochs in num_epochs:\n",
    "    # Training the Model\n",
    "    conv_model = cnn_model((32, 32, 3))\n",
    "    conv_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics='accuracy')\n",
    "    conv_model.fit(train_dataset, epochs = epochs)\n",
    "    \n",
    "    # Predicting on the Train/Test Datasets\n",
    "    preds_train = conv_model.predict(df_aug)\n",
    "    preds_test = conv_model.predict(df_test)\n",
    "\n",
    "    # Finding the Predicted Classes\n",
    "    cls_train = np.argmax(preds_train, axis = 1)\n",
    "    cls_test = np.argmax(preds_test, axis = 1)\n",
    "    \n",
    "    # Finding the Train/Test set Loss\n",
    "    train_loss.append(log_loss(y_aug_oh, preds_train))\n",
    "    test_loss.append(log_loss(y_test_oh, preds_test))\n",
    "    train_acc.append(accuracy_score(y_aug, cls_train))\n",
    "    test_acc.append(accuracy_score(y_test, cls_test))\n",
    "    \n",
    "    print(\"For \", epochs, \" Epochs:\")\n",
    "    print(\"Log-loss for Train Dataset = \", train_loss[-1])\n",
    "    print(\"Log-loss for Test Dataset = \", test_loss[-1])\n",
    "    print(\"Accuracy for Train Dataset = \", train_acc[-1])\n",
    "    print(\"Accuracy for Test Dataset = \", test_acc[-1])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43b83435",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2022-04-08T17:58:12.337610Z",
     "iopub.status.busy": "2022-04-08T17:58:12.336752Z",
     "iopub.status.idle": "2022-04-08T18:04:49.497220Z",
     "shell.execute_reply": "2022-04-08T18:04:49.496720Z"
    },
    "papermill": {
     "duration": 405.239685,
     "end_time": "2022-04-08T18:04:49.497365",
     "exception": false,
     "start_time": "2022-04-08T17:58:04.257680",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "1683/1683 [==============================] - 8s 5ms/step - loss: 1.6716 - accuracy: 0.3871\n",
      "Epoch 2/40\n",
      "1683/1683 [==============================] - 8s 5ms/step - loss: 1.2505 - accuracy: 0.5573\n",
      "Epoch 3/40\n",
      "1683/1683 [==============================] - 8s 5ms/step - loss: 1.0725 - accuracy: 0.6295\n",
      "Epoch 4/40\n",
      "1683/1683 [==============================] - 8s 5ms/step - loss: 0.9632 - accuracy: 0.6658\n",
      "Epoch 5/40\n",
      "1683/1683 [==============================] - 8s 5ms/step - loss: 0.8894 - accuracy: 0.6927\n",
      "Epoch 6/40\n",
      "1683/1683 [==============================] - 8s 5ms/step - loss: 0.8294 - accuracy: 0.7137\n",
      "Epoch 7/40\n",
      "1683/1683 [==============================] - 11s 7ms/step - loss: 0.7890 - accuracy: 0.7304\n",
      "Epoch 8/40\n",
      "1683/1683 [==============================] - 9s 5ms/step - loss: 0.7483 - accuracy: 0.7425\n",
      "Epoch 9/40\n",
      "1683/1683 [==============================] - 7s 4ms/step - loss: 0.7178 - accuracy: 0.7531\n",
      "Epoch 10/40\n",
      "1683/1683 [==============================] - 7s 4ms/step - loss: 0.6913 - accuracy: 0.7622\n",
      "Epoch 11/40\n",
      "1683/1683 [==============================] - 7s 4ms/step - loss: 0.6575 - accuracy: 0.7742\n",
      "Epoch 12/40\n",
      "1683/1683 [==============================] - 7s 4ms/step - loss: 0.6329 - accuracy: 0.7810\n",
      "Epoch 13/40\n",
      "1683/1683 [==============================] - 8s 5ms/step - loss: 0.6204 - accuracy: 0.7856\n",
      "Epoch 14/40\n",
      "1683/1683 [==============================] - 8s 5ms/step - loss: 0.6011 - accuracy: 0.7919\n",
      "Epoch 15/40\n",
      "1683/1683 [==============================] - 8s 5ms/step - loss: 0.5803 - accuracy: 0.7997\n",
      "Epoch 16/40\n",
      "1683/1683 [==============================] - 8s 5ms/step - loss: 0.5625 - accuracy: 0.8055\n",
      "Epoch 17/40\n",
      "1683/1683 [==============================] - 8s 5ms/step - loss: 0.5500 - accuracy: 0.8105\n",
      "Epoch 18/40\n",
      "1683/1683 [==============================] - 8s 5ms/step - loss: 0.5316 - accuracy: 0.8148\n",
      "Epoch 19/40\n",
      "1683/1683 [==============================] - 7s 4ms/step - loss: 0.5210 - accuracy: 0.8199\n",
      "Epoch 20/40\n",
      "1683/1683 [==============================] - 9s 5ms/step - loss: 0.5094 - accuracy: 0.8236\n",
      "Epoch 21/40\n",
      "1683/1683 [==============================] - 11s 6ms/step - loss: 0.5003 - accuracy: 0.8250\n",
      "Epoch 22/40\n",
      "1683/1683 [==============================] - 8s 4ms/step - loss: 0.4795 - accuracy: 0.8321\n",
      "Epoch 23/40\n",
      "1683/1683 [==============================] - 7s 4ms/step - loss: 0.4705 - accuracy: 0.8371\n",
      "Epoch 24/40\n",
      "1683/1683 [==============================] - 8s 5ms/step - loss: 0.4691 - accuracy: 0.8387\n",
      "Epoch 25/40\n",
      "1683/1683 [==============================] - 8s 5ms/step - loss: 0.4532 - accuracy: 0.8412\n",
      "Epoch 26/40\n",
      "1683/1683 [==============================] - 8s 5ms/step - loss: 0.4545 - accuracy: 0.8433\n",
      "Epoch 27/40\n",
      "1683/1683 [==============================] - 8s 5ms/step - loss: 0.4374 - accuracy: 0.8491\n",
      "Epoch 28/40\n",
      "1683/1683 [==============================] - 8s 5ms/step - loss: 0.4328 - accuracy: 0.8516\n",
      "Epoch 29/40\n",
      "1683/1683 [==============================] - 8s 5ms/step - loss: 0.4276 - accuracy: 0.8529\n",
      "Epoch 30/40\n",
      "1683/1683 [==============================] - 7s 4ms/step - loss: 0.4160 - accuracy: 0.8575\n",
      "Epoch 31/40\n",
      "1683/1683 [==============================] - 8s 4ms/step - loss: 0.4145 - accuracy: 0.8580\n",
      "Epoch 32/40\n",
      "1683/1683 [==============================] - 8s 5ms/step - loss: 0.4041 - accuracy: 0.8602\n",
      "Epoch 33/40\n",
      "1683/1683 [==============================] - 8s 5ms/step - loss: 0.4008 - accuracy: 0.8622\n",
      "Epoch 34/40\n",
      "1683/1683 [==============================] - 8s 5ms/step - loss: 0.4009 - accuracy: 0.8615\n",
      "Epoch 35/40\n",
      "1683/1683 [==============================] - 11s 6ms/step - loss: 0.3898 - accuracy: 0.8677\n",
      "Epoch 36/40\n",
      "1683/1683 [==============================] - 9s 5ms/step - loss: 0.3914 - accuracy: 0.8664\n",
      "Epoch 37/40\n",
      "1683/1683 [==============================] - 8s 5ms/step - loss: 0.3805 - accuracy: 0.8706\n",
      "Epoch 38/40\n",
      "1683/1683 [==============================] - 8s 5ms/step - loss: 0.3754 - accuracy: 0.8717\n",
      "Epoch 39/40\n",
      "1683/1683 [==============================] - 8s 5ms/step - loss: 0.3673 - accuracy: 0.8748\n",
      "Epoch 40/40\n",
      "1683/1683 [==============================] - 8s 5ms/step - loss: 0.3718 - accuracy: 0.8734\n"
     ]
    }
   ],
   "source": [
    "# Training the Model with the best hyper-parameter settings\n",
    "ind = np.argmax(test_acc)\n",
    "best_num_epochs = num_epochs[ind]\n",
    "conv_model = cnn_model((32, 32, 3))\n",
    "conv_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics='accuracy')\n",
    "conv_model.fit(train_dataset, epochs = best_num_epochs)\n",
    "\n",
    "# Saving the model along with it's weights\n",
    "conv_model.save('hybrid_trad_gan_augmented.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543c229a",
   "metadata": {
    "papermill": {
     "duration": 9.598442,
     "end_time": "2022-04-08T18:05:08.560915",
     "exception": false,
     "start_time": "2022-04-08T18:04:58.962473",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 4.2. Predicting the Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d5ef4d54",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-08T18:05:28.197941Z",
     "iopub.status.busy": "2022-04-08T18:05:28.196973Z",
     "iopub.status.idle": "2022-04-08T18:05:33.104641Z",
     "shell.execute_reply": "2022-04-08T18:05:33.105052Z"
    },
    "papermill": {
     "duration": 14.489137,
     "end_time": "2022-04-08T18:05:33.105197",
     "exception": false,
     "start_time": "2022-04-08T18:05:18.616060",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log-loss for Augmented Dataset =  0.14989328262409068\n",
      "Log-loss for Test Dataset =  0.8253970891010501\n",
      "Accuracy for Augmented Dataset =  0.9504904510663595\n",
      "Accuracy for Test Dataset =  0.7595\n"
     ]
    }
   ],
   "source": [
    "# Predicting on the Train/Test Datasets\n",
    "preds_train = conv_model.predict(df_aug)\n",
    "preds_test = conv_model.predict(df_test)\n",
    "\n",
    "# Finding the Predicted Classes\n",
    "cls_train = np.argmax(preds_train, axis = 1)\n",
    "cls_test = np.argmax(preds_test, axis = 1)\n",
    "\n",
    "# Finding the Train/Test set Loss\n",
    "print(\"Log-loss for Augmented Dataset = \", log_loss(y_aug_oh, preds_train))\n",
    "print(\"Log-loss for Test Dataset = \", log_loss(y_test_oh, preds_test))\n",
    "print(\"Accuracy for Augmented Dataset = \", accuracy_score(y_aug, cls_train))\n",
    "print(\"Accuracy for Test Dataset = \", accuracy_score(y_test, cls_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2111.668221,
   "end_time": "2022-04-08T18:05:46.606868",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-04-08T17:30:34.938647",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
