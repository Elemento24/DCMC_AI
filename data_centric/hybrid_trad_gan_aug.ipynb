{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b5f9985",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 0.012343,
     "end_time": "2022-05-10T10:37:04.507623",
     "exception": false,
     "start_time": "2022-05-10T10:37:04.495280",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Hybridization of Traditional and GAN-based Augmentations\n",
    "- In this kernel, we will be performing the Hybridization of **Traditional Augmentation** and **GAN-Based Augmentation** approaches. \n",
    "- In the traditional and GAN-based augmentation kernels, we have tried 3 different approaches in each. In this manner, we can have 9 different combinations for this hybridization. However, in this kernel, we will only be using a single combination. From both the kernels, we will be selecting the approach with the best performance scores, and combining them only. \n",
    "- We have used 3 performance metrics in each of the 3 different approaches, **Multi-Class Log-Loss**, **Weighted F1-Score** and **Accuracy**. We selected the approach which outperformed the other 2, in at least 2 out of these 3 different performance metrics. \n",
    "- From the traditional augmentation kernel, we will be selecting 'Augmentation based on class-wise performance' (**77.39% accuracy**), and from the GAN-based augmentation kernel too, we will be selecting 'Augmentation based on class-wise performance' (**76.64% accuracy**).\n",
    "- We will apply the aforementioned approaches individually on the training dataset, and then will be merging both of the augmented datasets with the training set.\n",
    "\n",
    "### Reference Kernels\n",
    "- [Traditional Augmentation](https://www.kaggle.com/code/elemento/rw-tradaug)\n",
    "- [GANs Augmentation 1](https://www.kaggle.com/code/elemento/rw-ganaug-1) and [GANs Augmentation 2](https://www.kaggle.com/code/elemento/rw-ganaug-2)\n",
    "\n",
    "# 1. Importing the Packages & Boilerplate Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb329d91",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-10T10:37:04.535440Z",
     "iopub.status.busy": "2022-05-10T10:37:04.533952Z",
     "iopub.status.idle": "2022-05-10T10:37:10.332273Z",
     "shell.execute_reply": "2022-05-10T10:37:10.331638Z"
    },
    "papermill": {
     "duration": 5.813318,
     "end_time": "2022-05-10T10:37:10.332457",
     "exception": false,
     "start_time": "2022-05-10T10:37:04.519139",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from shutil import copyfile\n",
    "from tabulate import tabulate\n",
    "from sklearn.metrics import accuracy_score, log_loss, confusion_matrix, f1_score\n",
    "\n",
    "# https://www.kaggle.com/c/ventilator-pressure-prediction/discussion/274717\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as tfl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f1843b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-10T10:37:10.361162Z",
     "iopub.status.busy": "2022-05-10T10:37:10.360500Z",
     "iopub.status.idle": "2022-05-10T10:37:10.362989Z",
     "shell.execute_reply": "2022-05-10T10:37:10.362594Z"
    },
    "papermill": {
     "duration": 0.018772,
     "end_time": "2022-05-10T10:37:10.363093",
     "exception": false,
     "start_time": "2022-05-10T10:37:10.344321",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setting the seeds\n",
    "SEED = 0\n",
    "os.environ['PYTHONHASHSEED']=str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55ab314c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-10T10:37:12.372950Z",
     "iopub.status.busy": "2022-05-10T10:37:12.372347Z",
     "iopub.status.idle": "2022-05-10T10:37:12.377435Z",
     "shell.execute_reply": "2022-05-10T10:37:12.376951Z"
    },
    "papermill": {
     "duration": 2.003105,
     "end_time": "2022-05-10T10:37:12.377562",
     "exception": false,
     "start_time": "2022-05-10T10:37:10.374457",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU at: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "# Making sure that Tensorflow is able to detect the GPU\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if \"GPU\" not in device_name:\n",
    "    print(\"GPU device not found\")\n",
    "print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1127a1cf",
   "metadata": {
    "papermill": {
     "duration": 0.012836,
     "end_time": "2022-05-10T10:37:12.403710",
     "exception": false,
     "start_time": "2022-05-10T10:37:12.390874",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 2. Importing the Train and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4161a57",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-10T10:37:12.439067Z",
     "iopub.status.busy": "2022-05-10T10:37:12.438434Z",
     "iopub.status.idle": "2022-05-10T10:37:39.686444Z",
     "shell.execute_reply": "2022-05-10T10:37:39.685964Z"
    },
    "papermill": {
     "duration": 27.269773,
     "end_time": "2022-05-10T10:37:39.686579",
     "exception": false,
     "start_time": "2022-05-10T10:37:12.416806",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Train Dataset:\n",
      "(40006, 3072) (40006, 1)\n",
      "(40006, 32, 32, 3)\n",
      "For Test Dataset:\n",
      "(10000, 3072) (10000, 1)\n",
      "(10000, 3, 32, 32)\n",
      "(10000, 32, 32, 3) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "# Importing the Labelled Training Dataset\n",
    "print(\"For Train Dataset:\")\n",
    "df_train = pd.read_csv(\"../input/cifar10/train_lab_x.csv\")\n",
    "y_train = pd.read_csv(\"../input/cifar10/train_lab_y.csv\")\n",
    "df_train = np.array(df_train)\n",
    "y_train = np.array(y_train)\n",
    "print(df_train.shape, y_train.shape)\n",
    "\n",
    "# Reshaping, rescaling and one-hot encoding\n",
    "df_train = np.reshape(df_train, (-1, 3, 32, 32))\n",
    "df_train = np.transpose(np.array(df_train), (0, 2, 3, 1))\n",
    "df_train = df_train / 255\n",
    "print(df_train.shape)\n",
    "\n",
    "# Importing the Test Dataset\n",
    "print(\"For Test Dataset:\")\n",
    "df_test = pd.read_csv(\"../input/cifar10/test_x.csv\")\n",
    "y_test = pd.read_csv(\"../input/cifar10/test_y.csv\")\n",
    "df_test = np.array(df_test)\n",
    "y_test = np.array(y_test)\n",
    "print(df_test.shape, y_test.shape)\n",
    "\n",
    "# Reshaping the dataset\n",
    "df_test = np.reshape(df_test, (-1, 3, 32, 32))\n",
    "print(df_test.shape)\n",
    "\n",
    "# Reshaping, rescaling and one-hot encoding\n",
    "df_test = np.transpose(np.array(df_test), (0, 2, 3, 1))\n",
    "df_test = df_test / 255\n",
    "y_test_oh = tf.one_hot(np.ravel(y_test), depth = 10)\n",
    "print(df_test.shape, y_test_oh.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1698ceb0",
   "metadata": {
    "papermill": {
     "duration": 0.013507,
     "end_time": "2022-05-10T10:37:39.714112",
     "exception": false,
     "start_time": "2022-05-10T10:37:39.700605",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 3. Performing the Augmentations on the Training Set\n",
    "## 3.1. GAN-Based Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ace96b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-10T10:37:39.746340Z",
     "iopub.status.busy": "2022-05-10T10:37:39.745845Z",
     "iopub.status.idle": "2022-05-10T10:37:49.720778Z",
     "shell.execute_reply": "2022-05-10T10:37:49.721296Z"
    },
    "papermill": {
     "duration": 9.993802,
     "end_time": "2022-05-10T10:37:49.721486",
     "exception": false,
     "start_time": "2022-05-10T10:37:39.727684",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10048, 32, 32, 3) (10048, 1)\n"
     ]
    }
   ],
   "source": [
    "df_gan_aug = pd.read_csv(\"../input/cifar10/df_clsper_gan_aug.csv\")\n",
    "y_gan_aug = pd.read_csv(\"../input/cifar10/y_clsper_gan_aug.csv\")\n",
    "df_gan_aug = np.array(df_gan_aug)\n",
    "y_gan_aug = np.array(y_gan_aug)\n",
    "\n",
    "# Reshaping, rescaling and one-hot encoding\n",
    "df_gan_aug = np.reshape(df_gan_aug, (-1, 3, 32, 32))\n",
    "df_gan_aug = np.transpose(np.array(df_gan_aug), (0, 2, 3, 1))\n",
    "print(df_gan_aug.shape, y_gan_aug.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13ee0ad",
   "metadata": {
    "papermill": {
     "duration": 0.013957,
     "end_time": "2022-05-10T10:37:49.749894",
     "exception": false,
     "start_time": "2022-05-10T10:37:49.735937",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3.2. Traditional Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "729cf718",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-10T10:37:49.785193Z",
     "iopub.status.busy": "2022-05-10T10:37:49.784523Z",
     "iopub.status.idle": "2022-05-10T10:37:58.885343Z",
     "shell.execute_reply": "2022-05-10T10:37:58.885770Z"
    },
    "papermill": {
     "duration": 9.122017,
     "end_time": "2022-05-10T10:37:58.885916",
     "exception": false,
     "start_time": "2022-05-10T10:37:49.763899",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10074, 32, 32, 3) (10074, 1)\n"
     ]
    }
   ],
   "source": [
    "df_trad_aug = pd.read_csv(\"../input/cifar10/df_clsper_trad_aug.csv\")\n",
    "y_trad_aug = pd.read_csv(\"../input/cifar10/y_clsper_trad_aug.csv\")\n",
    "df_trad_aug = np.array(df_trad_aug)\n",
    "y_trad_aug = np.array(y_trad_aug)\n",
    "\n",
    "# Reshaping, rescaling and one-hot encoding\n",
    "df_trad_aug = np.reshape(df_trad_aug, (-1, 32, 32, 3))\n",
    "print(df_trad_aug.shape, y_trad_aug.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d11873",
   "metadata": {
    "papermill": {
     "duration": 0.014743,
     "end_time": "2022-05-10T10:37:58.915997",
     "exception": false,
     "start_time": "2022-05-10T10:37:58.901254",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3.3. Preparing the Augmented Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45d737cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-10T10:37:58.951871Z",
     "iopub.status.busy": "2022-05-10T10:37:58.950837Z",
     "iopub.status.idle": "2022-05-10T10:38:02.397286Z",
     "shell.execute_reply": "2022-05-10T10:38:02.397919Z"
    },
    "papermill": {
     "duration": 3.467489,
     "end_time": "2022-05-10T10:38:02.398085",
     "exception": false,
     "start_time": "2022-05-10T10:37:58.930596",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60128, 32, 32, 3) (60128, 1) (60128, 10)\n"
     ]
    }
   ],
   "source": [
    "# Concatenating the Training with Augmenting Dataset\n",
    "df_aug = np.concatenate([df_train, df_gan_aug, df_trad_aug], axis=0)\n",
    "y_aug = np.concatenate([y_train, y_gan_aug, y_trad_aug], axis=0)\n",
    "\n",
    "# Creating a random permutation & shuffling the dataset\n",
    "perm = np.random.permutation(df_aug.shape[0])\n",
    "df_aug = np.array(df_aug[perm, : , : , : ])\n",
    "y_aug = y_aug[perm]\n",
    "\n",
    "# One-Hot Encoding\n",
    "y_aug_oh = tf.one_hot(np.ravel(y_aug), depth = 10)\n",
    "print(df_aug.shape, y_aug.shape, y_aug_oh.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb657a5a",
   "metadata": {
    "papermill": {
     "duration": 0.025525,
     "end_time": "2022-05-10T10:38:02.447750",
     "exception": false,
     "start_time": "2022-05-10T10:38:02.422225",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 4. Training the Model\n",
    "## 4.1. Preparing the Baseline Model and the Augmented Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "727fc805",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2022-05-10T10:38:02.505725Z",
     "iopub.status.busy": "2022-05-10T10:38:02.503189Z",
     "iopub.status.idle": "2022-05-10T10:38:05.036619Z",
     "shell.execute_reply": "2022-05-10T10:38:05.036127Z"
    },
    "papermill": {
     "duration": 2.562001,
     "end_time": "2022-05-10T10:38:05.036759",
     "exception": false,
     "start_time": "2022-05-10T10:38:02.474758",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Importing the Baseline Model Architecture\n",
    "copyfile(src = \"../input/dcai-rw/baseline_arch.py\", dst = \"../working/baseline_arch.py\")\n",
    "from baseline_arch import cnn_model\n",
    "\n",
    "# Creating Batches from the Augmented Dataset\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((df_aug, y_aug_oh)).batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f514141a",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2022-05-10T10:38:05.078159Z",
     "iopub.status.busy": "2022-05-10T10:38:05.077563Z",
     "iopub.status.idle": "2022-05-10T11:13:02.769613Z",
     "shell.execute_reply": "2022-05-10T11:13:02.769122Z"
    },
    "papermill": {
     "duration": 2097.717567,
     "end_time": "2022-05-10T11:13:02.769758",
     "exception": false,
     "start_time": "2022-05-10T10:38:05.052191",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1879/1879 [==============================] - 15s 4ms/step - loss: 1.6392 - accuracy: 0.3882\n",
      "Epoch 2/10\n",
      "1879/1879 [==============================] - 8s 4ms/step - loss: 1.2444 - accuracy: 0.5511\n",
      "Epoch 3/10\n",
      "1879/1879 [==============================] - 9s 5ms/step - loss: 1.0715 - accuracy: 0.6239\n",
      "Epoch 4/10\n",
      "1879/1879 [==============================] - 9s 5ms/step - loss: 0.9653 - accuracy: 0.6605\n",
      "Epoch 5/10\n",
      "1879/1879 [==============================] - 8s 4ms/step - loss: 0.8932 - accuracy: 0.6866\n",
      "Epoch 6/10\n",
      "1879/1879 [==============================] - 9s 5ms/step - loss: 0.8415 - accuracy: 0.7054\n",
      "Epoch 7/10\n",
      "1879/1879 [==============================] - 8s 4ms/step - loss: 0.7988 - accuracy: 0.7194\n",
      "Epoch 8/10\n",
      "1879/1879 [==============================] - 8s 4ms/step - loss: 0.7586 - accuracy: 0.7344\n",
      "Epoch 9/10\n",
      "1879/1879 [==============================] - 9s 5ms/step - loss: 0.7294 - accuracy: 0.7448\n",
      "Epoch 10/10\n",
      "1879/1879 [==============================] - 8s 4ms/step - loss: 0.6909 - accuracy: 0.7571\n",
      "For  10  Epochs:\n",
      "Log-loss for Train Dataset =  0.4738186323837023\n",
      "Log-loss for Test Dataset =  0.7703266763706831\n",
      "Accuracy for Train Dataset =  0.8331226716338478\n",
      "Accuracy for Test Dataset =  0.7368\n",
      "\n",
      "Epoch 1/20\n",
      "1879/1879 [==============================] - 9s 5ms/step - loss: 1.6470 - accuracy: 0.3851\n",
      "Epoch 2/20\n",
      "1879/1879 [==============================] - 9s 5ms/step - loss: 1.2565 - accuracy: 0.5458\n",
      "Epoch 3/20\n",
      "1879/1879 [==============================] - 8s 4ms/step - loss: 1.0945 - accuracy: 0.6095\n",
      "Epoch 4/20\n",
      "1879/1879 [==============================] - 8s 4ms/step - loss: 0.9867 - accuracy: 0.6513\n",
      "Epoch 5/20\n",
      "1879/1879 [==============================] - 9s 5ms/step - loss: 0.9173 - accuracy: 0.6766\n",
      "Epoch 6/20\n",
      "1879/1879 [==============================] - 8s 4ms/step - loss: 0.8589 - accuracy: 0.6954\n",
      "Epoch 7/20\n",
      "1879/1879 [==============================] - 9s 5ms/step - loss: 0.8138 - accuracy: 0.7127\n",
      "Epoch 8/20\n",
      "1879/1879 [==============================] - 9s 5ms/step - loss: 0.7797 - accuracy: 0.7267\n",
      "Epoch 9/20\n",
      "1879/1879 [==============================] - 9s 5ms/step - loss: 0.7438 - accuracy: 0.7385\n",
      "Epoch 10/20\n",
      "1879/1879 [==============================] - 8s 4ms/step - loss: 0.7187 - accuracy: 0.7481\n",
      "Epoch 11/20\n",
      "1879/1879 [==============================] - 9s 5ms/step - loss: 0.6923 - accuracy: 0.7549\n",
      "Epoch 12/20\n",
      "1879/1879 [==============================] - 9s 5ms/step - loss: 0.6657 - accuracy: 0.7653\n",
      "Epoch 13/20\n",
      "1879/1879 [==============================] - 8s 4ms/step - loss: 0.6469 - accuracy: 0.7730\n",
      "Epoch 14/20\n",
      "1879/1879 [==============================] - 9s 5ms/step - loss: 0.6304 - accuracy: 0.7784\n",
      "Epoch 15/20\n",
      "1879/1879 [==============================] - 8s 4ms/step - loss: 0.6209 - accuracy: 0.7822\n",
      "Epoch 16/20\n",
      "1879/1879 [==============================] - 9s 5ms/step - loss: 0.5889 - accuracy: 0.7943\n",
      "Epoch 17/20\n",
      "1879/1879 [==============================] - 8s 4ms/step - loss: 0.5803 - accuracy: 0.7977\n",
      "Epoch 18/20\n",
      "1879/1879 [==============================] - 9s 5ms/step - loss: 0.5616 - accuracy: 0.8048\n",
      "Epoch 19/20\n",
      "1879/1879 [==============================] - 9s 5ms/step - loss: 0.5482 - accuracy: 0.8069\n",
      "Epoch 20/20\n",
      "1879/1879 [==============================] - 9s 5ms/step - loss: 0.5386 - accuracy: 0.8111\n",
      "For  20  Epochs:\n",
      "Log-loss for Train Dataset =  0.3020233707411001\n",
      "Log-loss for Test Dataset =  0.7387696343934872\n",
      "Accuracy for Train Dataset =  0.8975685204896221\n",
      "Accuracy for Test Dataset =  0.7592\n",
      "\n",
      "Epoch 1/30\n",
      "1879/1879 [==============================] - 10s 5ms/step - loss: 1.6496 - accuracy: 0.3844\n",
      "Epoch 2/30\n",
      "1879/1879 [==============================] - 9s 5ms/step - loss: 1.2591 - accuracy: 0.5476\n",
      "Epoch 3/30\n",
      "1879/1879 [==============================] - 8s 4ms/step - loss: 1.0954 - accuracy: 0.6102\n",
      "Epoch 4/30\n",
      "1879/1879 [==============================] - 10s 5ms/step - loss: 0.9927 - accuracy: 0.6503\n",
      "Epoch 5/30\n",
      "1879/1879 [==============================] - 8s 4ms/step - loss: 0.9187 - accuracy: 0.6773\n",
      "Epoch 6/30\n",
      "1879/1879 [==============================] - 10s 5ms/step - loss: 0.8610 - accuracy: 0.6985\n",
      "Epoch 7/30\n",
      "1879/1879 [==============================] - 8s 4ms/step - loss: 0.8179 - accuracy: 0.7126\n",
      "Epoch 8/30\n",
      "1879/1879 [==============================] - 8s 4ms/step - loss: 0.7847 - accuracy: 0.7254\n",
      "Epoch 9/30\n",
      "1879/1879 [==============================] - 10s 5ms/step - loss: 0.7511 - accuracy: 0.7367\n",
      "Epoch 10/30\n",
      "1879/1879 [==============================] - 8s 4ms/step - loss: 0.7231 - accuracy: 0.7461\n",
      "Epoch 11/30\n",
      "1879/1879 [==============================] - 8s 4ms/step - loss: 0.6934 - accuracy: 0.7586\n",
      "Epoch 12/30\n",
      "1879/1879 [==============================] - 10s 6ms/step - loss: 0.6644 - accuracy: 0.7669\n",
      "Epoch 13/30\n",
      "1879/1879 [==============================] - 8s 4ms/step - loss: 0.6531 - accuracy: 0.7720\n",
      "Epoch 14/30\n",
      "1879/1879 [==============================] - 8s 5ms/step - loss: 0.6301 - accuracy: 0.7799\n",
      "Epoch 15/30\n",
      "1879/1879 [==============================] - 9s 5ms/step - loss: 0.6124 - accuracy: 0.7847\n",
      "Epoch 16/30\n",
      "1879/1879 [==============================] - 9s 5ms/step - loss: 0.5990 - accuracy: 0.7886\n",
      "Epoch 17/30\n",
      "1879/1879 [==============================] - 9s 5ms/step - loss: 0.5827 - accuracy: 0.7939\n",
      "Epoch 18/30\n",
      "1879/1879 [==============================] - 8s 4ms/step - loss: 0.5702 - accuracy: 0.7997\n",
      "Epoch 19/30\n",
      "1879/1879 [==============================] - 10s 6ms/step - loss: 0.5576 - accuracy: 0.8045\n",
      "Epoch 20/30\n",
      "1879/1879 [==============================] - 8s 4ms/step - loss: 0.5428 - accuracy: 0.8094\n",
      "Epoch 21/30\n",
      "1879/1879 [==============================] - 9s 5ms/step - loss: 0.5299 - accuracy: 0.8143\n",
      "Epoch 22/30\n",
      "1879/1879 [==============================] - 9s 5ms/step - loss: 0.5262 - accuracy: 0.8183\n",
      "Epoch 23/30\n",
      "1879/1879 [==============================] - 8s 4ms/step - loss: 0.5148 - accuracy: 0.8192\n",
      "Epoch 24/30\n",
      "1879/1879 [==============================] - 8s 5ms/step - loss: 0.5022 - accuracy: 0.8218\n",
      "Epoch 25/30\n",
      "1879/1879 [==============================] - 10s 6ms/step - loss: 0.4935 - accuracy: 0.8275\n",
      "Epoch 26/30\n",
      "1879/1879 [==============================] - 9s 5ms/step - loss: 0.4859 - accuracy: 0.8303\n",
      "Epoch 27/30\n",
      "1879/1879 [==============================] - 9s 5ms/step - loss: 0.4768 - accuracy: 0.8321\n",
      "Epoch 28/30\n",
      "1879/1879 [==============================] - 10s 5ms/step - loss: 0.4689 - accuracy: 0.8364\n",
      "Epoch 29/30\n",
      "1879/1879 [==============================] - 9s 5ms/step - loss: 0.4646 - accuracy: 0.8367\n",
      "Epoch 30/30\n",
      "1879/1879 [==============================] - 9s 5ms/step - loss: 0.4612 - accuracy: 0.8394\n",
      "For  30  Epochs:\n",
      "Log-loss for Train Dataset =  0.23218812232959168\n",
      "Log-loss for Test Dataset =  0.7669699033211331\n",
      "Accuracy for Train Dataset =  0.9282197977647685\n",
      "Accuracy for Test Dataset =  0.7579\n",
      "\n",
      "Epoch 1/40\n",
      "1879/1879 [==============================] - 10s 5ms/step - loss: 1.6462 - accuracy: 0.3889\n",
      "Epoch 2/40\n",
      "1879/1879 [==============================] - 9s 5ms/step - loss: 1.2547 - accuracy: 0.5481\n",
      "Epoch 3/40\n",
      "1879/1879 [==============================] - 8s 5ms/step - loss: 1.0783 - accuracy: 0.6161\n",
      "Epoch 4/40\n",
      "1879/1879 [==============================] - 11s 6ms/step - loss: 0.9787 - accuracy: 0.6543\n",
      "Epoch 5/40\n",
      "1879/1879 [==============================] - 8s 4ms/step - loss: 0.8999 - accuracy: 0.6823\n",
      "Epoch 6/40\n",
      "1879/1879 [==============================] - 9s 5ms/step - loss: 0.8495 - accuracy: 0.7017\n",
      "Epoch 7/40\n",
      "1879/1879 [==============================] - 8s 4ms/step - loss: 0.8030 - accuracy: 0.7197\n",
      "Epoch 8/40\n",
      "1879/1879 [==============================] - 11s 6ms/step - loss: 0.7600 - accuracy: 0.7317\n",
      "Epoch 9/40\n",
      "1879/1879 [==============================] - 9s 5ms/step - loss: 0.7337 - accuracy: 0.7420\n",
      "Epoch 10/40\n",
      "1879/1879 [==============================] - 9s 5ms/step - loss: 0.7039 - accuracy: 0.7523\n",
      "Epoch 11/40\n",
      "1879/1879 [==============================] - 9s 5ms/step - loss: 0.6745 - accuracy: 0.7641\n",
      "Epoch 12/40\n",
      "1879/1879 [==============================] - 10s 5ms/step - loss: 0.6480 - accuracy: 0.7718\n",
      "Epoch 13/40\n",
      "1879/1879 [==============================] - 8s 4ms/step - loss: 0.6343 - accuracy: 0.7754\n",
      "Epoch 14/40\n",
      "1879/1879 [==============================] - 8s 4ms/step - loss: 0.6105 - accuracy: 0.7856\n",
      "Epoch 15/40\n",
      "1879/1879 [==============================] - 9s 5ms/step - loss: 0.5966 - accuracy: 0.7900\n",
      "Epoch 16/40\n",
      "1879/1879 [==============================] - 8s 4ms/step - loss: 0.5804 - accuracy: 0.7951\n",
      "Epoch 17/40\n",
      "1879/1879 [==============================] - 11s 6ms/step - loss: 0.5670 - accuracy: 0.8003\n",
      "Epoch 18/40\n",
      "1879/1879 [==============================] - 9s 5ms/step - loss: 0.5557 - accuracy: 0.8046\n",
      "Epoch 19/40\n",
      "1879/1879 [==============================] - 9s 5ms/step - loss: 0.5417 - accuracy: 0.8098\n",
      "Epoch 20/40\n",
      "1879/1879 [==============================] - 9s 5ms/step - loss: 0.5300 - accuracy: 0.8153\n",
      "Epoch 21/40\n",
      "1879/1879 [==============================] - 9s 5ms/step - loss: 0.5194 - accuracy: 0.8184\n",
      "Epoch 22/40\n",
      "1879/1879 [==============================] - 8s 4ms/step - loss: 0.5100 - accuracy: 0.8225\n",
      "Epoch 23/40\n",
      "1879/1879 [==============================] - 8s 4ms/step - loss: 0.5010 - accuracy: 0.8239\n",
      "Epoch 24/40\n",
      "1879/1879 [==============================] - 12s 6ms/step - loss: 0.4980 - accuracy: 0.8254\n",
      "Epoch 25/40\n",
      "1879/1879 [==============================] - 8s 4ms/step - loss: 0.4775 - accuracy: 0.8326\n",
      "Epoch 26/40\n",
      "1879/1879 [==============================] - 8s 5ms/step - loss: 0.4743 - accuracy: 0.8348\n",
      "Epoch 27/40\n",
      "1879/1879 [==============================] - 9s 5ms/step - loss: 0.4714 - accuracy: 0.8363\n",
      "Epoch 28/40\n",
      "1879/1879 [==============================] - 8s 4ms/step - loss: 0.4622 - accuracy: 0.8382\n",
      "Epoch 29/40\n",
      "1879/1879 [==============================] - 8s 4ms/step - loss: 0.4562 - accuracy: 0.8414\n",
      "Epoch 30/40\n",
      "1879/1879 [==============================] - 12s 6ms/step - loss: 0.4501 - accuracy: 0.8439\n",
      "Epoch 31/40\n",
      "1879/1879 [==============================] - 8s 4ms/step - loss: 0.4375 - accuracy: 0.8479\n",
      "Epoch 32/40\n",
      "1879/1879 [==============================] - 8s 4ms/step - loss: 0.4345 - accuracy: 0.8479\n",
      "Epoch 33/40\n",
      "1879/1879 [==============================] - 9s 5ms/step - loss: 0.4331 - accuracy: 0.8508\n",
      "Epoch 34/40\n",
      "1879/1879 [==============================] - 8s 4ms/step - loss: 0.4245 - accuracy: 0.8535\n",
      "Epoch 35/40\n",
      "1879/1879 [==============================] - 8s 4ms/step - loss: 0.4186 - accuracy: 0.8546\n",
      "Epoch 36/40\n",
      "1879/1879 [==============================] - 12s 7ms/step - loss: 0.4121 - accuracy: 0.8568\n",
      "Epoch 37/40\n",
      "1879/1879 [==============================] - 8s 4ms/step - loss: 0.4114 - accuracy: 0.8564\n",
      "Epoch 38/40\n",
      "1879/1879 [==============================] - 8s 4ms/step - loss: 0.4116 - accuracy: 0.8559\n",
      "Epoch 39/40\n",
      "1879/1879 [==============================] - 9s 5ms/step - loss: 0.4042 - accuracy: 0.8604\n",
      "Epoch 40/40\n",
      "1879/1879 [==============================] - 8s 4ms/step - loss: 0.4063 - accuracy: 0.8595\n",
      "For  40  Epochs:\n",
      "Log-loss for Train Dataset =  0.14187289407267917\n",
      "Log-loss for Test Dataset =  0.727615067366647\n",
      "Accuracy for Train Dataset =  0.9611994411921234\n",
      "Accuracy for Test Dataset =  0.7779\n",
      "\n",
      "Epoch 1/50\n",
      "1879/1879 [==============================] - 12s 6ms/step - loss: 1.6474 - accuracy: 0.3867\n",
      "Epoch 2/50\n",
      "1879/1879 [==============================] - 8s 4ms/step - loss: 1.2556 - accuracy: 0.5459\n",
      "Epoch 3/50\n",
      "1879/1879 [==============================] - 8s 5ms/step - loss: 1.0954 - accuracy: 0.6100\n",
      "Epoch 4/50\n",
      "1879/1879 [==============================] - 8s 4ms/step - loss: 0.9941 - accuracy: 0.6494\n",
      "Epoch 5/50\n",
      "1879/1879 [==============================] - 8s 4ms/step - loss: 0.9131 - accuracy: 0.6779\n",
      "Epoch 6/50\n",
      "1879/1879 [==============================] - 8s 4ms/step - loss: 0.8614 - accuracy: 0.6981\n",
      "Epoch 7/50\n",
      "1879/1879 [==============================] - 11s 6ms/step - loss: 0.8161 - accuracy: 0.7139\n",
      "Epoch 8/50\n",
      "1879/1879 [==============================] - 9s 5ms/step - loss: 0.7823 - accuracy: 0.7254\n",
      "Epoch 9/50\n",
      "1879/1879 [==============================] - 8s 4ms/step - loss: 0.7460 - accuracy: 0.7374\n",
      "Epoch 10/50\n",
      "1879/1879 [==============================] - 9s 5ms/step - loss: 0.7149 - accuracy: 0.7495\n",
      "Epoch 11/50\n",
      "1879/1879 [==============================] - 8s 4ms/step - loss: 0.6925 - accuracy: 0.7572\n",
      "Epoch 12/50\n",
      "1879/1879 [==============================] - 8s 4ms/step - loss: 0.6705 - accuracy: 0.7629\n",
      "Epoch 13/50\n",
      "1879/1879 [==============================] - 9s 5ms/step - loss: 0.6447 - accuracy: 0.7730\n",
      "Epoch 14/50\n",
      "1879/1879 [==============================] - 10s 6ms/step - loss: 0.6235 - accuracy: 0.7810\n",
      "Epoch 15/50\n",
      "1879/1879 [==============================] - 9s 5ms/step - loss: 0.6057 - accuracy: 0.7875\n",
      "Epoch 16/50\n",
      "1879/1879 [==============================] - 8s 4ms/step - loss: 0.5932 - accuracy: 0.7930\n",
      "Epoch 17/50\n",
      "1879/1879 [==============================] - 8s 4ms/step - loss: 0.5821 - accuracy: 0.7974\n",
      "Epoch 18/50\n",
      "1879/1879 [==============================] - 8s 4ms/step - loss: 0.5608 - accuracy: 0.8037\n",
      "Epoch 19/50\n",
      "1879/1879 [==============================] - 8s 4ms/step - loss: 0.5508 - accuracy: 0.8084\n",
      "Epoch 20/50\n",
      "1879/1879 [==============================] - 9s 5ms/step - loss: 0.5416 - accuracy: 0.8112\n",
      "Epoch 21/50\n",
      "1879/1879 [==============================] - 10s 5ms/step - loss: 0.5286 - accuracy: 0.8141\n",
      "Epoch 22/50\n",
      "1879/1879 [==============================] - 9s 5ms/step - loss: 0.5169 - accuracy: 0.8194\n",
      "Epoch 23/50\n",
      "1879/1879 [==============================] - 8s 4ms/step - loss: 0.5077 - accuracy: 0.8214\n",
      "Epoch 24/50\n",
      "1879/1879 [==============================] - 8s 4ms/step - loss: 0.4946 - accuracy: 0.8267\n",
      "Epoch 25/50\n",
      "1879/1879 [==============================] - 8s 4ms/step - loss: 0.4895 - accuracy: 0.8308\n",
      "Epoch 26/50\n",
      "1879/1879 [==============================] - 9s 5ms/step - loss: 0.4863 - accuracy: 0.8305\n",
      "Epoch 27/50\n",
      "1879/1879 [==============================] - 10s 5ms/step - loss: 0.4783 - accuracy: 0.8316\n",
      "Epoch 28/50\n",
      "1879/1879 [==============================] - 9s 5ms/step - loss: 0.4606 - accuracy: 0.8397\n",
      "Epoch 29/50\n",
      "1879/1879 [==============================] - 8s 4ms/step - loss: 0.4604 - accuracy: 0.8404\n",
      "Epoch 30/50\n",
      "1879/1879 [==============================] - 8s 4ms/step - loss: 0.4540 - accuracy: 0.8407\n",
      "Epoch 31/50\n",
      "1879/1879 [==============================] - 9s 5ms/step - loss: 0.4426 - accuracy: 0.8469\n",
      "Epoch 32/50\n",
      "1879/1879 [==============================] - 8s 4ms/step - loss: 0.4402 - accuracy: 0.8475\n",
      "Epoch 33/50\n",
      "1879/1879 [==============================] - 10s 5ms/step - loss: 0.4342 - accuracy: 0.8482\n",
      "Epoch 34/50\n",
      "1879/1879 [==============================] - 11s 6ms/step - loss: 0.4237 - accuracy: 0.8525\n",
      "Epoch 35/50\n",
      "1879/1879 [==============================] - 8s 4ms/step - loss: 0.4222 - accuracy: 0.8537\n",
      "Epoch 36/50\n",
      "1879/1879 [==============================] - 8s 5ms/step - loss: 0.4127 - accuracy: 0.8565\n",
      "Epoch 37/50\n",
      "1879/1879 [==============================] - 9s 5ms/step - loss: 0.4153 - accuracy: 0.8557\n",
      "Epoch 38/50\n",
      "1879/1879 [==============================] - 9s 5ms/step - loss: 0.4112 - accuracy: 0.8569\n",
      "Epoch 39/50\n",
      "1879/1879 [==============================] - 9s 5ms/step - loss: 0.4016 - accuracy: 0.8596\n",
      "Epoch 40/50\n",
      "1879/1879 [==============================] - 9s 5ms/step - loss: 0.4007 - accuracy: 0.8611\n",
      "Epoch 41/50\n",
      "1879/1879 [==============================] - 8s 4ms/step - loss: 0.3945 - accuracy: 0.8636\n",
      "Epoch 42/50\n",
      "1879/1879 [==============================] - 8s 4ms/step - loss: 0.3960 - accuracy: 0.8631\n",
      "Epoch 43/50\n",
      "1879/1879 [==============================] - 9s 5ms/step - loss: 0.3923 - accuracy: 0.8644\n",
      "Epoch 44/50\n",
      "1879/1879 [==============================] - 8s 4ms/step - loss: 0.3881 - accuracy: 0.8644\n",
      "Epoch 45/50\n",
      "1879/1879 [==============================] - 8s 4ms/step - loss: 0.3862 - accuracy: 0.8659\n",
      "Epoch 46/50\n",
      "1879/1879 [==============================] - 12s 6ms/step - loss: 0.3776 - accuracy: 0.8690\n",
      "Epoch 47/50\n",
      "1879/1879 [==============================] - 9s 5ms/step - loss: 0.3734 - accuracy: 0.8683\n",
      "Epoch 48/50\n",
      "1879/1879 [==============================] - 8s 4ms/step - loss: 0.3696 - accuracy: 0.8725\n",
      "Epoch 49/50\n",
      "1879/1879 [==============================] - 9s 5ms/step - loss: 0.3698 - accuracy: 0.8737\n",
      "Epoch 50/50\n",
      "1879/1879 [==============================] - 9s 5ms/step - loss: 0.3679 - accuracy: 0.8736\n",
      "For  50  Epochs:\n",
      "Log-loss for Train Dataset =  0.1188438345150888\n",
      "Log-loss for Test Dataset =  0.7735144163994173\n",
      "Accuracy for Train Dataset =  0.966953831825439\n",
      "Accuracy for Test Dataset =  0.7674\n",
      "\n",
      "Epoch 1/40\n",
      "1879/1879 [==============================] - 9s 5ms/step - loss: 1.6693 - accuracy: 0.3743\n",
      "Epoch 2/40\n",
      "1879/1879 [==============================] - 8s 4ms/step - loss: 1.2880 - accuracy: 0.5323\n",
      "Epoch 3/40\n",
      "1879/1879 [==============================] - 8s 4ms/step - loss: 1.1013 - accuracy: 0.6064\n",
      "Epoch 4/40\n",
      "1879/1879 [==============================] - 8s 4ms/step - loss: 0.9853 - accuracy: 0.6536\n",
      "Epoch 5/40\n",
      "1879/1879 [==============================] - 9s 5ms/step - loss: 0.9087 - accuracy: 0.6818\n",
      "Epoch 6/40\n",
      "1879/1879 [==============================] - 8s 4ms/step - loss: 0.8524 - accuracy: 0.7018\n",
      "Epoch 7/40\n",
      "1879/1879 [==============================] - 9s 5ms/step - loss: 0.8058 - accuracy: 0.7175\n",
      "Epoch 8/40\n",
      "1879/1879 [==============================] - 12s 7ms/step - loss: 0.7733 - accuracy: 0.7301\n",
      "Epoch 9/40\n",
      "1879/1879 [==============================] - 8s 4ms/step - loss: 0.7366 - accuracy: 0.7427\n",
      "Epoch 10/40\n",
      "1879/1879 [==============================] - 9s 5ms/step - loss: 0.7040 - accuracy: 0.7540\n",
      "Epoch 11/40\n",
      "1879/1879 [==============================] - 8s 4ms/step - loss: 0.6860 - accuracy: 0.7594\n",
      "Epoch 12/40\n",
      "1879/1879 [==============================] - 9s 5ms/step - loss: 0.6573 - accuracy: 0.7697\n",
      "Epoch 13/40\n",
      "1879/1879 [==============================] - 8s 5ms/step - loss: 0.6381 - accuracy: 0.7777\n",
      "Epoch 14/40\n",
      "1879/1879 [==============================] - 9s 5ms/step - loss: 0.6219 - accuracy: 0.7838\n",
      "Epoch 15/40\n",
      "1879/1879 [==============================] - 8s 4ms/step - loss: 0.6048 - accuracy: 0.7889\n",
      "Epoch 16/40\n",
      "1879/1879 [==============================] - 9s 5ms/step - loss: 0.5864 - accuracy: 0.7955\n",
      "Epoch 17/40\n",
      "1879/1879 [==============================] - 9s 5ms/step - loss: 0.5761 - accuracy: 0.7988\n",
      "Epoch 18/40\n",
      "1879/1879 [==============================] - 9s 5ms/step - loss: 0.5654 - accuracy: 0.8009\n",
      "Epoch 19/40\n",
      "1879/1879 [==============================] - 8s 4ms/step - loss: 0.5493 - accuracy: 0.8089\n",
      "Epoch 20/40\n",
      "1879/1879 [==============================] - 10s 6ms/step - loss: 0.5381 - accuracy: 0.8116\n",
      "Epoch 21/40\n",
      "1879/1879 [==============================] - 12s 6ms/step - loss: 0.5269 - accuracy: 0.8163\n",
      "Epoch 22/40\n",
      "1879/1879 [==============================] - 9s 5ms/step - loss: 0.5167 - accuracy: 0.8193\n",
      "Epoch 23/40\n",
      "1879/1879 [==============================] - 9s 5ms/step - loss: 0.5115 - accuracy: 0.8230\n",
      "Epoch 24/40\n",
      "1879/1879 [==============================] - 8s 4ms/step - loss: 0.4974 - accuracy: 0.8268\n",
      "Epoch 25/40\n",
      "1879/1879 [==============================] - 8s 4ms/step - loss: 0.4913 - accuracy: 0.8289\n",
      "Epoch 26/40\n",
      "1879/1879 [==============================] - 9s 5ms/step - loss: 0.4831 - accuracy: 0.8316\n",
      "Epoch 27/40\n",
      "1879/1879 [==============================] - 9s 5ms/step - loss: 0.4750 - accuracy: 0.8348\n",
      "Epoch 28/40\n",
      "1879/1879 [==============================] - 9s 5ms/step - loss: 0.4720 - accuracy: 0.8364\n",
      "Epoch 29/40\n",
      "1879/1879 [==============================] - 8s 4ms/step - loss: 0.4597 - accuracy: 0.8404\n",
      "Epoch 30/40\n",
      "1879/1879 [==============================] - 9s 5ms/step - loss: 0.4579 - accuracy: 0.8405\n",
      "Epoch 31/40\n",
      "1879/1879 [==============================] - 8s 4ms/step - loss: 0.4451 - accuracy: 0.8447\n",
      "Epoch 32/40\n",
      "1879/1879 [==============================] - 8s 4ms/step - loss: 0.4465 - accuracy: 0.8435\n",
      "Epoch 33/40\n",
      "1879/1879 [==============================] - 9s 5ms/step - loss: 0.4386 - accuracy: 0.8472\n",
      "Epoch 34/40\n",
      "1879/1879 [==============================] - 11s 6ms/step - loss: 0.4310 - accuracy: 0.8502\n",
      "Epoch 35/40\n",
      "1879/1879 [==============================] - 12s 6ms/step - loss: 0.4209 - accuracy: 0.8540\n",
      "Epoch 36/40\n",
      "1879/1879 [==============================] - 9s 5ms/step - loss: 0.4170 - accuracy: 0.8551\n",
      "Epoch 37/40\n",
      "1879/1879 [==============================] - 8s 4ms/step - loss: 0.4154 - accuracy: 0.8548\n",
      "Epoch 38/40\n",
      "1879/1879 [==============================] - 8s 4ms/step - loss: 0.4158 - accuracy: 0.8554\n",
      "Epoch 39/40\n",
      "1879/1879 [==============================] - 9s 5ms/step - loss: 0.4104 - accuracy: 0.8575\n",
      "Epoch 40/40\n",
      "1879/1879 [==============================] - 8s 4ms/step - loss: 0.4066 - accuracy: 0.8596\n"
     ]
    }
   ],
   "source": [
    "# If the model has been pre-trained\n",
    "try:\n",
    "    conv_model = cnn_model((32, 32, 3))\n",
    "    conv_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics='accuracy')\n",
    "    conv_model.load_weights(\"../input/dcai-rw/hybrid_trad_gan_augmented.h5\")\n",
    "\n",
    "# If the model hasn't been pre-trained\n",
    "except:\n",
    "    num_epochs = [10, 20, 30, 40, 50]\n",
    "    train_loss, test_loss, train_acc, test_acc = [], [], [], []\n",
    "\n",
    "    for epochs in num_epochs:\n",
    "        # Training the Model\n",
    "        conv_model = cnn_model((32, 32, 3))\n",
    "        conv_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics='accuracy')\n",
    "        conv_model.fit(train_dataset, epochs = epochs)\n",
    "\n",
    "        # Predicting on the Train/Test Datasets\n",
    "        preds_train = conv_model.predict(df_aug)\n",
    "        preds_test = conv_model.predict(df_test)\n",
    "\n",
    "        # Finding the Predicted Classes\n",
    "        cls_train = np.argmax(preds_train, axis = 1)\n",
    "        cls_test = np.argmax(preds_test, axis = 1)\n",
    "\n",
    "        # Finding the Train/Test set Loss\n",
    "        train_loss.append(log_loss(y_aug_oh, preds_train))\n",
    "        test_loss.append(log_loss(y_test_oh, preds_test))\n",
    "        train_acc.append(accuracy_score(y_aug, cls_train))\n",
    "        test_acc.append(accuracy_score(y_test, cls_test))\n",
    "\n",
    "        print(\"For \", epochs, \" Epochs:\")\n",
    "        print(\"Log-loss for Train Dataset = \", train_loss[-1])\n",
    "        print(\"Log-loss for Test Dataset = \", test_loss[-1])\n",
    "        print(\"Accuracy for Train Dataset = \", train_acc[-1])\n",
    "        print(\"Accuracy for Test Dataset = \", test_acc[-1])\n",
    "        print()\n",
    "        \n",
    "    # Training the Model with the best hyper-parameter settings\n",
    "    ind = np.argmax(test_acc)\n",
    "    best_num_epochs = num_epochs[ind]\n",
    "    conv_model = cnn_model((32, 32, 3))\n",
    "    conv_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics='accuracy')\n",
    "    conv_model.fit(train_dataset, epochs = best_num_epochs)\n",
    "\n",
    "    # Saving the model along with it's weights\n",
    "    conv_model.save('hybrid_trad_gan_augmented.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0daf3ee",
   "metadata": {
    "papermill": {
     "duration": 10.592351,
     "end_time": "2022-05-10T11:13:23.805164",
     "exception": false,
     "start_time": "2022-05-10T11:13:13.212813",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 4.2. Predicting the Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6f1579c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-10T11:13:45.243371Z",
     "iopub.status.busy": "2022-05-10T11:13:45.242264Z",
     "iopub.status.idle": "2022-05-10T11:13:51.086338Z",
     "shell.execute_reply": "2022-05-10T11:13:51.085664Z"
    },
    "papermill": {
     "duration": 16.244874,
     "end_time": "2022-05-10T11:13:51.086508",
     "exception": false,
     "start_time": "2022-05-10T11:13:34.841634",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log-loss for Augmented Dataset =  0.17044280393337208\n",
      "Log-loss for Test Dataset =  0.7709342780244012\n",
      "Weighted F1 Score for Augmented Dataset =  0.9476430446272331\n",
      "Weighted F1 Score for Test Dataset =  0.76664537228173\n",
      "Accuracy for Augmented Dataset =  0.9477780734433209\n",
      "Accuracy for Test Dataset =  0.7698\n"
     ]
    }
   ],
   "source": [
    "# Predicting on the Train/Test Datasets\n",
    "preds_train = conv_model.predict(df_aug)\n",
    "preds_test = conv_model.predict(df_test)\n",
    "\n",
    "# Finding the Predicted Classes\n",
    "cls_train = np.argmax(preds_train, axis = 1)\n",
    "cls_test = np.argmax(preds_test, axis = 1)\n",
    "\n",
    "# Finding the Train/Test set Loss\n",
    "print(\"Log-loss for Augmented Dataset = \", log_loss(y_aug_oh, preds_train))\n",
    "print(\"Log-loss for Test Dataset = \", log_loss(y_test_oh, preds_test))\n",
    "print(\"Weighted F1 Score for Augmented Dataset = \", f1_score(y_aug, cls_train, average = 'weighted'))\n",
    "print(\"Weighted F1 Score for Test Dataset = \", f1_score(y_test, cls_test, average = 'weighted'))\n",
    "print(\"Accuracy for Augmented Dataset = \", accuracy_score(y_aug, cls_train))\n",
    "print(\"Accuracy for Test Dataset = \", accuracy_score(y_test, cls_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2228.751868,
   "end_time": "2022-05-10T11:14:05.293949",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-05-10T10:36:56.542081",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
