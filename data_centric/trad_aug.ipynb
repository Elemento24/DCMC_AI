{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Traditional Augmentation\n- In this notebook, we will be applying a data-centric approach on our baseline model. We will be using Traditional Augmentation techniques, such as Center Crop, Rotate, Color Shift, Flip, etc in this kernel.\n- We will be applying these techniques in 3 different ways. Firstly, we will apply these techniques on 25% of the samples from the training dataset irrespective of their classes, and then observe the accuracy of the baseline model after training it on the augmented dataset.\n- Secondly, we will be using these techniques for class balancing, and then, will train the baseline model on the balanced dataset.\n- Thirdly, we will be analysing the class-wise performance of the baseline model, and will apply augmentation on only those classes on which the baseline model is not performing well.","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"markdown","source":"# 1. Importing the Packages & Boilerplate Code","metadata":{}},{"cell_type":"code","source":"import os\nimport sys\nimport random\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom tqdm import tqdm\nfrom shutil import copyfile\nfrom tabulate import tabulate\nfrom sklearn.metrics import accuracy_score, log_loss, confusion_matrix\n\n# https://www.kaggle.com/c/ventilator-pressure-prediction/discussion/274717\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n\nimport tensorflow as tf\nimport tensorflow.keras.layers as tfl","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Setting the seeds\nSEED = 0\nos.environ['PYTHONHASHSEED']=str(SEED)\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntf.random.set_seed(SEED)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Making sure that Tensorflow is able to detect the GPU\ndevice_name = tf.test.gpu_device_name()\nif \"GPU\" not in device_name:\n    print(\"GPU device not found\")\nprint('Found GPU at: {}'.format(device_name))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# These are the usual ipython objects\nipython_vars = ['In', 'Out', 'exit', 'quit', 'get_ipython', 'ipython_vars']\n\n# Defining a function to list the memory consumed\n# Only outputs variables taking at least 1MB space\ndef list_storage(inp_dir):\n    # Get a sorted list of the objects and their sizes\n    vars_defined = [x for x in inp_dir if not x.startswith('_') and x not in sys.modules and x not in ipython_vars]\n    sto = sorted([(x, sys.getsizeof(globals().get(x))) for x in vars_defined], key=lambda x: x[1], reverse=True)\n    sto = [(x[0], str(round((x[1] / 2**20), 2)) + ' MB') for x in sto if x[1] >= 2**20]\n    print(tabulate(sto, headers = ['Variable', 'Storage (in MB)']))\n\n# In order to use this function, use the below line of code\n# list_storage(dir())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Importing the Train/Test Sets","metadata":{}},{"cell_type":"code","source":"# Importing the Labelled Dataset\ndf_train = pd.read_csv(\"../input/cifar10/train_lab_x.csv\")\ny_train = pd.read_csv(\"../input/cifar10/train_lab_y.csv\")\ndf_train = np.array(df_train)\ny_train = np.array(y_train)\nprint(df_train.shape, y_train.shape)\n\n# Reshaping the dataset\ndf_train = np.reshape(df_train, (-1, 3, 32, 32))\nprint(df_train.shape)\n\n# Basic Pre-processing\n# Creating a random permutation\nperm = np.random.permutation(df_train.shape[0])\n\n# Shuffling the training dataset\ndf_train = df_train[perm, : , : , : ]\ny_train = y_train[perm]\n\n# Reshaping, rescaling and one-hot encoding\ndf_train = np.transpose(np.array(df_train), (0, 2, 3, 1))\ndf_train = df_train / 255\ny_train_oh = tf.one_hot(np.ravel(y_train), depth = 10)\nprint(df_train.shape, y_train_oh.shape)\n\n# Importing the Test Dataset\ndf_test = pd.read_csv(\"../input/cifar10/test_x.csv\")\ny_test = pd.read_csv(\"../input/cifar10/test_y.csv\")\ndf_test = np.array(df_test)\ny_test = np.array(y_test)\nprint(df_test.shape, y_test.shape)\n\n# Reshaping the dataset\ndf_test = np.reshape(df_test, (-1, 3, 32, 32))\nprint(df_test.shape)\n\n# Reshaping, rescaling and one-hot encoding\ndf_test = np.transpose(np.array(df_test), (0, 2, 3, 1))\ndf_test = df_test / 255\ny_test_oh = tf.one_hot(np.ravel(y_test), depth = 10)\nprint(df_test.shape, y_test_oh.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. Defining the Tensorflow Augmentations","metadata":{}},{"cell_type":"code","source":"data_augmentation = tf.keras.Sequential([\n    tfl.RandomFlip(\"horizontal_and_vertical\"),\n    tfl.RandomRotation(0.2),\n])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. Image Augmentation on 25% of the Training Dataset\n## 4.1. Augmenting the Training Dataset","metadata":{}},{"cell_type":"code","source":"# Visualizing a single image\nind = 16\nexample = df_train[ind, : , : , : ]\nprint(example.shape)\n\n# Add the image to a batch.\nimage = tf.cast(tf.expand_dims(example, 0), tf.float32)\nprint(image.shape)\n\nplt.figure(figsize=(5, 5))\nfor i in range(9):\n    aug_image = data_augmentation(image)\n    ax = plt.subplot(3, 3, i + 1)\n    plt.imshow(aug_image[0])\n    plt.axis(\"off\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating an empty list\ndf_train_aug, y_train_aug = [], []\n\n# Iterating over all the images in the dataset\nfor ind in tqdm(range(df_train.shape[0])):\n    if np.random.uniform() <= 0.25:\n        aug_image = data_augmentation(df_train[ind, : , : , : ])\n        df_train_aug.append(aug_image)\n        y_train_aug.append(y_train[ind])\n\n# Sanity Checks and Transformations\ndf_train_aug = np.array(df_train_aug)\ny_train_aug = np.reshape(np.array(y_train_aug), (-1, 1))\ny_train_aug_oh = tf.one_hot(np.ravel(y_train_aug), depth = 10)\nprint(df_train_aug.shape, y_train_aug.shape, y_train_aug_oh.shape)\n\ndf_aug = np.concatenate([df_train, df_train_aug], axis = 0)\ny_aug = np.concatenate([y_train, y_train_aug], axis = 0)\ny_aug_oh = np.concatenate([y_train_oh, y_train_aug_oh], axis = 0)\nprint(df_aug.shape, y_aug.shape, y_aug_oh.shape)\n\n# Creating a random permutation\nperm_aug = np.random.permutation(df_aug.shape[0])\n\n# Shuffling the augmented dataset\ndf_aug = df_aug[perm_aug, : , : , : ]\ny_aug = y_aug[perm_aug]\ny_aug_oh = y_aug_oh[perm_aug, : ]\nprint(df_aug.shape, y_aug.shape, y_aug_oh.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4.2. Training the Baseline Model on the Augmented Dataset","metadata":{}},{"cell_type":"code","source":"# Importing the Baseline Model Architecture\ncopyfile(src = \"../input/dcai-rw/baseline_arch.py\", dst = \"../working/baseline_arch.py\")\nfrom baseline_arch import cnn_model\n\nconv_model = cnn_model((32, 32, 3))\nconv_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics='accuracy')\n\n# Creating Batches from the Augmented Dataset\naug_dataset = tf.data.Dataset.from_tensor_slices((df_train, y_train_oh)).batch(32)\nhistory = conv_model.fit(aug_dataset, epochs = 25)\n\n# Saving the model along with it's weights\nconv_model.save('baseline_augmented_all.h5')","metadata":{"scrolled":true,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4.3. Predicting the Performance","metadata":{}},{"cell_type":"code","source":"# Predicting on the Train/Test Datasets\npreds_train = conv_model.predict(df_train)\npreds_test = conv_model.predict(df_test)\n\n# Finding the Predicted Classes\ncls_train = np.argmax(preds_train, axis = 1)\ncls_test = np.argmax(preds_test, axis = 1)\n\n# Finding the Train/Test set Loss\nprint(\"Log-loss for Train Dataset = \", log_loss(y_train_oh, preds_train))\nprint(\"Log-loss for Test Dataset = \", log_loss(y_test_oh, preds_test))\nprint(\"Accuracy for Train Dataset = \", accuracy_score(y_train, cls_train))\nprint(\"Accuracy for Test Dataset = \", accuracy_score(y_test, cls_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- From the above analysis, we can observe that Traditional Augmentation on 25% of the Training Dataset doesn't help at all. Instead, if we compare the scores with those of the baseline model, we will find them lagging a bit. \n- Let's try to balance the dataset with the help of Traditional Augmentation Techniques, and see if it gets us any better results.\n\n# 5. Image Augmentation for Class Balancing\n## 5.1. Finding out the Class Imbalance","metadata":{}},{"cell_type":"code","source":"y_train_reshape = np.reshape(y_train, (-1))\nnum_examples = np.zeros((10,))\n\nfor i in y_train_reshape:\n    num_examples[i] += 1\n\n# Number of examples from each class\nnum_exa = num_examples.astype('int32')\n\n# Finding out the maximum number of examples for any class\nmax_exa = max(num_exa)\n\n# Number of examples that needs to be added to each of the classes\naug_exa = [max_exa - num_exa[i] for i in range(10)]\n\n# Creating a list of lists for storing the indices of data-points in the training dataset, class-wise\nclasses_ind = []\nfor i in range(10):\n    classes_ind.append([])\n\nfor ind, clss in enumerate(y_train_reshape):\n    classes_ind[clss].append(ind)\n\n# # Transforming list of lists into numpy array\n# classes_ind = np.array([np.array(xi) for xi in classes_ind])\n\nprint(num_exa)\nprint(aug_exa, sum(aug_exa))\nprint(len(classes_ind), len(classes_ind[0]))\n\n# Creating a list for indices of images and their labels on which augmentation needs to be done\n# These are randomly chosen from each class\naug_ind = []\ny_train_aug = []\n\nfor i in range(10):\n    indices = random.choices(classes_ind[i], k = aug_exa[i])\n    aug_ind.extend(indices)\n    y_train_aug.extend([i]*aug_exa[i])\n\nprint(len(aug_ind), len(y_train_aug))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5.2. Augmenting based on the Class Imbalance","metadata":{}},{"cell_type":"code","source":"# Creating an empty list\ndf_train_aug = []\n\nfor ind in tqdm(aug_ind):\n    aug_image = data_augmentation(df_train[ind, : , : , : ])\n    df_train_aug.append(aug_image)\n    \n# Sanity Checks and Transformations\ndf_train_aug = np.array(df_train_aug)\ny_train_aug = np.reshape(np.array(y_train_aug), (-1, 1))\ny_train_aug_oh = tf.one_hot(np.ravel(y_train_aug), depth = 10)\nprint(df_train_aug.shape, y_train_aug.shape, y_train_aug_oh.shape)\n\ndf_aug = np.concatenate([df_train, df_train_aug], axis = 0)\ny_aug = np.concatenate([y_train, y_train_aug], axis = 0)\ny_aug_oh = np.concatenate([y_train_oh, y_train_aug_oh], axis = 0)\nprint(df_aug.shape, y_aug.shape, y_aug_oh.shape)\n\n# Creating a random permutation\nperm_aug = np.random.permutation(df_aug.shape[0])\n\n# Shuffling the augmented dataset\ndf_aug = df_aug[perm_aug, : , : , : ]\ny_aug = y_aug[perm_aug]\ny_aug_oh = y_aug_oh[perm_aug, : ]\nprint(df_aug.shape, y_aug.shape, y_aug_oh.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Finding out the number of examples in each class after augmentation\nnum_examples = np.zeros((10,))\nfor i in y_aug[:]:\n    num_examples[i[0]] += 1\nprint(num_examples)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5.3. Training the Baseline Model on the Augmented Dataset","metadata":{}},{"cell_type":"code","source":"# Importing the Baseline Model Architecture\ncopyfile(src = \"../input/dcai-rw/baseline_arch.py\", dst = \"../working/baseline_arch.py\")\nfrom baseline_arch import cnn_model\n\nconv_model = cnn_model((32, 32, 3))\nconv_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics='accuracy')\n\n# Creating Batches from the Augmented Dataset\naug_dataset = tf.data.Dataset.from_tensor_slices((df_train, y_train_oh)).batch(32)\nhistory = conv_model.fit(aug_dataset, epochs = 25)\n\n# Saving the model along with it's weights\nconv_model.save('baseline_augmented_cls_imbalance.h5')","metadata":{"_kg_hide-output":true,"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5.4. Predicting the Performance","metadata":{}},{"cell_type":"code","source":"# Predicting on the Train/Test Datasets\npreds_train = conv_model.predict(df_train)\npreds_test = conv_model.predict(df_test)\n\n# Finding the Predicted Classes\ncls_train = np.argmax(preds_train, axis = 1)\ncls_test = np.argmax(preds_test, axis = 1)\n\n# Finding the Train/Test set Loss\nprint(\"Log-loss for Train Dataset = \", log_loss(y_train_oh, preds_train))\nprint(\"Log-loss for Test Dataset = \", log_loss(y_test_oh, preds_test))\nprint(\"Accuracy for Train Dataset = \", accuracy_score(y_train, cls_train))\nprint(\"Accuracy for Test Dataset = \", accuracy_score(y_test, cls_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- From the above analysis, we can observe that Traditional Augmentation for Class Balancing doesn't help at all too, and if we compare the scores with those of the baseline model, we will find them lagging a bit. \n- Now, let's try to analyze the performance of the original baseline model on the non-augmented training set and test set, and depending on it's class-wise performance, we will perform augmentation on selected classes only. \n\n# 6. Image Augmentation based on Class-wise Performance\n## 6.1. Finding out the Class-wise Performance of the Baseline Model","metadata":{}},{"cell_type":"code","source":"# Importing the Baseline Model\nconv_model = tf.keras.models.load_model(\"../input/dcai-rw/baseline_model.h5\")\n\n# Predicting on the Test Datasets\npreds_test = conv_model.predict(df_test)\n\n# Finding the Predicted Classes\ncls_test = np.argmax(preds_test, axis = 1)\n\n# Finding the Test set Loss\nprint(\"Log-loss for Test Dataset = \", log_loss(y_test_oh, preds_test))\nprint(\"Accuracy for Test Dataset = \", accuracy_score(y_test, cls_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating a list of lists for storing the class-wise indices of the Test Dataset\nindices = []\nfor _ in range(10):\n    indices.append([])\nfor ind, y in enumerate(y_test):\n    indices[y[0]].append(ind)\n\n# Creating list of lists values\ny_test_cls = []\ny_test_oh_cls = []\npreds_test_cls = []\ncls_test_cls = []\n\nfor _ in range(10):\n    y_test_cls.append([])\n    y_test_oh_cls.append([])\n    preds_test_cls.append([])\n    cls_test_cls.append([])\n\nfor ind, y in enumerate(y_test):\n    label = y[0]\n    y_test_cls[label].append(y_test[ind])\n    y_test_oh_cls[label].append(y_test_oh[ind])\n    preds_test_cls[label].append(preds_test[ind])\n    cls_test_cls[label].append(cls_test[ind])\n\n# Sanity Checks\nprint(len(y_test_cls), len(y_test_oh_cls), len(preds_test_cls), len(cls_test_cls))\nprint(len(y_test_cls[4]), len(y_test_oh_cls[3]), len(preds_test_cls[2]), len(cls_test_cls[1]))\nprint(len(y_test_oh_cls[3][42]), len(y_test_oh_cls[5][49]))\nprint()\n\n# Finding the Class-Wise Log-loss and Accuracy on the Test Set\nfor i in range(10):\n    print('For Class ', i)\n    print(\"Log-loss = \", log_loss(y_test_oh_cls[i], preds_test_cls[i]))\n    print(\"Accuracy = \", accuracy_score(y_test_cls[i], cls_test_cls[i]))\n    print()","metadata":{"scrolled":true,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 6.2. Augmenting the Train Dataset","metadata":{}},{"cell_type":"code","source":"# Creating a list of lists for storing the indices of data-points in the training dataset, class-wise\nclasses_ind = []\ny_train_reshape = np.reshape(y_train, (-1))\nfor i in range(10):\n    classes_ind.append([])\nfor ind, clss in enumerate(y_train_reshape):\n    classes_ind[clss].append(ind)\n    \n# Creating a list for indices of images and their labels on which augmentation needs to be done\n# These are randomly chosen from each of the underperforming classes\naug_ind = []\ny_train_aug = []\n\n# As for the under-performing classes, we will simply be choosing those classes having accuracy\n# less than 80%\nund_cls = [2, 3, 4, 5]\n\n# Creating an empty list\ndf_train_aug, y_train_aug = [], []\n\n# 50% Sampling\nfor clas in und_cls:\n    for ind in tqdm(classes_ind[clas]):\n        if np.random.uniform() <= 0.5:\n            aug_image = data_augmentation(df_train[ind, : , : , : ])\n            df_train_aug.append(aug_image)\n            y_train_aug.append(y_train[ind])\n\n# Sanity Checks and Transformations\ndf_train_aug = np.array(df_train_aug)\ny_train_aug = np.reshape(np.array(y_train_aug), (-1, 1))\ny_train_aug_oh = tf.one_hot(np.ravel(y_train_aug), depth = 10)\nprint(df_train_aug.shape, y_train_aug.shape, y_train_aug_oh.shape)\n\ndf_aug = np.concatenate([df_train, df_train_aug], axis = 0)\ny_aug = np.concatenate([y_train, y_train_aug], axis = 0)\ny_aug_oh = np.concatenate([y_train_oh, y_train_aug_oh], axis = 0)\nprint(df_aug.shape, y_aug.shape, y_aug_oh.shape)\n\n# Creating a random permutation\nperm_aug = np.random.permutation(df_aug.shape[0])\n\n# Shuffling the augmented dataset\ndf_aug = df_aug[perm_aug, : , : , : ]\ny_aug = y_aug[perm_aug]\ny_aug_oh = y_aug_oh[perm_aug, : ]\nprint(df_aug.shape, y_aug.shape, y_aug_oh.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 6.3. Training the Baseline Model on the Augmented Dataset","metadata":{}},{"cell_type":"code","source":"# Importing the Baseline Model Architecture\ncopyfile(src = \"../input/dcai-rw/baseline_arch.py\", dst = \"../working/baseline_arch.py\")\nfrom baseline_arch import cnn_model\n\nconv_model = cnn_model((32, 32, 3))\nconv_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics='accuracy')\n\n# Creating Batches from the Augmented Dataset\naug_dataset = tf.data.Dataset.from_tensor_slices((df_train, y_train_oh)).batch(32)\nhistory = conv_model.fit(aug_dataset, epochs = 25)\n\n# Saving the model along with it's weights\nconv_model.save('baseline_augmented_cls_performance_wise.h5')","metadata":{"_kg_hide-output":true,"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 6.4. Predicting the Performance","metadata":{}},{"cell_type":"code","source":"# Predicting on the Train/Test Datasets\npreds_train = conv_model.predict(df_train)\npreds_test = conv_model.predict(df_test)\n\n# Finding the Predicted Classes\ncls_train = np.argmax(preds_train, axis = 1)\ncls_test = np.argmax(preds_test, axis = 1)\n\n# Finding the Train/Test set Loss\nprint(\"Log-loss for Train Dataset = \", log_loss(y_train_oh, preds_train))\nprint(\"Log-loss for Test Dataset = \", log_loss(y_test_oh, preds_test))\nprint(\"Accuracy for Train Dataset = \", accuracy_score(y_train, cls_train))\nprint(\"Accuracy for Test Dataset = \", accuracy_score(y_test, cls_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- From the above analysis, we can observe that Traditional Augmentation based on class-wise performance doesn't help at all too, and if we compare the scores with those of the baseline model, we will find them lagging a bit. ","metadata":{}}]}