{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a0734c2",
   "metadata": {
    "papermill": {
     "duration": 0.019087,
     "end_time": "2022-06-06T15:11:44.504810",
     "exception": false,
     "start_time": "2022-06-06T15:11:44.485723",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# AutoAugment: Learning Augmentation Policies from Data\n",
    "* AutoAugment is used to automatically search for improved data augmentation policies.\n",
    "* A search algorithm is used to find the best policy such that the neural network yields the highest validation accuracy on a target dataset.\n",
    "* AutoAugment policy is applied on the CIFAR10 in addition to the baseline for training.\n",
    "* The operations we searched over are **ShearX/Y, TranslateX/Y, Rotate, AutoContrast, Invert, Equalize, Solarize, Posterize, Contrast, Color, Brightness, Sharpness, Cutout and Sample Pairing**.\n",
    "\n",
    "#### [Reference of the paper](https://arxiv.org/abs/1805.09501)\n",
    "\n",
    "# Installing Packages and Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59eda1c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-06T15:11:44.542563Z",
     "iopub.status.busy": "2022-06-06T15:11:44.541982Z",
     "iopub.status.idle": "2022-06-06T15:11:50.854281Z",
     "shell.execute_reply": "2022-06-06T15:11:50.853518Z"
    },
    "papermill": {
     "duration": 6.333862,
     "end_time": "2022-06-06T15:11:50.856822",
     "exception": false,
     "start_time": "2022-06-06T15:11:44.522960",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from PIL import Image, ImageEnhance, ImageOps\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import random\n",
    "import pdb\n",
    "\n",
    "# import utlis\n",
    "# from autoaugment import CIFAR10Policy\n",
    "\n",
    "import os\n",
    "from os import listdir\n",
    "import sys\n",
    "import argparse\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from tabulate import tabulate\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import scipy\n",
    "from scipy import ndimage\n",
    "\n",
    "import tensorflow.keras.layers as tfl\n",
    "from tabulate import tabulate\n",
    "from shutil import copyfile\n",
    "from sklearn.metrics import accuracy_score, log_loss, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82d58497",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-06T15:11:50.892970Z",
     "iopub.status.busy": "2022-06-06T15:11:50.892751Z",
     "iopub.status.idle": "2022-06-06T15:11:50.945633Z",
     "shell.execute_reply": "2022-06-06T15:11:50.944817Z"
    },
    "papermill": {
     "duration": 0.073698,
     "end_time": "2022-06-06T15:11:50.948258",
     "exception": false,
     "start_time": "2022-06-06T15:11:50.874560",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Pillow version 9.0.1. Upgrade using 'pip install Pillow -U'\n"
     ]
    }
   ],
   "source": [
    "import PIL\n",
    "print(\"Using Pillow version {}. Upgrade using 'pip install Pillow -U'\".format(PIL.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4fff14b",
   "metadata": {
    "papermill": {
     "duration": 0.017617,
     "end_time": "2022-06-06T15:11:50.985084",
     "exception": false,
     "start_time": "2022-06-06T15:11:50.967467",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Basic Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5ee5405",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2022-06-06T15:11:51.022592Z",
     "iopub.status.busy": "2022-06-06T15:11:51.022037Z",
     "iopub.status.idle": "2022-06-06T15:11:53.432378Z",
     "shell.execute_reply": "2022-06-06T15:11:53.431411Z"
    },
    "papermill": {
     "duration": 2.43242,
     "end_time": "2022-06-06T15:11:53.435207",
     "exception": false,
     "start_time": "2022-06-06T15:11:51.002787",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU at: /device:GPU:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-06 15:11:51.071997: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-06 15:11:51.141094: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-06 15:11:51.259882: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-06 15:11:51.260678: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-06 15:11:53.416098: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-06 15:11:53.417113: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-06 15:11:53.417820: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-06 15:11:53.418996: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /device:GPU:0 with 15403 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    }
   ],
   "source": [
    "# Making sure that Tensorflow is able to detect the GPU\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if \"GPU\" not in device_name:\n",
    "    print(\"GPU device not found\")\n",
    "print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c1fa04d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-06T15:11:53.474553Z",
     "iopub.status.busy": "2022-06-06T15:11:53.474347Z",
     "iopub.status.idle": "2022-06-06T15:11:53.531424Z",
     "shell.execute_reply": "2022-06-06T15:11:53.530754Z"
    },
    "papermill": {
     "duration": 0.078835,
     "end_time": "2022-06-06T15:11:53.533205",
     "exception": false,
     "start_time": "2022-06-06T15:11:53.454370",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# These are the usual ipython objects\n",
    "ipython_vars = ['In', 'Out', 'exit', 'quit', 'get_ipython', 'ipython_vars']\n",
    "\n",
    "# Defining a function to list the memory consumed\n",
    "# Only outputs variables taking at least 1MB space\n",
    "def list_storage(inp_dir):\n",
    "    # Get a sorted list of the objects and their sizes\n",
    "    vars_defined = [x for x in inp_dir if not x.startswith('_') and x not in sys.modules and x not in ipython_vars]\n",
    "    sto = sorted([(x, sys.getsizeof(globals().get(x))) for x in vars_defined], key=lambda x: x[1], reverse=True)\n",
    "    sto = [(x[0], str(round((x[1] / 2**20), 2)) + ' MB') for x in sto if x[1] >= 2**20]\n",
    "    print(tabulate(sto, headers = ['Variable', 'Storage (in MB)']))\n",
    "\n",
    "# In order to use this function, use the below line of code\n",
    "# list_storage(dir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3449adce",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2022-06-06T15:11:53.574627Z",
     "iopub.status.busy": "2022-06-06T15:11:53.573935Z",
     "iopub.status.idle": "2022-06-06T15:12:23.150708Z",
     "shell.execute_reply": "2022-06-06T15:12:23.149720Z"
    },
    "papermill": {
     "duration": 29.60049,
     "end_time": "2022-06-06T15:12:23.152574",
     "exception": false,
     "start_time": "2022-06-06T15:11:53.552084",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40006, 3072) (40006, 1)\n",
      "(40006, 3, 32, 32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-06 15:12:17.457976: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-06 15:12:17.458980: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-06 15:12:17.459793: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-06 15:12:17.460828: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-06 15:12:17.461495: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-06 15:12:17.462121: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-06 15:12:17.462792: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-06 15:12:17.463479: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-06 15:12:17.464049: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15403 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40006, 32, 32, 3) (40006, 10)\n",
      "(10000, 3072) (10000, 1)\n",
      "(10000, 3, 32, 32)\n",
      "(10000, 32, 32, 3) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "# Importing the Labelled Dataset\n",
    "df_train = pd.read_csv(\"../input/cifar10/train_lab_x.csv\")\n",
    "y_train = pd.read_csv(\"../input/cifar10/train_lab_y.csv\")\n",
    "df_train = np.array(df_train)\n",
    "y_train = np.array(y_train)\n",
    "print(df_train.shape, y_train.shape)\n",
    "\n",
    "# Reshaping the dataset\n",
    "df_train = np.reshape(df_train, (-1, 3, 32, 32))\n",
    "print(df_train.shape)\n",
    "\n",
    "# Basic Pre-processing\n",
    "# Creating a random permutation\n",
    "perm = np.random.permutation(df_train.shape[0])\n",
    "\n",
    "# Shuffling the training dataset\n",
    "df_train = df_train[perm, : , : , : ]\n",
    "y_train = y_train[perm]\n",
    "\n",
    "# Reshaping, rescaling and one-hot encoding\n",
    "df_train = np.transpose(np.array(df_train), (0, 2, 3, 1))\n",
    "df_train = df_train / 255\n",
    "y_train_oh = tf.one_hot(np.ravel(y_train), depth = 10)\n",
    "print(df_train.shape, y_train_oh.shape)\n",
    "\n",
    "# Importing the Test Dataset\n",
    "df_test = pd.read_csv(\"../input/cifar10/test_x.csv\")\n",
    "y_test = pd.read_csv(\"../input/cifar10/test_y.csv\")\n",
    "df_test = np.array(df_test)\n",
    "y_test = np.array(y_test)\n",
    "print(df_test.shape, y_test.shape)\n",
    "\n",
    "# Reshaping the dataset\n",
    "df_test = np.reshape(df_test, (-1, 3, 32, 32))\n",
    "print(df_test.shape)\n",
    "\n",
    "# Reshaping, rescaling and one-hot encoding\n",
    "df_test = np.transpose(np.array(df_test), (0, 2, 3, 1))\n",
    "df_test = df_test / 255\n",
    "y_test_oh = tf.one_hot(np.ravel(y_test), depth = 10)\n",
    "print(df_test.shape, y_test_oh.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7bf0a8",
   "metadata": {
    "papermill": {
     "duration": 0.019939,
     "end_time": "2022-06-06T15:12:23.193618",
     "exception": false,
     "start_time": "2022-06-06T15:12:23.173679",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Create images from csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2560de8a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-06T15:12:23.235293Z",
     "iopub.status.busy": "2022-06-06T15:12:23.235070Z",
     "iopub.status.idle": "2022-06-06T15:12:23.290675Z",
     "shell.execute_reply": "2022-06-06T15:12:23.290057Z"
    },
    "papermill": {
     "duration": 0.078573,
     "end_time": "2022-06-06T15:12:23.292310",
     "exception": false,
     "start_time": "2022-06-06T15:12:23.213737",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_dir_images(data_csv, path):\n",
    "    \"\"\"A function to create images from CSV file\"\"\"\n",
    "    for i in tqdm(range(len(data_csv))):\n",
    "        img = data_csv[i, : , : , : ] * 255\n",
    "        img = img.astype(np.uint8)\n",
    "        cv2.imwrite(path + str(i) + '.png', img)\n",
    "\n",
    "def str2bool(v):\n",
    "    if v.lower() in ['true', 1]:\n",
    "        return True\n",
    "    elif v.lower() in ['false', 0]:\n",
    "        return False\n",
    "    else:\n",
    "        raise argparse.ArgumentTypeError('Boolean value expected.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d4d217",
   "metadata": {
    "papermill": {
     "duration": 0.019624,
     "end_time": "2022-06-06T15:12:23.332250",
     "exception": false,
     "start_time": "2022-06-06T15:12:23.312626",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Creating the Image Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d241ecbc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-06T15:12:23.373724Z",
     "iopub.status.busy": "2022-06-06T15:12:23.373511Z",
     "iopub.status.idle": "2022-06-06T15:12:23.440890Z",
     "shell.execute_reply": "2022-06-06T15:12:23.440285Z"
    },
    "papermill": {
     "duration": 0.090152,
     "end_time": "2022-06-06T15:12:23.442925",
     "exception": false,
     "start_time": "2022-06-06T15:12:23.352773",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Cifar10ImageDataGenerator:\n",
    "    def __init__(self, args):\n",
    "        self.datagen = ImageDataGenerator(width_shift_range=0.1, height_shift_range=0.1, fill_mode='constant', cval=0, horizontal_flip=True)\n",
    "\n",
    "        self.means = np.array([0.4914009 , 0.48215896, 0.4465308])\n",
    "        self.stds = np.array([0.24703279, 0.24348423, 0.26158753])\n",
    "\n",
    "        self.args = args\n",
    "        if args.auto_augment:\n",
    "            self.policies = [\n",
    "                ['Invert', 0.1, 7, 'Contrast', 0.2, 6],\n",
    "                ['Rotate', 0.7, 2, 'TranslateX', 0.3, 9],\n",
    "                ['Sharpness', 0.8, 1, 'Sharpness', 0.9, 3],\n",
    "                ['ShearY', 0.5, 8, 'TranslateY', 0.7, 9],\n",
    "                ['AutoContrast', 0.5, 8, 'Equalize', 0.9, 2],\n",
    "                ['ShearY', 0.2, 7, 'Posterize', 0.3, 7],\n",
    "                ['Color', 0.4, 3, 'Brightness', 0.6, 7],\n",
    "                ['Sharpness', 0.3, 9, 'Brightness', 0.7, 9],\n",
    "                ['Equalize', 0.6, 5, 'Equalize', 0.5, 1],\n",
    "                ['Contrast', 0.6, 7, 'Sharpness', 0.6, 5],\n",
    "                ['Color', 0.7, 7, 'TranslateX', 0.5, 8],\n",
    "                ['Equalize', 0.3, 7, 'AutoContrast', 0.4, 8],\n",
    "                ['TranslateY', 0.4, 3, 'Sharpness', 0.2, 6],\n",
    "                ['Brightness', 0.9, 6, 'Color', 0.2, 8],\n",
    "                ['Solarize', 0.5, 2, 'Invert', 0, 0.3],\n",
    "                ['Equalize', 0.2, 0, 'AutoContrast', 0.6, 0],\n",
    "                ['Equalize', 0.2, 8, 'Equalize', 0.6, 4],\n",
    "                ['Color', 0.9, 9, 'Equalize', 0.6, 6],\n",
    "                ['AutoContrast', 0.8, 4, 'Solarize', 0.2, 8],\n",
    "                ['Brightness', 0.1, 3, 'Color', 0.7, 0],\n",
    "                ['Solarize', 0.4, 5, 'AutoContrast', 0.9, 3],\n",
    "                ['TranslateY', 0.9, 9, 'TranslateY', 0.7, 9],\n",
    "                ['AutoContrast', 0.9, 2, 'Solarize', 0.8, 3],\n",
    "                ['Equalize', 0.8, 8, 'Invert', 0.1, 3],\n",
    "                ['TranslateY', 0.7, 9, 'AutoContrast', 0.9, 1],\n",
    "            ]\n",
    "\n",
    "    def standardize(self, x):\n",
    "        x = x.astype('float32') / 255\n",
    "\n",
    "        means = self.means.reshape(1, 1, 1, 3)\n",
    "        stds = self.stds.reshape(1, 1, 1, 3)\n",
    "\n",
    "        x -= means\n",
    "        x /= (stds + 1e-6)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def flow(self, x, y=None, batch_size=32, shuffle=True, sample_weight=None,\n",
    "             seed=None, save_to_dir=None, save_prefix='', save_format='png', subset=None):\n",
    "        batches = self.datagen.flow(x, y, batch_size, shuffle, sample_weight,\n",
    "                               seed, save_to_dir, save_prefix, save_format, subset)\n",
    "\n",
    "        while True:\n",
    "            x_batch, y_batch = next(batches)\n",
    "\n",
    "            if self.args.cutout:\n",
    "                for i in range(x_batch.shape[0]):\n",
    "                    x_batch[i] = cutout(x_batch[i])\n",
    "\n",
    "            if self.args.auto_augment:\n",
    "                x_batch = x_batch.astype('uint8')\n",
    "                for i in range(x_batch.shape[0]):\n",
    "                    x_batch[i] = apply_policy(x_batch[i], self.policies[random.randrange(len(self.policies))])\n",
    "\n",
    "            x_batch = self.standardize(x_batch)\n",
    "\n",
    "            yield x_batch, y_batch\n",
    "\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--cutout', default=True, type=str2bool)\n",
    "    parser.add_argument('--auto-augment', default=True, type=str2bool)\n",
    "    args = parser.parse_args()\n",
    "    datagen = Cifar10ImageDataGenerator(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3cad89",
   "metadata": {
    "papermill": {
     "duration": 0.019532,
     "end_time": "2022-06-06T15:12:23.482285",
     "exception": false,
     "start_time": "2022-06-06T15:12:23.462753",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Applying the augmentations on the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1563b8ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-06T15:12:23.523130Z",
     "iopub.status.busy": "2022-06-06T15:12:23.522910Z",
     "iopub.status.idle": "2022-06-06T15:12:23.613379Z",
     "shell.execute_reply": "2022-06-06T15:12:23.612748Z"
    },
    "papermill": {
     "duration": 0.113062,
     "end_time": "2022-06-06T15:12:23.615214",
     "exception": false,
     "start_time": "2022-06-06T15:12:23.502152",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "operations = {\n",
    "    'ShearX': lambda img, magnitude: shear_x(img, magnitude),\n",
    "    'ShearY': lambda img, magnitude: shear_y(img, magnitude),\n",
    "    'TranslateX': lambda img, magnitude: translate_x(img, magnitude),\n",
    "    'TranslateY': lambda img, magnitude: translate_y(img, magnitude),\n",
    "    'Rotate': lambda img, magnitude: rotate(img, magnitude),\n",
    "    'AutoContrast': lambda img, magnitude: auto_contrast(img, magnitude),\n",
    "    'Invert': lambda img, magnitude: invert(img, magnitude),\n",
    "    'Equalize': lambda img, magnitude: equalize(img, magnitude),\n",
    "    'Solarize': lambda img, magnitude: solarize(img, magnitude),\n",
    "    'Posterize': lambda img, magnitude: posterize(img, magnitude),\n",
    "    'Contrast': lambda img, magnitude: contrast(img, magnitude),\n",
    "    'Color': lambda img, magnitude: color(img, magnitude),\n",
    "    'Brightness': lambda img, magnitude: brightness(img, magnitude),\n",
    "    'Sharpness': lambda img, magnitude: sharpness(img, magnitude),\n",
    "    'Cutout': lambda img, magnitude: cutout(img, magnitude),\n",
    "}\n",
    "\n",
    "\n",
    "def apply_policy(img, policy):\n",
    "    if random.random() < policy[1]:\n",
    "        img = operations[policy[0]](img, policy[2])\n",
    "    if random.random() < policy[4]:\n",
    "        img = operations[policy[3]](img, policy[5])\n",
    "\n",
    "    return img\n",
    "\n",
    "\n",
    "def transform_matrix_offset_center(matrix, x, y):\n",
    "    o_x = float(x) / 2 + 0.5\n",
    "    o_y = float(y) / 2 + 0.5\n",
    "    offset_matrix = np.array([[1, 0, o_x], [0, 1, o_y], [0, 0, 1]])\n",
    "    reset_matrix = np.array([[1, 0, -o_x], [0, 1, -o_y], [0, 0, 1]])\n",
    "    transform_matrix = offset_matrix @ matrix @ reset_matrix\n",
    "    return transform_matrix\n",
    "\n",
    "\n",
    "def shear_x(img, magnitude):\n",
    "    magnitudes = np.linspace(-0.3, 0.3, 11)\n",
    "\n",
    "    transform_matrix = np.array([[1, random.uniform(magnitudes[magnitude], magnitudes[magnitude+1]), 0],\n",
    "                                 [0, 1, 0],\n",
    "                                 [0, 0, 1]])\n",
    "    transform_matrix = transform_matrix_offset_center(transform_matrix, img.shape[0], img.shape[1])\n",
    "    affine_matrix = transform_matrix[:2, :2]\n",
    "    offset = transform_matrix[:2, 2]\n",
    "    img = np.stack([ndimage.interpolation.affine_transform(\n",
    "                    img[:, :, c],\n",
    "                    affine_matrix,\n",
    "                    offset) for c in range(img.shape[2])], axis=2)\n",
    "    return img\n",
    "\n",
    "\n",
    "def shear_y(img, magnitude):\n",
    "    magnitudes = np.linspace(-0.3, 0.3, 11)\n",
    "\n",
    "    transform_matrix = np.array([[1, 0, 0],\n",
    "                                 [random.uniform(magnitudes[magnitude], magnitudes[magnitude+1]), 1, 0],\n",
    "                                 [0, 0, 1]])\n",
    "    transform_matrix = transform_matrix_offset_center(transform_matrix, img.shape[0], img.shape[1])\n",
    "    affine_matrix = transform_matrix[:2, :2]\n",
    "    offset = transform_matrix[:2, 2]\n",
    "    img = np.stack([ndimage.interpolation.affine_transform(\n",
    "                    img[:, :, c],\n",
    "                    affine_matrix,\n",
    "                    offset) for c in range(img.shape[2])], axis=2)\n",
    "    return img\n",
    "\n",
    "\n",
    "def translate_x(img, magnitude):\n",
    "    magnitudes = np.linspace(-150/331, 150/331, 11)\n",
    "\n",
    "    transform_matrix = np.array([[1, 0, 0],\n",
    "                                 [0, 1, img.shape[1]*random.uniform(magnitudes[magnitude], magnitudes[magnitude+1])],\n",
    "                                 [0, 0, 1]])\n",
    "    transform_matrix = transform_matrix_offset_center(transform_matrix, img.shape[0], img.shape[1])\n",
    "    affine_matrix = transform_matrix[:2, :2]\n",
    "    offset = transform_matrix[:2, 2]\n",
    "    img = np.stack([ndimage.interpolation.affine_transform(\n",
    "                    img[:, :, c],\n",
    "                    affine_matrix,\n",
    "                    offset) for c in range(img.shape[2])], axis=2)\n",
    "    return img\n",
    "\n",
    "\n",
    "def translate_y(img, magnitude):\n",
    "    magnitudes = np.linspace(-150/331, 150/331, 11)\n",
    "\n",
    "    transform_matrix = np.array([[1, 0, img.shape[0]*random.uniform(magnitudes[magnitude], magnitudes[magnitude+1])],\n",
    "                                 [0, 1, 0],\n",
    "                                 [0, 0, 1]])\n",
    "    transform_matrix = transform_matrix_offset_center(transform_matrix, img.shape[0], img.shape[1])\n",
    "    affine_matrix = transform_matrix[:2, :2]\n",
    "    offset = transform_matrix[:2, 2]\n",
    "    img = np.stack([ndimage.interpolation.affine_transform(\n",
    "                    img[:, :, c],\n",
    "                    affine_matrix,\n",
    "                    offset) for c in range(img.shape[2])], axis=2)\n",
    "    return img\n",
    "\n",
    "\n",
    "def rotate(img, magnitude):\n",
    "    magnitudes = np.linspace(-30, 30, 11)\n",
    "\n",
    "    theta = np.deg2rad(random.uniform(magnitudes[magnitude], magnitudes[magnitude+1]))\n",
    "    transform_matrix = np.array([[np.cos(theta), -np.sin(theta), 0],\n",
    "                                 [np.sin(theta), np.cos(theta), 0],\n",
    "                                 [0, 0, 1]])\n",
    "    transform_matrix = transform_matrix_offset_center(transform_matrix, img.shape[0], img.shape[1])\n",
    "    affine_matrix = transform_matrix[:2, :2]\n",
    "    offset = transform_matrix[:2, 2]\n",
    "    img = np.stack([ndimage.interpolation.affine_transform(\n",
    "                    img[:, :, c],\n",
    "                    affine_matrix,\n",
    "                    offset) for c in range(img.shape[2])], axis=2)\n",
    "    return img\n",
    "\n",
    "\n",
    "def auto_contrast(img, magnitude):\n",
    "    img = Image.fromarray(img)\n",
    "    img = ImageOps.autocontrast(img)\n",
    "    img = np.array(img)\n",
    "    return img\n",
    "\n",
    "\n",
    "def invert(img, magnitude):\n",
    "    img = Image.fromarray(img)\n",
    "    img = ImageOps.invert(img)\n",
    "    img = np.array(img)\n",
    "    return img\n",
    "\n",
    "\n",
    "def equalize(img, magnitude):\n",
    "    img = Image.fromarray(img)\n",
    "    img = ImageOps.equalize(img)\n",
    "    img = np.array(img)\n",
    "    return img\n",
    "\n",
    "\n",
    "def solarize(img, magnitude):\n",
    "    magnitudes = np.linspace(0, 256, 11)\n",
    "\n",
    "    img = Image.fromarray(img)\n",
    "    img = ImageOps.solarize(img, random.uniform(magnitudes[magnitude], magnitudes[magnitude+1]))\n",
    "    img = np.array(img)\n",
    "    return img\n",
    "\n",
    "\n",
    "def posterize(img, magnitude):\n",
    "    magnitudes = np.linspace(4, 8, 11)\n",
    "\n",
    "    img = Image.fromarray(img)\n",
    "    img = ImageOps.posterize(img, int(round(random.uniform(magnitudes[magnitude], magnitudes[magnitude+1]))))\n",
    "    img = np.array(img)\n",
    "    return img\n",
    "\n",
    "\n",
    "def contrast(img, magnitude):\n",
    "    magnitudes = np.linspace(0.1, 1.9, 11)\n",
    "\n",
    "    img = Image.fromarray(img)\n",
    "    img = ImageEnhance.Contrast(img).enhance(random.uniform(magnitudes[magnitude], magnitudes[magnitude+1]))\n",
    "    img = np.array(img)\n",
    "    return img\n",
    "\n",
    "\n",
    "def color(img, magnitude):\n",
    "    magnitudes = np.linspace(0.1, 1.9, 11)\n",
    "\n",
    "    img = Image.fromarray(img)\n",
    "    img = ImageEnhance.Color(img).enhance(random.uniform(magnitudes[magnitude], magnitudes[magnitude+1]))\n",
    "    img = np.array(img)\n",
    "    return img\n",
    "\n",
    "\n",
    "def brightness(img, magnitude):\n",
    "    magnitudes = np.linspace(0.1, 1.9, 11)\n",
    "\n",
    "    img = Image.fromarray(img)\n",
    "    img = ImageEnhance.Brightness(img).enhance(random.uniform(magnitudes[magnitude], magnitudes[magnitude+1]))\n",
    "    img = np.array(img)\n",
    "    return img\n",
    "\n",
    "\n",
    "def sharpness(img, magnitude):\n",
    "    magnitudes = np.linspace(0.1, 1.9, 11)\n",
    "\n",
    "    img = Image.fromarray(img)\n",
    "    img = ImageEnhance.Sharpness(img).enhance(random.uniform(magnitudes[magnitude], magnitudes[magnitude+1]))\n",
    "    img = np.array(img)\n",
    "    return img\n",
    "\n",
    "\n",
    "def cutout(org_img, magnitude=None):\n",
    "    magnitudes = np.linspace(0, 60/331, 11)\n",
    "\n",
    "    img = np.copy(org_img)\n",
    "    mask_val = img.mean()\n",
    "\n",
    "    if magnitude is None:\n",
    "        mask_size = 16\n",
    "    else:\n",
    "        mask_size = int(round(img.shape[0]*random.uniform(magnitudes[magnitude], magnitudes[magnitude+1])))\n",
    "    top = np.random.randint(0 - mask_size//2, img.shape[0] - mask_size)\n",
    "    left = np.random.randint(0 - mask_size//2, img.shape[1] - mask_size)\n",
    "    bottom = top + mask_size\n",
    "    right = left + mask_size\n",
    "\n",
    "    if top < 0:\n",
    "        top = 0\n",
    "    if left < 0:\n",
    "        left = 0\n",
    "\n",
    "    img[top:bottom, left:right, :].fill(mask_val)\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70173a24",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-06T15:12:23.655871Z",
     "iopub.status.busy": "2022-06-06T15:12:23.655345Z",
     "iopub.status.idle": "2022-06-06T15:12:23.707877Z",
     "shell.execute_reply": "2022-06-06T15:12:23.707283Z"
    },
    "papermill": {
     "duration": 0.074958,
     "end_time": "2022-06-06T15:12:23.709858",
     "exception": false,
     "start_time": "2022-06-06T15:12:23.634900",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    parser.add_argument('--name', default=None,\n",
    "                        help='model name: (default: arch+timestamp)')\n",
    "    parser.add_argument('--depth', default=28, type=int)\n",
    "    parser.add_argument('--width', default=10, type=int)\n",
    "    parser.add_argument('--epochs', default=200, type=int)\n",
    "    parser.add_argument('--batch-size', default=128, type=int)\n",
    "    parser.add_argument('--cutout', default=False, type=str2bool)\n",
    "    parser.add_argument('--auto-augment', default=False, type=str2bool)\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49dcacc9",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2022-06-06T15:12:23.750874Z",
     "iopub.status.busy": "2022-06-06T15:12:23.750689Z",
     "iopub.status.idle": "2022-06-06T15:12:24.000422Z",
     "shell.execute_reply": "2022-06-06T15:12:23.999682Z"
    },
    "papermill": {
     "duration": 0.272571,
     "end_time": "2022-06-06T15:12:24.002283",
     "exception": false,
     "start_time": "2022-06-06T15:12:23.729712",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 32, 32, 16)        448       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 32, 32, 16)        64        \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 16)        2320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32, 32, 16)        64        \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 16, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 15, 15, 32)        2080      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 15, 15, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 14, 14, 32)        4128      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 14, 14, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1568)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               401664    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 428,122\n",
      "Trainable params: 427,930\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Importing the Baseline Model Architecture\n",
    "copyfile(src = \"../input/dcai-rw/baseline_arch.py\", dst = \"../working/baseline_arch.py\")\n",
    "from baseline_arch import cnn_model\n",
    "\n",
    "conv_model = cnn_model((32, 32, 3))\n",
    "conv_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics='accuracy')\n",
    "conv_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "676cc5b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-06T15:12:24.044439Z",
     "iopub.status.busy": "2022-06-06T15:12:24.044193Z",
     "iopub.status.idle": "2022-06-06T15:12:24.097026Z",
     "shell.execute_reply": "2022-06-06T15:12:24.096367Z"
    },
    "papermill": {
     "duration": 0.075932,
     "end_time": "2022-06-06T15:12:24.098680",
     "exception": false,
     "start_time": "2022-06-06T15:12:24.022748",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.argv=['']\n",
    "del sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "30099d6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-06T15:12:24.140171Z",
     "iopub.status.busy": "2022-06-06T15:12:24.139603Z",
     "iopub.status.idle": "2022-06-06T15:12:24.301422Z",
     "shell.execute_reply": "2022-06-06T15:12:24.300736Z"
    },
    "papermill": {
     "duration": 0.184327,
     "end_time": "2022-06-06T15:12:24.303103",
     "exception": false,
     "start_time": "2022-06-06T15:12:24.118776",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40006, 32, 32, 3) (10000, 32, 32, 3)\n",
      "0.0 0.9333333333333333\n",
      "0.050980392156862744 1.0\n",
      "0.0 238.0\n",
      "13.0 255.0\n"
     ]
    }
   ],
   "source": [
    "print(df_train.shape, df_test.shape)\n",
    "print(np.min(df_train[0]), np.max(df_train[0]))\n",
    "print(np.min(df_test[0]), np.max(df_test[0]))\n",
    "\n",
    "df_train *= 255\n",
    "df_test *= 255\n",
    "\n",
    "print(np.min(df_train[0]), np.max(df_train[0]))\n",
    "print(np.min(df_test[0]), np.max(df_test[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2943e37f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-06T15:12:24.346091Z",
     "iopub.status.busy": "2022-06-06T15:12:24.345564Z",
     "iopub.status.idle": "2022-06-06T15:12:24.522609Z",
     "shell.execute_reply": "2022-06-06T15:12:24.521952Z"
    },
    "papermill": {
     "duration": 0.200609,
     "end_time": "2022-06-06T15:12:24.524482",
     "exception": false,
     "start_time": "2022-06-06T15:12:24.323873",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "args = parse_args()\n",
    "datagen = Cifar10ImageDataGenerator(args)\n",
    "df_test = datagen.standardize(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3f2e8f",
   "metadata": {
    "papermill": {
     "duration": 0.021033,
     "end_time": "2022-06-06T15:12:24.566976",
     "exception": false,
     "start_time": "2022-06-06T15:12:24.545943",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training & Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0726dd93",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2022-06-06T15:12:24.609511Z",
     "iopub.status.busy": "2022-06-06T15:12:24.609313Z",
     "iopub.status.idle": "2022-06-06T15:32:38.303444Z",
     "shell.execute_reply": "2022-06-06T15:32:38.302744Z"
    },
    "papermill": {
     "duration": 1218.527911,
     "end_time": "2022-06-06T15:32:43.115597",
     "exception": false,
     "start_time": "2022-06-06T15:12:24.587686",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n",
      "2022-06-06 15:12:24.969770: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-06 15:12:26.554057: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "312/312 [==============================] - 26s 59ms/step - loss: 1.9467 - accuracy: 0.2883 - val_loss: 1.6589 - val_accuracy: 0.3992\n",
      "Epoch 2/10\n",
      "312/312 [==============================] - 17s 56ms/step - loss: 1.6192 - accuracy: 0.4105 - val_loss: 1.3223 - val_accuracy: 0.5247\n",
      "Epoch 3/10\n",
      "312/312 [==============================] - 19s 60ms/step - loss: 1.4749 - accuracy: 0.4696 - val_loss: 1.2751 - val_accuracy: 0.5492\n",
      "Epoch 4/10\n",
      "312/312 [==============================] - 17s 55ms/step - loss: 1.3751 - accuracy: 0.5078 - val_loss: 1.1668 - val_accuracy: 0.5926\n",
      "Epoch 5/10\n",
      "312/312 [==============================] - 18s 58ms/step - loss: 1.2837 - accuracy: 0.5475 - val_loss: 1.1002 - val_accuracy: 0.6098\n",
      "Epoch 6/10\n",
      "312/312 [==============================] - 17s 54ms/step - loss: 1.2190 - accuracy: 0.5723 - val_loss: 0.9882 - val_accuracy: 0.6533\n",
      "Epoch 7/10\n",
      "312/312 [==============================] - 19s 61ms/step - loss: 1.1560 - accuracy: 0.5958 - val_loss: 0.9682 - val_accuracy: 0.6516\n",
      "Epoch 8/10\n",
      "312/312 [==============================] - 17s 56ms/step - loss: 1.1062 - accuracy: 0.6142 - val_loss: 0.9819 - val_accuracy: 0.6590\n",
      "Epoch 9/10\n",
      "312/312 [==============================] - 18s 58ms/step - loss: 1.0728 - accuracy: 0.6251 - val_loss: 0.9227 - val_accuracy: 0.6772\n",
      "Epoch 10/10\n",
      "312/312 [==============================] - 18s 57ms/step - loss: 1.0403 - accuracy: 0.6363 - val_loss: 0.9422 - val_accuracy: 0.6723\n",
      "For  10  Epochs:\n",
      "Log-loss for Train Dataset =  26.245288763704004\n",
      "Log-loss for Test Dataset =  0.9421724155942622\n",
      "Accuracy for Train Dataset =  0.16650002499625055\n",
      "Accuracy for Test Dataset =  0.6723\n",
      "\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.9422 - accuracy: 0.6723\n",
      "Test loss: 0.9421724677085876\n",
      "Test accuracy: 0.6722999811172485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "312/312 [==============================] - 20s 65ms/step - loss: 1.0067 - accuracy: 0.6484 - val_loss: 0.8744 - val_accuracy: 0.6978\n",
      "Epoch 2/20\n",
      "312/312 [==============================] - 17s 56ms/step - loss: 0.9930 - accuracy: 0.6526 - val_loss: 0.8878 - val_accuracy: 0.6944\n",
      "Epoch 3/20\n",
      "312/312 [==============================] - 18s 59ms/step - loss: 0.9745 - accuracy: 0.6626 - val_loss: 0.8566 - val_accuracy: 0.7028\n",
      "Epoch 4/20\n",
      "312/312 [==============================] - 19s 60ms/step - loss: 0.9481 - accuracy: 0.6692 - val_loss: 0.8413 - val_accuracy: 0.7088\n",
      "Epoch 5/20\n",
      "312/312 [==============================] - 18s 58ms/step - loss: 0.9358 - accuracy: 0.6766 - val_loss: 0.8594 - val_accuracy: 0.7088\n",
      "Epoch 6/20\n",
      "312/312 [==============================] - 18s 59ms/step - loss: 0.9246 - accuracy: 0.6811 - val_loss: 0.8588 - val_accuracy: 0.7050\n",
      "Epoch 7/20\n",
      "312/312 [==============================] - 18s 58ms/step - loss: 0.9054 - accuracy: 0.6850 - val_loss: 0.8553 - val_accuracy: 0.7145\n",
      "Epoch 8/20\n",
      "312/312 [==============================] - 19s 60ms/step - loss: 0.8946 - accuracy: 0.6921 - val_loss: 0.8206 - val_accuracy: 0.7149\n",
      "Epoch 9/20\n",
      "312/312 [==============================] - 18s 58ms/step - loss: 0.8882 - accuracy: 0.6917 - val_loss: 0.8352 - val_accuracy: 0.7136\n",
      "Epoch 10/20\n",
      "312/312 [==============================] - 19s 60ms/step - loss: 0.8638 - accuracy: 0.7000 - val_loss: 0.7928 - val_accuracy: 0.7270\n",
      "Epoch 11/20\n",
      "312/312 [==============================] - 18s 58ms/step - loss: 0.8614 - accuracy: 0.7047 - val_loss: 0.8139 - val_accuracy: 0.7222\n",
      "Epoch 12/20\n",
      "312/312 [==============================] - 18s 58ms/step - loss: 0.8595 - accuracy: 0.7041 - val_loss: 0.7414 - val_accuracy: 0.7425\n",
      "Epoch 13/20\n",
      "312/312 [==============================] - 19s 62ms/step - loss: 0.8452 - accuracy: 0.7101 - val_loss: 0.7481 - val_accuracy: 0.7429\n",
      "Epoch 14/20\n",
      "312/312 [==============================] - 18s 56ms/step - loss: 0.8354 - accuracy: 0.7120 - val_loss: 0.7989 - val_accuracy: 0.7328\n",
      "Epoch 15/20\n",
      "312/312 [==============================] - 19s 62ms/step - loss: 0.8277 - accuracy: 0.7140 - val_loss: 0.8485 - val_accuracy: 0.7124\n",
      "Epoch 16/20\n",
      "312/312 [==============================] - 18s 59ms/step - loss: 0.8244 - accuracy: 0.7164 - val_loss: 0.7572 - val_accuracy: 0.7446\n",
      "Epoch 17/20\n",
      "312/312 [==============================] - 20s 63ms/step - loss: 0.8119 - accuracy: 0.7201 - val_loss: 0.7409 - val_accuracy: 0.7448\n",
      "Epoch 18/20\n",
      "312/312 [==============================] - 18s 57ms/step - loss: 0.8086 - accuracy: 0.7207 - val_loss: 0.8886 - val_accuracy: 0.7091\n",
      "Epoch 19/20\n",
      "312/312 [==============================] - 19s 62ms/step - loss: 0.7978 - accuracy: 0.7271 - val_loss: 0.7201 - val_accuracy: 0.7504\n",
      "Epoch 20/20\n",
      "312/312 [==============================] - 18s 57ms/step - loss: 0.7986 - accuracy: 0.7250 - val_loss: 0.7635 - val_accuracy: 0.7438\n",
      "For  20  Epochs:\n",
      "Log-loss for Train Dataset =  25.68673657433847\n",
      "Log-loss for Test Dataset =  0.7635399298709211\n",
      "Accuracy for Train Dataset =  0.12438134279858021\n",
      "Accuracy for Test Dataset =  0.7438\n",
      "\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.7635 - accuracy: 0.7438\n",
      "Test loss: 0.7635399699211121\n",
      "Test accuracy: 0.7437999844551086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "312/312 [==============================] - 20s 65ms/step - loss: 0.7886 - accuracy: 0.7268 - val_loss: 0.7657 - val_accuracy: 0.7418\n",
      "Epoch 2/30\n",
      "312/312 [==============================] - 20s 64ms/step - loss: 0.7857 - accuracy: 0.7324 - val_loss: 0.7798 - val_accuracy: 0.7338\n",
      "Epoch 3/30\n",
      "312/312 [==============================] - 18s 57ms/step - loss: 0.7682 - accuracy: 0.7393 - val_loss: 0.7176 - val_accuracy: 0.7564\n",
      "Epoch 4/30\n",
      "312/312 [==============================] - 20s 63ms/step - loss: 0.7756 - accuracy: 0.7328 - val_loss: 0.6859 - val_accuracy: 0.7616\n",
      "Epoch 5/30\n",
      "312/312 [==============================] - 18s 57ms/step - loss: 0.7690 - accuracy: 0.7344 - val_loss: 0.7016 - val_accuracy: 0.7569\n",
      "Epoch 6/30\n",
      "312/312 [==============================] - 20s 65ms/step - loss: 0.7640 - accuracy: 0.7375 - val_loss: 0.6692 - val_accuracy: 0.7666\n",
      "Epoch 7/30\n",
      "312/312 [==============================] - 18s 58ms/step - loss: 0.7598 - accuracy: 0.7377 - val_loss: 0.7555 - val_accuracy: 0.7445\n",
      "Epoch 8/30\n",
      "312/312 [==============================] - 20s 65ms/step - loss: 0.7537 - accuracy: 0.7403 - val_loss: 0.7032 - val_accuracy: 0.7584\n",
      "Epoch 9/30\n",
      "312/312 [==============================] - 19s 60ms/step - loss: 0.7522 - accuracy: 0.7405 - val_loss: 0.7785 - val_accuracy: 0.7415\n",
      "Epoch 10/30\n",
      "312/312 [==============================] - 20s 64ms/step - loss: 0.7382 - accuracy: 0.7448 - val_loss: 0.7104 - val_accuracy: 0.7573\n",
      "Epoch 11/30\n",
      "312/312 [==============================] - 18s 58ms/step - loss: 0.7387 - accuracy: 0.7467 - val_loss: 0.7375 - val_accuracy: 0.7488\n",
      "Epoch 12/30\n",
      "312/312 [==============================] - 21s 68ms/step - loss: 0.7401 - accuracy: 0.7444 - val_loss: 0.6873 - val_accuracy: 0.7608\n",
      "Epoch 13/30\n",
      "312/312 [==============================] - 20s 64ms/step - loss: 0.7374 - accuracy: 0.7461 - val_loss: 0.6896 - val_accuracy: 0.7602\n",
      "Epoch 14/30\n",
      "312/312 [==============================] - 22s 71ms/step - loss: 0.7366 - accuracy: 0.7471 - val_loss: 0.6784 - val_accuracy: 0.7672\n",
      "Epoch 15/30\n",
      "312/312 [==============================] - 23s 74ms/step - loss: 0.7286 - accuracy: 0.7488 - val_loss: 0.7063 - val_accuracy: 0.7604\n",
      "Epoch 16/30\n",
      "312/312 [==============================] - 19s 60ms/step - loss: 0.7243 - accuracy: 0.7505 - val_loss: 0.6748 - val_accuracy: 0.7713\n",
      "Epoch 17/30\n",
      "312/312 [==============================] - 19s 62ms/step - loss: 0.7174 - accuracy: 0.7547 - val_loss: 0.6917 - val_accuracy: 0.7710\n",
      "Epoch 18/30\n",
      "312/312 [==============================] - 19s 60ms/step - loss: 0.7172 - accuracy: 0.7549 - val_loss: 0.7035 - val_accuracy: 0.7609\n",
      "Epoch 19/30\n",
      "312/312 [==============================] - 21s 66ms/step - loss: 0.7191 - accuracy: 0.7533 - val_loss: 0.6813 - val_accuracy: 0.7679\n",
      "Epoch 20/30\n",
      "312/312 [==============================] - 18s 57ms/step - loss: 0.7133 - accuracy: 0.7572 - val_loss: 0.7168 - val_accuracy: 0.7628\n",
      "Epoch 21/30\n",
      "312/312 [==============================] - 18s 57ms/step - loss: 0.7085 - accuracy: 0.7568 - val_loss: 0.7184 - val_accuracy: 0.7590\n",
      "Epoch 22/30\n",
      "312/312 [==============================] - 21s 67ms/step - loss: 0.7033 - accuracy: 0.7568 - val_loss: 0.7283 - val_accuracy: 0.7640\n",
      "Epoch 23/30\n",
      "312/312 [==============================] - 18s 59ms/step - loss: 0.7026 - accuracy: 0.7584 - val_loss: 0.6768 - val_accuracy: 0.7708\n",
      "Epoch 24/30\n",
      "312/312 [==============================] - 18s 57ms/step - loss: 0.7032 - accuracy: 0.7588 - val_loss: 0.6471 - val_accuracy: 0.7804\n",
      "Epoch 25/30\n",
      "312/312 [==============================] - 18s 56ms/step - loss: 0.6902 - accuracy: 0.7621 - val_loss: 0.6437 - val_accuracy: 0.7776\n",
      "Epoch 26/30\n",
      "312/312 [==============================] - 21s 69ms/step - loss: 0.6950 - accuracy: 0.7614 - val_loss: 0.6538 - val_accuracy: 0.7809\n",
      "Epoch 27/30\n",
      "312/312 [==============================] - 18s 59ms/step - loss: 0.6954 - accuracy: 0.7586 - val_loss: 0.6455 - val_accuracy: 0.7833\n",
      "Epoch 28/30\n",
      "312/312 [==============================] - 17s 56ms/step - loss: 0.6921 - accuracy: 0.7638 - val_loss: 0.6670 - val_accuracy: 0.7778\n",
      "Epoch 29/30\n",
      "312/312 [==============================] - 20s 63ms/step - loss: 0.6948 - accuracy: 0.7615 - val_loss: 0.6742 - val_accuracy: 0.7736\n",
      "Epoch 30/30\n",
      "312/312 [==============================] - 20s 64ms/step - loss: 0.6858 - accuracy: 0.7628 - val_loss: 0.6994 - val_accuracy: 0.7687\n",
      "For  30  Epochs:\n",
      "Log-loss for Train Dataset =  15.236330757441879\n",
      "Log-loss for Test Dataset =  0.6994233328333197\n",
      "Accuracy for Train Dataset =  0.1585762135679648\n",
      "Accuracy for Test Dataset =  0.7687\n",
      "\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.6994 - accuracy: 0.7687\n",
      "Test loss: 0.6994233131408691\n",
      "Test accuracy: 0.7687000036239624\n"
     ]
    }
   ],
   "source": [
    "num_epochs = [10, 20, 30]\n",
    "train_loss, test_loss, train_acc, test_acc = [], [], [], []\n",
    "\n",
    "for epochs in num_epochs:\n",
    "    # Training the Model\n",
    "    conv_model.fit_generator(datagen.flow(df_train, y_train_oh, batch_size=args.batch_size),\n",
    "    steps_per_epoch=len(df_train)//args.batch_size,\n",
    "    validation_data=(df_test, y_test_oh), epochs=epochs, verbose=1\n",
    ")\n",
    "    \n",
    "    # Predicting on the Train/Test Datasets\n",
    "    preds_train = conv_model.predict(df_train)\n",
    "    preds_test = conv_model.predict(df_test)\n",
    "\n",
    "    # Finding the Predicted Classes\n",
    "    cls_train = np.argmax(preds_train, axis = 1)\n",
    "    cls_test = np.argmax(preds_test, axis = 1)\n",
    "    \n",
    "    # Finding the Train/Test set Loss\n",
    "    train_loss.append(log_loss(y_train_oh, preds_train))\n",
    "    test_loss.append(log_loss(y_test_oh, preds_test))\n",
    "    train_acc.append(accuracy_score(y_train, cls_train))\n",
    "    test_acc.append(accuracy_score(y_test, cls_test))\n",
    "    \n",
    "    print(\"For \", epochs, \" Epochs:\")\n",
    "    print(\"Log-loss for Train Dataset = \", train_loss[-1])\n",
    "    print(\"Log-loss for Test Dataset = \", test_loss[-1])\n",
    "    print(\"Accuracy for Train Dataset = \", train_acc[-1])\n",
    "    print(\"Accuracy for Test Dataset = \", test_acc[-1])\n",
    "    print()\n",
    "    \n",
    "    scores = conv_model.evaluate(df_test, y_test_oh, verbose=1)\n",
    "    print('Test loss:', scores[0])\n",
    "    print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be6adf41",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-06T15:32:54.150074Z",
     "iopub.status.busy": "2022-06-06T15:32:54.149723Z",
     "iopub.status.idle": "2022-06-06T15:43:21.176725Z",
     "shell.execute_reply": "2022-06-06T15:43:21.175960Z"
    },
    "papermill": {
     "duration": 632.886782,
     "end_time": "2022-06-06T15:43:21.178858",
     "exception": false,
     "start_time": "2022-06-06T15:32:48.292076",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "312/312 [==============================] - 17s 56ms/step - loss: 0.6872 - accuracy: 0.7681 - val_loss: 0.6145 - val_accuracy: 0.7919\n",
      "Epoch 2/30\n",
      "312/312 [==============================] - 18s 58ms/step - loss: 0.6735 - accuracy: 0.7681 - val_loss: 0.6496 - val_accuracy: 0.7804\n",
      "Epoch 3/30\n",
      "312/312 [==============================] - 18s 58ms/step - loss: 0.6782 - accuracy: 0.7667 - val_loss: 0.6366 - val_accuracy: 0.7817\n",
      "Epoch 4/30\n",
      "312/312 [==============================] - 22s 71ms/step - loss: 0.6845 - accuracy: 0.7676 - val_loss: 0.6487 - val_accuracy: 0.7770\n",
      "Epoch 5/30\n",
      "312/312 [==============================] - 18s 58ms/step - loss: 0.6691 - accuracy: 0.7685 - val_loss: 0.6662 - val_accuracy: 0.7800\n",
      "Epoch 6/30\n",
      "312/312 [==============================] - 18s 59ms/step - loss: 0.6718 - accuracy: 0.7692 - val_loss: 0.6262 - val_accuracy: 0.7881\n",
      "Epoch 7/30\n",
      "312/312 [==============================] - 18s 58ms/step - loss: 0.6717 - accuracy: 0.7702 - val_loss: 0.6540 - val_accuracy: 0.7835\n",
      "Epoch 8/30\n",
      "312/312 [==============================] - 23s 74ms/step - loss: 0.6746 - accuracy: 0.7672 - val_loss: 0.6279 - val_accuracy: 0.7857\n",
      "Epoch 9/30\n",
      "312/312 [==============================] - 19s 60ms/step - loss: 0.6594 - accuracy: 0.7732 - val_loss: 0.6773 - val_accuracy: 0.7740\n",
      "Epoch 10/30\n",
      "312/312 [==============================] - 19s 60ms/step - loss: 0.6634 - accuracy: 0.7735 - val_loss: 0.6282 - val_accuracy: 0.7871\n",
      "Epoch 11/30\n",
      "312/312 [==============================] - 23s 74ms/step - loss: 0.6666 - accuracy: 0.7694 - val_loss: 0.7463 - val_accuracy: 0.7607\n",
      "Epoch 12/30\n",
      "312/312 [==============================] - 19s 61ms/step - loss: 0.6586 - accuracy: 0.7750 - val_loss: 0.6292 - val_accuracy: 0.7876\n",
      "Epoch 13/30\n",
      "312/312 [==============================] - 18s 59ms/step - loss: 0.6621 - accuracy: 0.7739 - val_loss: 0.6239 - val_accuracy: 0.7890\n",
      "Epoch 14/30\n",
      "312/312 [==============================] - 19s 60ms/step - loss: 0.6620 - accuracy: 0.7719 - val_loss: 0.6171 - val_accuracy: 0.7915\n",
      "Epoch 15/30\n",
      "312/312 [==============================] - 23s 73ms/step - loss: 0.6455 - accuracy: 0.7752 - val_loss: 0.6665 - val_accuracy: 0.7783\n",
      "Epoch 16/30\n",
      "312/312 [==============================] - 19s 61ms/step - loss: 0.6490 - accuracy: 0.7755 - val_loss: 0.6644 - val_accuracy: 0.7817\n",
      "Epoch 17/30\n",
      "312/312 [==============================] - 18s 57ms/step - loss: 0.6488 - accuracy: 0.7759 - val_loss: 0.6179 - val_accuracy: 0.7931\n",
      "Epoch 18/30\n",
      "312/312 [==============================] - 21s 66ms/step - loss: 0.6520 - accuracy: 0.7761 - val_loss: 0.6199 - val_accuracy: 0.7899\n",
      "Epoch 19/30\n",
      "312/312 [==============================] - 21s 68ms/step - loss: 0.6554 - accuracy: 0.7761 - val_loss: 0.6410 - val_accuracy: 0.7864\n",
      "Epoch 20/30\n",
      "312/312 [==============================] - 19s 60ms/step - loss: 0.6471 - accuracy: 0.7782 - val_loss: 0.6284 - val_accuracy: 0.7911\n",
      "Epoch 21/30\n",
      "312/312 [==============================] - 18s 56ms/step - loss: 0.6433 - accuracy: 0.7762 - val_loss: 0.6625 - val_accuracy: 0.7792\n",
      "Epoch 22/30\n",
      "312/312 [==============================] - 24s 79ms/step - loss: 0.6424 - accuracy: 0.7785 - val_loss: 0.6160 - val_accuracy: 0.7903\n",
      "Epoch 23/30\n",
      "312/312 [==============================] - 18s 58ms/step - loss: 0.6431 - accuracy: 0.7782 - val_loss: 0.6090 - val_accuracy: 0.7919\n",
      "Epoch 24/30\n",
      "312/312 [==============================] - 18s 58ms/step - loss: 0.6411 - accuracy: 0.7802 - val_loss: 0.6643 - val_accuracy: 0.7781\n",
      "Epoch 25/30\n",
      "312/312 [==============================] - 19s 61ms/step - loss: 0.6417 - accuracy: 0.7808 - val_loss: 0.6338 - val_accuracy: 0.7876\n",
      "Epoch 26/30\n",
      "312/312 [==============================] - 24s 77ms/step - loss: 0.6365 - accuracy: 0.7804 - val_loss: 0.6084 - val_accuracy: 0.7941\n",
      "Epoch 27/30\n",
      "312/312 [==============================] - 18s 59ms/step - loss: 0.6357 - accuracy: 0.7827 - val_loss: 0.6533 - val_accuracy: 0.7812\n",
      "Epoch 28/30\n",
      "312/312 [==============================] - 18s 58ms/step - loss: 0.6344 - accuracy: 0.7832 - val_loss: 0.6016 - val_accuracy: 0.7971\n",
      "Epoch 29/30\n",
      "312/312 [==============================] - 19s 61ms/step - loss: 0.6309 - accuracy: 0.7819 - val_loss: 0.6397 - val_accuracy: 0.7878\n",
      "Epoch 30/30\n",
      "312/312 [==============================] - 24s 76ms/step - loss: 0.6333 - accuracy: 0.7804 - val_loss: 0.6538 - val_accuracy: 0.7775\n"
     ]
    }
   ],
   "source": [
    "# Training the Model with the best hyper-parameter settings\n",
    "ind = np.argmax(test_acc)\n",
    "best_num_epochs = num_epochs[ind]\n",
    "conv_model.fit_generator(datagen.flow(df_train, y_train_oh, batch_size=args.batch_size),\n",
    "    steps_per_epoch=len(df_train)//args.batch_size,\n",
    "    validation_data=(df_test, y_test_oh), epochs=epochs, verbose=1)\n",
    "\n",
    "# Saving the model along with it's weights\n",
    "conv_model.save('simclr_model.h5')\n",
    "\n",
    "# Predicting on the Train/Test Datasets\n",
    "preds_train = conv_model.predict(df_train)\n",
    "preds_test = conv_model.predict(df_test)\n",
    "\n",
    "# Finding the Predicted Classes\n",
    "cls_train = np.argmax(preds_train, axis = 1)\n",
    "cls_test = np.argmax(preds_test, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ab18f9d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-06T15:43:37.292578Z",
     "iopub.status.busy": "2022-06-06T15:43:37.292264Z",
     "iopub.status.idle": "2022-06-06T15:43:37.439656Z",
     "shell.execute_reply": "2022-06-06T15:43:37.438745Z"
    },
    "papermill": {
     "duration": 8.171412,
     "end_time": "2022-06-06T15:43:37.441940",
     "exception": false,
     "start_time": "2022-06-06T15:43:29.270528",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log-loss for Train Dataset =  16.22050904849515\n",
      "Log-loss for Test Dataset =  0.6537877656479885\n",
      "Weighted F1 Score for Train Dataset =  0.12040514528772045\n",
      "Weighted F1 Score for Test Dataset =  0.7777205355909564\n",
      "Accuracy for Train Dataset =  0.1687996800479928\n",
      "Accuracy for Test Dataset =  0.7775\n"
     ]
    }
   ],
   "source": [
    "# Finding the Train/Test set Loss\n",
    "print(\"Log-loss for Train Dataset = \", log_loss(y_train_oh, preds_train))\n",
    "print(\"Log-loss for Test Dataset = \", log_loss(y_test_oh, preds_test))\n",
    "print(\"Weighted F1 Score for Train Dataset = \", f1_score(y_train, cls_train, average = 'weighted'))\n",
    "print(\"Weighted F1 Score for Test Dataset = \", f1_score(y_test, cls_test, average = 'weighted'))\n",
    "print(\"Accuracy for Train Dataset = \", accuracy_score(y_train, cls_train))\n",
    "print(\"Accuracy for Test Dataset = \", accuracy_score(y_test, cls_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1932.824894,
   "end_time": "2022-06-06T15:43:49.257100",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-06-06T15:11:36.432206",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
